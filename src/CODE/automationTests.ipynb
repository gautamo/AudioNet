{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioNet import *\n",
    "from twilio.rest import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twilioMessage(testnum=0, acc=0, time=0, message=None):\n",
    "    # Your Account Sid and Auth Token from twilio.com / console \n",
    "    account_sid = 'AC6f784ea7dd32ff0e948716c731dd4cbf'\n",
    "    auth_token = '63593e9baabf3ac31aed7d195414b6a3' #PRIVATE\n",
    "\n",
    "    if message:\n",
    "        text = message\n",
    "    else:\n",
    "        text = f'TEST {testnum}, TEST ACC: {acc:.2f}%, TOTIME: {time:.2f} hours'\n",
    "    \n",
    "    client = Client(account_sid, auth_token) \n",
    "    message = client.messages.create( \n",
    "                    from_='+14804053343', to ='+14087723101',\n",
    "                    body = text\n",
    "                    )\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 5\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=600), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=600, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "    main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "    twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 6\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "    main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "    twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 7\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Second convolution layer\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._body(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 8\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=1000), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 4th layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 9\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=1000), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 4th layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 10\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 11\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 12\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 13\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 14\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=800), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=800, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 15\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=600, out_features=300), # 4th layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 16\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.2\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=600, out_features=300), # 4th layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 17\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 20\n",
    "LEARNING_RATE = 0.2\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 18\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 30\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 19\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 30\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 20\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS_COUNT = 30\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 21\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 30\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=600, out_features=300), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVAILABLE\n",
      "USING 100% OF THE DATA\n",
      "Train Epoch: 0 [16000/906425] Loss: 10.473149 Acc: 0.0000\n",
      "Train Epoch: 0 [32000/906425] Loss: 10.465066 Acc: 0.0000\n",
      "Train Epoch: 0 [48000/906425] Loss: 10.408939 Acc: 0.0625\n",
      "Train Epoch: 0 [64000/906425] Loss: 10.461823 Acc: 0.0000\n",
      "Train Epoch: 0 [80000/906425] Loss: 10.438855 Acc: 0.0000\n",
      "Train Epoch: 0 [96000/906425] Loss: 10.014087 Acc: 0.0000\n",
      "Train Epoch: 0 [112000/906425] Loss: 9.738981 Acc: 0.0000\n",
      "Train Epoch: 0 [128000/906425] Loss: 9.059366 Acc: 0.0000\n",
      "Train Epoch: 0 [144000/906425] Loss: 9.667430 Acc: 0.0000\n",
      "Train Epoch: 0 [160000/906425] Loss: 9.660781 Acc: 0.0000\n",
      "Train Epoch: 0 [176000/906425] Loss: 8.035956 Acc: 0.0625\n",
      "Train Epoch: 0 [192000/906425] Loss: 8.814575 Acc: 0.0625\n",
      "Train Epoch: 0 [208000/906425] Loss: 8.740342 Acc: 0.0625\n",
      "Train Epoch: 0 [224000/906425] Loss: 8.546540 Acc: 0.0625\n",
      "Train Epoch: 0 [240000/906425] Loss: 8.473011 Acc: 0.0000\n",
      "Train Epoch: 0 [256000/906425] Loss: 9.028548 Acc: 0.0000\n",
      "Train Epoch: 0 [272000/906425] Loss: 8.621485 Acc: 0.0000\n",
      "Train Epoch: 0 [288000/906425] Loss: 8.560605 Acc: 0.0000\n",
      "Train Epoch: 0 [304000/906425] Loss: 8.383786 Acc: 0.0000\n",
      "Train Epoch: 0 [320000/906425] Loss: 9.881779 Acc: 0.0000\n",
      "Train Epoch: 0 [336000/906425] Loss: 8.170562 Acc: 0.0625\n",
      "Train Epoch: 0 [352000/906425] Loss: 8.654990 Acc: 0.0625\n",
      "Train Epoch: 0 [368000/906425] Loss: 8.666216 Acc: 0.0000\n",
      "Train Epoch: 0 [384000/906425] Loss: 8.817715 Acc: 0.0000\n",
      "Train Epoch: 0 [400000/906425] Loss: 9.170440 Acc: 0.0000\n",
      "Train Epoch: 0 [416000/906425] Loss: 8.303413 Acc: 0.0000\n",
      "Train Epoch: 0 [432000/906425] Loss: 8.695433 Acc: 0.0000\n",
      "Train Epoch: 0 [448000/906425] Loss: 8.723539 Acc: 0.0625\n",
      "Train Epoch: 0 [464000/906425] Loss: 8.481383 Acc: 0.0625\n",
      "Train Epoch: 0 [480000/906425] Loss: 8.522718 Acc: 0.0000\n",
      "Train Epoch: 0 [496000/906425] Loss: 8.665290 Acc: 0.0000\n",
      "Train Epoch: 0 [512000/906425] Loss: 9.005451 Acc: 0.0625\n",
      "Train Epoch: 0 [528000/906425] Loss: 8.272301 Acc: 0.0625\n",
      "Train Epoch: 0 [544000/906425] Loss: 8.165857 Acc: 0.0000\n",
      "Train Epoch: 0 [560000/906425] Loss: 8.931526 Acc: 0.0000\n",
      "Train Epoch: 0 [576000/906425] Loss: 8.676763 Acc: 0.0000\n",
      "Train Epoch: 0 [592000/906425] Loss: 8.579183 Acc: 0.0625\n",
      "Train Epoch: 0 [608000/906425] Loss: 8.902371 Acc: 0.0625\n",
      "Train Epoch: 0 [624000/906425] Loss: 7.785019 Acc: 0.0625\n",
      "Train Epoch: 0 [640000/906425] Loss: 8.679999 Acc: 0.0000\n",
      "Train Epoch: 0 [656000/906425] Loss: 8.286232 Acc: 0.0625\n",
      "Train Epoch: 0 [672000/906425] Loss: 8.098239 Acc: 0.0000\n",
      "Train Epoch: 0 [688000/906425] Loss: 8.146522 Acc: 0.0625\n",
      "Train Epoch: 0 [704000/906425] Loss: 8.955513 Acc: 0.0000\n",
      "Train Epoch: 0 [720000/906425] Loss: 8.390179 Acc: 0.0625\n",
      "Train Epoch: 0 [736000/906425] Loss: 8.340364 Acc: 0.0625\n",
      "Train Epoch: 0 [752000/906425] Loss: 8.469135 Acc: 0.0000\n",
      "Train Epoch: 0 [768000/906425] Loss: 9.453554 Acc: 0.0000\n",
      "Train Epoch: 0 [784000/906425] Loss: 8.831870 Acc: 0.0000\n",
      "Train Epoch: 0 [800000/906425] Loss: 8.265494 Acc: 0.0000\n",
      "Train Epoch: 0 [816000/906425] Loss: 8.800489 Acc: 0.0625\n",
      "Train Epoch: 0 [832000/906425] Loss: 9.216861 Acc: 0.0000\n",
      "Train Epoch: 0 [848000/906425] Loss: 8.950811 Acc: 0.0000\n",
      "Train Epoch: 0 [864000/906425] Loss: 8.916231 Acc: 0.0000\n",
      "Train Epoch: 0 [880000/906425] Loss: 8.579615 Acc: 0.0000\n",
      "Train Epoch: 0 [896000/906425] Loss: 8.658012 Acc: 0.0000\n",
      "Elapsed 499.79s, 499.79 s/epoch, 0.01 s/batch, ets 24489.70s\n",
      "\n",
      "Test set: Average loss: 8.2398, Accuracy: 7269/293785 (2%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 1 [16000/906425] Loss: 7.995725 Acc: 0.1875\n",
      "Train Epoch: 1 [32000/906425] Loss: 8.092623 Acc: 0.0625\n",
      "Train Epoch: 1 [48000/906425] Loss: 7.828398 Acc: 0.0000\n",
      "Train Epoch: 1 [64000/906425] Loss: 8.283819 Acc: 0.0000\n",
      "Train Epoch: 1 [80000/906425] Loss: 8.814604 Acc: 0.0000\n",
      "Train Epoch: 1 [96000/906425] Loss: 6.882607 Acc: 0.1875\n",
      "Train Epoch: 1 [112000/906425] Loss: 8.937289 Acc: 0.0000\n",
      "Train Epoch: 1 [128000/906425] Loss: 7.571765 Acc: 0.0000\n",
      "Train Epoch: 1 [144000/906425] Loss: 5.649303 Acc: 0.1875\n",
      "Train Epoch: 1 [160000/906425] Loss: 9.157599 Acc: 0.0000\n",
      "Train Epoch: 1 [176000/906425] Loss: 7.328237 Acc: 0.0000\n",
      "Train Epoch: 1 [192000/906425] Loss: 7.685297 Acc: 0.0625\n",
      "Train Epoch: 1 [208000/906425] Loss: 7.991687 Acc: 0.1875\n",
      "Train Epoch: 1 [224000/906425] Loss: 7.346406 Acc: 0.0625\n",
      "Train Epoch: 1 [240000/906425] Loss: 7.675121 Acc: 0.0000\n",
      "Train Epoch: 1 [256000/906425] Loss: 5.535758 Acc: 0.1875\n",
      "Train Epoch: 1 [272000/906425] Loss: 7.010044 Acc: 0.0625\n",
      "Train Epoch: 1 [288000/906425] Loss: 7.910555 Acc: 0.0625\n",
      "Train Epoch: 1 [304000/906425] Loss: 6.701092 Acc: 0.1875\n",
      "Train Epoch: 1 [320000/906425] Loss: 7.613082 Acc: 0.1875\n",
      "Train Epoch: 1 [336000/906425] Loss: 6.472747 Acc: 0.0625\n",
      "Train Epoch: 1 [352000/906425] Loss: 6.037478 Acc: 0.0625\n",
      "Train Epoch: 1 [368000/906425] Loss: 6.982527 Acc: 0.0625\n",
      "Train Epoch: 1 [384000/906425] Loss: 6.942887 Acc: 0.1875\n",
      "Train Epoch: 1 [400000/906425] Loss: 7.618766 Acc: 0.1250\n",
      "Train Epoch: 1 [416000/906425] Loss: 7.539909 Acc: 0.2500\n",
      "Train Epoch: 1 [432000/906425] Loss: 7.196846 Acc: 0.1250\n",
      "Train Epoch: 1 [448000/906425] Loss: 6.023445 Acc: 0.1875\n",
      "Train Epoch: 1 [464000/906425] Loss: 5.314981 Acc: 0.2500\n",
      "Train Epoch: 1 [480000/906425] Loss: 5.981209 Acc: 0.2500\n",
      "Train Epoch: 1 [496000/906425] Loss: 6.179514 Acc: 0.2500\n",
      "Train Epoch: 1 [512000/906425] Loss: 6.931690 Acc: 0.1250\n",
      "Train Epoch: 1 [528000/906425] Loss: 6.787653 Acc: 0.0625\n",
      "Train Epoch: 1 [544000/906425] Loss: 7.414878 Acc: 0.1250\n",
      "Train Epoch: 1 [560000/906425] Loss: 7.422247 Acc: 0.0000\n",
      "Train Epoch: 1 [576000/906425] Loss: 6.535510 Acc: 0.1875\n",
      "Train Epoch: 1 [592000/906425] Loss: 7.449312 Acc: 0.0625\n",
      "Train Epoch: 1 [608000/906425] Loss: 5.963740 Acc: 0.1250\n",
      "Train Epoch: 1 [624000/906425] Loss: 6.534507 Acc: 0.1875\n",
      "Train Epoch: 1 [640000/906425] Loss: 7.322078 Acc: 0.1250\n",
      "Train Epoch: 1 [656000/906425] Loss: 7.175453 Acc: 0.1250\n",
      "Train Epoch: 1 [672000/906425] Loss: 5.752045 Acc: 0.2500\n",
      "Train Epoch: 1 [688000/906425] Loss: 5.946400 Acc: 0.0625\n",
      "Train Epoch: 1 [704000/906425] Loss: 4.427447 Acc: 0.1875\n",
      "Train Epoch: 1 [720000/906425] Loss: 5.268435 Acc: 0.2500\n",
      "Train Epoch: 1 [736000/906425] Loss: 4.824791 Acc: 0.2500\n",
      "Train Epoch: 1 [752000/906425] Loss: 5.989304 Acc: 0.0000\n",
      "Train Epoch: 1 [768000/906425] Loss: 7.365836 Acc: 0.1250\n",
      "Train Epoch: 1 [784000/906425] Loss: 6.335919 Acc: 0.1875\n",
      "Train Epoch: 1 [800000/906425] Loss: 4.907259 Acc: 0.1875\n",
      "Train Epoch: 1 [816000/906425] Loss: 6.157523 Acc: 0.1250\n",
      "Train Epoch: 1 [832000/906425] Loss: 6.388966 Acc: 0.1250\n",
      "Train Epoch: 1 [848000/906425] Loss: 6.000820 Acc: 0.2500\n",
      "Train Epoch: 1 [864000/906425] Loss: 4.467540 Acc: 0.2500\n",
      "Train Epoch: 1 [880000/906425] Loss: 5.373616 Acc: 0.2500\n",
      "Train Epoch: 1 [896000/906425] Loss: 7.810035 Acc: 0.0625\n",
      "Elapsed 1078.05s, 539.02 s/epoch, 0.01 s/batch, ets 25873.18s\n",
      "\n",
      "Test set: Average loss: 5.4009, Accuracy: 57307/293785 (20%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 2 [16000/906425] Loss: 5.972975 Acc: 0.0625\n",
      "Train Epoch: 2 [32000/906425] Loss: 5.728621 Acc: 0.1875\n",
      "Train Epoch: 2 [48000/906425] Loss: 3.977053 Acc: 0.1875\n",
      "Train Epoch: 2 [64000/906425] Loss: 4.882277 Acc: 0.2500\n",
      "Train Epoch: 2 [80000/906425] Loss: 4.854796 Acc: 0.3125\n",
      "Train Epoch: 2 [96000/906425] Loss: 5.325682 Acc: 0.3750\n",
      "Train Epoch: 2 [112000/906425] Loss: 5.172089 Acc: 0.1875\n",
      "Train Epoch: 2 [128000/906425] Loss: 6.116929 Acc: 0.1250\n",
      "Train Epoch: 2 [144000/906425] Loss: 4.350937 Acc: 0.3125\n",
      "Train Epoch: 2 [160000/906425] Loss: 4.704798 Acc: 0.4375\n",
      "Train Epoch: 2 [176000/906425] Loss: 4.985674 Acc: 0.1250\n",
      "Train Epoch: 2 [192000/906425] Loss: 4.992135 Acc: 0.2500\n",
      "Train Epoch: 2 [208000/906425] Loss: 5.543084 Acc: 0.1875\n",
      "Train Epoch: 2 [224000/906425] Loss: 6.186267 Acc: 0.3125\n",
      "Train Epoch: 2 [240000/906425] Loss: 5.960940 Acc: 0.1250\n",
      "Train Epoch: 2 [256000/906425] Loss: 4.801596 Acc: 0.2500\n",
      "Train Epoch: 2 [272000/906425] Loss: 4.142573 Acc: 0.2500\n",
      "Train Epoch: 2 [288000/906425] Loss: 6.021673 Acc: 0.1250\n",
      "Train Epoch: 2 [304000/906425] Loss: 4.181540 Acc: 0.1875\n",
      "Train Epoch: 2 [320000/906425] Loss: 6.488528 Acc: 0.1875\n",
      "Train Epoch: 2 [336000/906425] Loss: 4.828878 Acc: 0.2500\n",
      "Train Epoch: 2 [352000/906425] Loss: 4.244837 Acc: 0.3125\n",
      "Train Epoch: 2 [368000/906425] Loss: 4.674823 Acc: 0.3750\n",
      "Train Epoch: 2 [384000/906425] Loss: 5.921654 Acc: 0.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [400000/906425] Loss: 4.831058 Acc: 0.1875\n",
      "Train Epoch: 2 [416000/906425] Loss: 3.887038 Acc: 0.5000\n",
      "Train Epoch: 2 [432000/906425] Loss: 4.997967 Acc: 0.3125\n",
      "Train Epoch: 2 [448000/906425] Loss: 7.446680 Acc: 0.0000\n",
      "Train Epoch: 2 [464000/906425] Loss: 6.053707 Acc: 0.1875\n",
      "Train Epoch: 2 [480000/906425] Loss: 5.645463 Acc: 0.1875\n",
      "Train Epoch: 2 [496000/906425] Loss: 6.668434 Acc: 0.1875\n",
      "Train Epoch: 2 [512000/906425] Loss: 4.933176 Acc: 0.3750\n",
      "Train Epoch: 2 [528000/906425] Loss: 5.099960 Acc: 0.2500\n",
      "Train Epoch: 2 [544000/906425] Loss: 5.461891 Acc: 0.1875\n",
      "Train Epoch: 2 [560000/906425] Loss: 5.488800 Acc: 0.1250\n",
      "Train Epoch: 2 [576000/906425] Loss: 4.498505 Acc: 0.3750\n",
      "Train Epoch: 2 [592000/906425] Loss: 5.649401 Acc: 0.0625\n",
      "Train Epoch: 2 [608000/906425] Loss: 3.579786 Acc: 0.5625\n",
      "Train Epoch: 2 [624000/906425] Loss: 5.183014 Acc: 0.4375\n",
      "Train Epoch: 2 [640000/906425] Loss: 4.480009 Acc: 0.0625\n",
      "Train Epoch: 2 [656000/906425] Loss: 4.282396 Acc: 0.3750\n",
      "Train Epoch: 2 [672000/906425] Loss: 4.049313 Acc: 0.1250\n",
      "Train Epoch: 2 [688000/906425] Loss: 3.665801 Acc: 0.3750\n",
      "Train Epoch: 2 [704000/906425] Loss: 4.588326 Acc: 0.3125\n",
      "Train Epoch: 2 [720000/906425] Loss: 2.926557 Acc: 0.5000\n",
      "Train Epoch: 2 [736000/906425] Loss: 5.048995 Acc: 0.1875\n",
      "Train Epoch: 2 [752000/906425] Loss: 3.796542 Acc: 0.5000\n",
      "Train Epoch: 2 [768000/906425] Loss: 3.875509 Acc: 0.2500\n",
      "Train Epoch: 2 [784000/906425] Loss: 4.475940 Acc: 0.3750\n",
      "Train Epoch: 2 [800000/906425] Loss: 4.993088 Acc: 0.2500\n",
      "Train Epoch: 2 [816000/906425] Loss: 3.789700 Acc: 0.3750\n",
      "Train Epoch: 2 [832000/906425] Loss: 3.982243 Acc: 0.2500\n",
      "Train Epoch: 2 [848000/906425] Loss: 5.938330 Acc: 0.1875\n",
      "Train Epoch: 2 [864000/906425] Loss: 3.304522 Acc: 0.3750\n",
      "Train Epoch: 2 [880000/906425] Loss: 4.793137 Acc: 0.2500\n",
      "Train Epoch: 2 [896000/906425] Loss: 4.128823 Acc: 0.2500\n",
      "Elapsed 1656.22s, 552.07 s/epoch, 0.01 s/batch, ets 25947.45s\n",
      "\n",
      "Test set: Average loss: 4.1144, Accuracy: 88516/293785 (30%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 3 [16000/906425] Loss: 2.886627 Acc: 0.4375\n",
      "Train Epoch: 3 [32000/906425] Loss: 3.264190 Acc: 0.3125\n",
      "Train Epoch: 3 [48000/906425] Loss: 3.467557 Acc: 0.5000\n",
      "Train Epoch: 3 [64000/906425] Loss: 3.881684 Acc: 0.3750\n",
      "Train Epoch: 3 [80000/906425] Loss: 4.305529 Acc: 0.1875\n",
      "Train Epoch: 3 [96000/906425] Loss: 5.627834 Acc: 0.1250\n",
      "Train Epoch: 3 [112000/906425] Loss: 3.791209 Acc: 0.3750\n",
      "Train Epoch: 3 [128000/906425] Loss: 4.165700 Acc: 0.0625\n",
      "Train Epoch: 3 [144000/906425] Loss: 4.084695 Acc: 0.2500\n",
      "Train Epoch: 3 [160000/906425] Loss: 4.053018 Acc: 0.2500\n",
      "Train Epoch: 3 [176000/906425] Loss: 2.618366 Acc: 0.3125\n",
      "Train Epoch: 3 [192000/906425] Loss: 4.564777 Acc: 0.1875\n",
      "Train Epoch: 3 [208000/906425] Loss: 4.714107 Acc: 0.1875\n",
      "Train Epoch: 3 [224000/906425] Loss: 3.783092 Acc: 0.3125\n",
      "Train Epoch: 3 [240000/906425] Loss: 3.699277 Acc: 0.5625\n",
      "Train Epoch: 3 [256000/906425] Loss: 5.047681 Acc: 0.1250\n",
      "Train Epoch: 3 [272000/906425] Loss: 4.162314 Acc: 0.1875\n",
      "Train Epoch: 3 [288000/906425] Loss: 5.609044 Acc: 0.1250\n",
      "Train Epoch: 3 [304000/906425] Loss: 3.851279 Acc: 0.4375\n",
      "Train Epoch: 3 [320000/906425] Loss: 5.129545 Acc: 0.3750\n",
      "Train Epoch: 3 [336000/906425] Loss: 5.002333 Acc: 0.2500\n",
      "Train Epoch: 3 [352000/906425] Loss: 3.084115 Acc: 0.3750\n",
      "Train Epoch: 3 [368000/906425] Loss: 4.323078 Acc: 0.3125\n",
      "Train Epoch: 3 [384000/906425] Loss: 3.478822 Acc: 0.1875\n",
      "Train Epoch: 3 [400000/906425] Loss: 3.015203 Acc: 0.5000\n",
      "Train Epoch: 3 [416000/906425] Loss: 3.826333 Acc: 0.3125\n",
      "Train Epoch: 3 [432000/906425] Loss: 3.227537 Acc: 0.3125\n",
      "Train Epoch: 3 [448000/906425] Loss: 3.119986 Acc: 0.3750\n",
      "Train Epoch: 3 [464000/906425] Loss: 5.402093 Acc: 0.2500\n",
      "Train Epoch: 3 [480000/906425] Loss: 3.521977 Acc: 0.3750\n",
      "Train Epoch: 3 [496000/906425] Loss: 4.464693 Acc: 0.1250\n",
      "Train Epoch: 3 [512000/906425] Loss: 4.149898 Acc: 0.2500\n",
      "Train Epoch: 3 [528000/906425] Loss: 3.703832 Acc: 0.2500\n",
      "Train Epoch: 3 [544000/906425] Loss: 3.710604 Acc: 0.4375\n",
      "Train Epoch: 3 [560000/906425] Loss: 4.581830 Acc: 0.2500\n",
      "Train Epoch: 3 [576000/906425] Loss: 3.529158 Acc: 0.4375\n",
      "Train Epoch: 3 [592000/906425] Loss: 4.407726 Acc: 0.3125\n",
      "Train Epoch: 3 [608000/906425] Loss: 2.667799 Acc: 0.3750\n",
      "Train Epoch: 3 [624000/906425] Loss: 3.687555 Acc: 0.3750\n",
      "Train Epoch: 3 [640000/906425] Loss: 3.537171 Acc: 0.5000\n",
      "Train Epoch: 3 [656000/906425] Loss: 2.998756 Acc: 0.4375\n",
      "Train Epoch: 3 [672000/906425] Loss: 4.669643 Acc: 0.3125\n",
      "Train Epoch: 3 [688000/906425] Loss: 2.625329 Acc: 0.5000\n",
      "Train Epoch: 3 [704000/906425] Loss: 4.052736 Acc: 0.3125\n",
      "Train Epoch: 3 [720000/906425] Loss: 4.003026 Acc: 0.1250\n",
      "Train Epoch: 3 [736000/906425] Loss: 4.403772 Acc: 0.3125\n",
      "Train Epoch: 3 [752000/906425] Loss: 4.162410 Acc: 0.3125\n",
      "Train Epoch: 3 [768000/906425] Loss: 2.306332 Acc: 0.5625\n",
      "Train Epoch: 3 [784000/906425] Loss: 3.795188 Acc: 0.3125\n",
      "Train Epoch: 3 [800000/906425] Loss: 4.971097 Acc: 0.1250\n",
      "Train Epoch: 3 [816000/906425] Loss: 3.505620 Acc: 0.3750\n",
      "Train Epoch: 3 [832000/906425] Loss: 4.246671 Acc: 0.5000\n",
      "Train Epoch: 3 [848000/906425] Loss: 4.410441 Acc: 0.2500\n",
      "Train Epoch: 3 [864000/906425] Loss: 4.016947 Acc: 0.3750\n",
      "Train Epoch: 3 [880000/906425] Loss: 3.392299 Acc: 0.3125\n",
      "Train Epoch: 3 [896000/906425] Loss: 2.426653 Acc: 0.5000\n",
      "Elapsed 2234.77s, 558.69 s/epoch, 0.01 s/batch, ets 25699.91s\n",
      "\n",
      "Test set: Average loss: 3.3768, Accuracy: 109996/293785 (37%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 4 [16000/906425] Loss: 1.903553 Acc: 0.3750\n",
      "Train Epoch: 4 [32000/906425] Loss: 3.980729 Acc: 0.1875\n",
      "Train Epoch: 4 [48000/906425] Loss: 3.220670 Acc: 0.3125\n",
      "Train Epoch: 4 [64000/906425] Loss: 3.463728 Acc: 0.4375\n",
      "Train Epoch: 4 [80000/906425] Loss: 4.235041 Acc: 0.4375\n",
      "Train Epoch: 4 [96000/906425] Loss: 4.696073 Acc: 0.0625\n",
      "Train Epoch: 4 [112000/906425] Loss: 3.088649 Acc: 0.2500\n",
      "Train Epoch: 4 [128000/906425] Loss: 4.780818 Acc: 0.2500\n",
      "Train Epoch: 4 [144000/906425] Loss: 3.487468 Acc: 0.3125\n",
      "Train Epoch: 4 [160000/906425] Loss: 3.166591 Acc: 0.1875\n",
      "Train Epoch: 4 [176000/906425] Loss: 3.812154 Acc: 0.4375\n",
      "Train Epoch: 4 [192000/906425] Loss: 3.604273 Acc: 0.4375\n",
      "Train Epoch: 4 [208000/906425] Loss: 3.901333 Acc: 0.2500\n",
      "Train Epoch: 4 [224000/906425] Loss: 3.002741 Acc: 0.4375\n",
      "Train Epoch: 4 [240000/906425] Loss: 2.577223 Acc: 0.5000\n",
      "Train Epoch: 4 [256000/906425] Loss: 3.655816 Acc: 0.3125\n",
      "Train Epoch: 4 [272000/906425] Loss: 3.450486 Acc: 0.3125\n",
      "Train Epoch: 4 [288000/906425] Loss: 3.642273 Acc: 0.4375\n",
      "Train Epoch: 4 [304000/906425] Loss: 2.878162 Acc: 0.5625\n",
      "Train Epoch: 4 [320000/906425] Loss: 3.433622 Acc: 0.3750\n",
      "Train Epoch: 4 [336000/906425] Loss: 2.445659 Acc: 0.5625\n",
      "Train Epoch: 4 [352000/906425] Loss: 4.699154 Acc: 0.3750\n",
      "Train Epoch: 4 [368000/906425] Loss: 3.478067 Acc: 0.3125\n",
      "Train Epoch: 4 [384000/906425] Loss: 2.839158 Acc: 0.6250\n",
      "Train Epoch: 4 [400000/906425] Loss: 2.941804 Acc: 0.3125\n",
      "Train Epoch: 4 [416000/906425] Loss: 3.217510 Acc: 0.3125\n",
      "Train Epoch: 4 [432000/906425] Loss: 4.753675 Acc: 0.3125\n",
      "Train Epoch: 4 [448000/906425] Loss: 2.904325 Acc: 0.3125\n",
      "Train Epoch: 4 [464000/906425] Loss: 3.137925 Acc: 0.3750\n",
      "Train Epoch: 4 [480000/906425] Loss: 3.471269 Acc: 0.3750\n",
      "Train Epoch: 4 [496000/906425] Loss: 1.751457 Acc: 0.6875\n",
      "Train Epoch: 4 [512000/906425] Loss: 4.541541 Acc: 0.3125\n",
      "Train Epoch: 4 [528000/906425] Loss: 4.697152 Acc: 0.2500\n",
      "Train Epoch: 4 [544000/906425] Loss: 2.933396 Acc: 0.4375\n",
      "Train Epoch: 4 [560000/906425] Loss: 3.914802 Acc: 0.2500\n",
      "Train Epoch: 4 [576000/906425] Loss: 3.833002 Acc: 0.3750\n",
      "Train Epoch: 4 [592000/906425] Loss: 2.532604 Acc: 0.5625\n",
      "Train Epoch: 4 [608000/906425] Loss: 2.926720 Acc: 0.4375\n",
      "Train Epoch: 4 [624000/906425] Loss: 3.303131 Acc: 0.4375\n",
      "Train Epoch: 4 [640000/906425] Loss: 3.710155 Acc: 0.4375\n",
      "Train Epoch: 4 [656000/906425] Loss: 3.258355 Acc: 0.4375\n",
      "Train Epoch: 4 [672000/906425] Loss: 2.302151 Acc: 0.6250\n",
      "Train Epoch: 4 [688000/906425] Loss: 3.178210 Acc: 0.3750\n",
      "Train Epoch: 4 [704000/906425] Loss: 2.958911 Acc: 0.4375\n",
      "Train Epoch: 4 [720000/906425] Loss: 2.384561 Acc: 0.3750\n",
      "Train Epoch: 4 [736000/906425] Loss: 2.504203 Acc: 0.5000\n",
      "Train Epoch: 4 [752000/906425] Loss: 2.280314 Acc: 0.6250\n",
      "Train Epoch: 4 [768000/906425] Loss: 2.187899 Acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [784000/906425] Loss: 2.523930 Acc: 0.5000\n",
      "Train Epoch: 4 [800000/906425] Loss: 3.083327 Acc: 0.3750\n",
      "Train Epoch: 4 [816000/906425] Loss: 2.785357 Acc: 0.5000\n",
      "Train Epoch: 4 [832000/906425] Loss: 4.423494 Acc: 0.3125\n",
      "Train Epoch: 4 [848000/906425] Loss: 3.125810 Acc: 0.3750\n",
      "Train Epoch: 4 [864000/906425] Loss: 4.538547 Acc: 0.2500\n",
      "Train Epoch: 4 [880000/906425] Loss: 3.552544 Acc: 0.4375\n",
      "Train Epoch: 4 [896000/906425] Loss: 3.140967 Acc: 0.4375\n",
      "Elapsed 2813.91s, 562.78 s/epoch, 0.01 s/batch, ets 25325.22s\n",
      "\n",
      "Test set: Average loss: 2.9585, Accuracy: 124165/293785 (42%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 5 [16000/906425] Loss: 2.376197 Acc: 0.5625\n",
      "Train Epoch: 5 [32000/906425] Loss: 2.224427 Acc: 0.5625\n",
      "Train Epoch: 5 [48000/906425] Loss: 2.259635 Acc: 0.3750\n",
      "Train Epoch: 5 [64000/906425] Loss: 2.073647 Acc: 0.5000\n",
      "Train Epoch: 5 [80000/906425] Loss: 3.913765 Acc: 0.2500\n",
      "Train Epoch: 5 [96000/906425] Loss: 2.181508 Acc: 0.6250\n",
      "Train Epoch: 5 [112000/906425] Loss: 3.831326 Acc: 0.2500\n",
      "Train Epoch: 5 [128000/906425] Loss: 2.163415 Acc: 0.5000\n",
      "Train Epoch: 5 [144000/906425] Loss: 3.410099 Acc: 0.3750\n",
      "Train Epoch: 5 [160000/906425] Loss: 5.207538 Acc: 0.1250\n",
      "Train Epoch: 5 [176000/906425] Loss: 3.036074 Acc: 0.4375\n",
      "Train Epoch: 5 [192000/906425] Loss: 1.938469 Acc: 0.6250\n",
      "Train Epoch: 5 [208000/906425] Loss: 3.188846 Acc: 0.3750\n",
      "Train Epoch: 5 [224000/906425] Loss: 3.609255 Acc: 0.3125\n",
      "Train Epoch: 5 [240000/906425] Loss: 3.023968 Acc: 0.4375\n",
      "Train Epoch: 5 [256000/906425] Loss: 2.760703 Acc: 0.5000\n",
      "Train Epoch: 5 [272000/906425] Loss: 2.566569 Acc: 0.4375\n",
      "Train Epoch: 5 [288000/906425] Loss: 3.462518 Acc: 0.3750\n",
      "Train Epoch: 5 [304000/906425] Loss: 2.008534 Acc: 0.6250\n",
      "Train Epoch: 5 [320000/906425] Loss: 2.442567 Acc: 0.6250\n",
      "Train Epoch: 5 [336000/906425] Loss: 2.506869 Acc: 0.5000\n",
      "Train Epoch: 5 [352000/906425] Loss: 2.806108 Acc: 0.3750\n",
      "Train Epoch: 5 [368000/906425] Loss: 2.203481 Acc: 0.4375\n",
      "Train Epoch: 5 [384000/906425] Loss: 3.152758 Acc: 0.5000\n",
      "Train Epoch: 5 [400000/906425] Loss: 2.696414 Acc: 0.4375\n",
      "Train Epoch: 5 [416000/906425] Loss: 1.668639 Acc: 0.5625\n",
      "Train Epoch: 5 [432000/906425] Loss: 3.024233 Acc: 0.4375\n",
      "Train Epoch: 5 [448000/906425] Loss: 2.528302 Acc: 0.4375\n",
      "Train Epoch: 5 [464000/906425] Loss: 2.850202 Acc: 0.4375\n",
      "Train Epoch: 5 [480000/906425] Loss: 2.933210 Acc: 0.4375\n",
      "Train Epoch: 5 [496000/906425] Loss: 2.756958 Acc: 0.3750\n",
      "Train Epoch: 5 [512000/906425] Loss: 4.554988 Acc: 0.2500\n",
      "Train Epoch: 5 [528000/906425] Loss: 2.267672 Acc: 0.5000\n",
      "Train Epoch: 5 [544000/906425] Loss: 3.161462 Acc: 0.3125\n",
      "Train Epoch: 5 [560000/906425] Loss: 1.826541 Acc: 0.6250\n",
      "Train Epoch: 5 [576000/906425] Loss: 2.690718 Acc: 0.4375\n",
      "Train Epoch: 5 [592000/906425] Loss: 2.395834 Acc: 0.4375\n",
      "Train Epoch: 5 [608000/906425] Loss: 1.879881 Acc: 0.4375\n",
      "Train Epoch: 5 [624000/906425] Loss: 1.503591 Acc: 0.5625\n",
      "Train Epoch: 5 [640000/906425] Loss: 2.964888 Acc: 0.5000\n",
      "Train Epoch: 5 [656000/906425] Loss: 3.494277 Acc: 0.4375\n",
      "Train Epoch: 5 [672000/906425] Loss: 2.247185 Acc: 0.3750\n",
      "Train Epoch: 5 [688000/906425] Loss: 1.899927 Acc: 0.4375\n",
      "Train Epoch: 5 [704000/906425] Loss: 2.380738 Acc: 0.5000\n",
      "Train Epoch: 5 [720000/906425] Loss: 2.264192 Acc: 0.5000\n",
      "Train Epoch: 5 [736000/906425] Loss: 2.610716 Acc: 0.3750\n",
      "Train Epoch: 5 [752000/906425] Loss: 3.319293 Acc: 0.5000\n",
      "Train Epoch: 5 [768000/906425] Loss: 3.944965 Acc: 0.3125\n",
      "Train Epoch: 5 [784000/906425] Loss: 2.962800 Acc: 0.3125\n",
      "Train Epoch: 5 [800000/906425] Loss: 2.230886 Acc: 0.5000\n",
      "Train Epoch: 5 [816000/906425] Loss: 2.402255 Acc: 0.5625\n",
      "Train Epoch: 5 [832000/906425] Loss: 3.447927 Acc: 0.3125\n",
      "Train Epoch: 5 [848000/906425] Loss: 2.654027 Acc: 0.5625\n",
      "Train Epoch: 5 [864000/906425] Loss: 0.984865 Acc: 0.8125\n",
      "Train Epoch: 5 [880000/906425] Loss: 1.834036 Acc: 0.5625\n",
      "Train Epoch: 5 [896000/906425] Loss: 1.594923 Acc: 0.5000\n",
      "Elapsed 3392.49s, 565.41 s/epoch, 0.01 s/batch, ets 24878.24s\n",
      "\n",
      "Test set: Average loss: 2.6461, Accuracy: 136290/293785 (46%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 6 [16000/906425] Loss: 1.940121 Acc: 0.3750\n",
      "Train Epoch: 6 [32000/906425] Loss: 2.370050 Acc: 0.5000\n",
      "Train Epoch: 6 [48000/906425] Loss: 1.928488 Acc: 0.6250\n",
      "Train Epoch: 6 [64000/906425] Loss: 0.787826 Acc: 0.8750\n",
      "Train Epoch: 6 [80000/906425] Loss: 3.146097 Acc: 0.4375\n",
      "Train Epoch: 6 [96000/906425] Loss: 2.483472 Acc: 0.3750\n",
      "Train Epoch: 6 [112000/906425] Loss: 2.020641 Acc: 0.5625\n",
      "Train Epoch: 6 [128000/906425] Loss: 2.363937 Acc: 0.5625\n",
      "Train Epoch: 6 [144000/906425] Loss: 2.653210 Acc: 0.4375\n",
      "Train Epoch: 6 [160000/906425] Loss: 3.069459 Acc: 0.3750\n",
      "Train Epoch: 6 [176000/906425] Loss: 2.274123 Acc: 0.5000\n",
      "Train Epoch: 6 [192000/906425] Loss: 1.436728 Acc: 0.5625\n",
      "Train Epoch: 6 [208000/906425] Loss: 1.529642 Acc: 0.5000\n",
      "Train Epoch: 6 [224000/906425] Loss: 2.966010 Acc: 0.4375\n",
      "Train Epoch: 6 [240000/906425] Loss: 1.773486 Acc: 0.5625\n",
      "Train Epoch: 6 [256000/906425] Loss: 2.252563 Acc: 0.5625\n",
      "Train Epoch: 6 [272000/906425] Loss: 2.467327 Acc: 0.4375\n",
      "Train Epoch: 6 [288000/906425] Loss: 2.851847 Acc: 0.2500\n",
      "Train Epoch: 6 [304000/906425] Loss: 2.250568 Acc: 0.6250\n",
      "Train Epoch: 6 [320000/906425] Loss: 3.632763 Acc: 0.2500\n",
      "Train Epoch: 6 [336000/906425] Loss: 2.211009 Acc: 0.5625\n",
      "Train Epoch: 6 [352000/906425] Loss: 2.994701 Acc: 0.3750\n",
      "Train Epoch: 6 [368000/906425] Loss: 2.598893 Acc: 0.3750\n",
      "Train Epoch: 6 [384000/906425] Loss: 1.954583 Acc: 0.6875\n",
      "Train Epoch: 6 [400000/906425] Loss: 2.132239 Acc: 0.5000\n",
      "Train Epoch: 6 [416000/906425] Loss: 2.698413 Acc: 0.5000\n",
      "Train Epoch: 6 [432000/906425] Loss: 2.304495 Acc: 0.4375\n",
      "Train Epoch: 6 [448000/906425] Loss: 2.326152 Acc: 0.3750\n",
      "Train Epoch: 6 [464000/906425] Loss: 3.264983 Acc: 0.3750\n",
      "Train Epoch: 6 [480000/906425] Loss: 1.656249 Acc: 0.5625\n",
      "Train Epoch: 6 [496000/906425] Loss: 2.487225 Acc: 0.3750\n",
      "Train Epoch: 6 [512000/906425] Loss: 2.246063 Acc: 0.6250\n",
      "Train Epoch: 6 [528000/906425] Loss: 2.093756 Acc: 0.5000\n",
      "Train Epoch: 6 [544000/906425] Loss: 1.972323 Acc: 0.6250\n",
      "Train Epoch: 6 [560000/906425] Loss: 1.541457 Acc: 0.6875\n",
      "Train Epoch: 6 [576000/906425] Loss: 2.272706 Acc: 0.3750\n",
      "Train Epoch: 6 [592000/906425] Loss: 2.724535 Acc: 0.6250\n",
      "Train Epoch: 6 [608000/906425] Loss: 2.648523 Acc: 0.5000\n",
      "Train Epoch: 6 [624000/906425] Loss: 2.361938 Acc: 0.4375\n",
      "Train Epoch: 6 [640000/906425] Loss: 2.536854 Acc: 0.5000\n",
      "Train Epoch: 6 [656000/906425] Loss: 1.821452 Acc: 0.6250\n",
      "Train Epoch: 6 [672000/906425] Loss: 2.996883 Acc: 0.3750\n",
      "Train Epoch: 6 [688000/906425] Loss: 3.403072 Acc: 0.5625\n",
      "Train Epoch: 6 [704000/906425] Loss: 1.501536 Acc: 0.5625\n",
      "Train Epoch: 6 [720000/906425] Loss: 1.866090 Acc: 0.6250\n",
      "Train Epoch: 6 [736000/906425] Loss: 4.529316 Acc: 0.2500\n",
      "Train Epoch: 6 [752000/906425] Loss: 2.899929 Acc: 0.5000\n",
      "Train Epoch: 6 [768000/906425] Loss: 2.487326 Acc: 0.3750\n",
      "Train Epoch: 6 [784000/906425] Loss: 2.438627 Acc: 0.3750\n",
      "Train Epoch: 6 [800000/906425] Loss: 1.998905 Acc: 0.5625\n",
      "Train Epoch: 6 [816000/906425] Loss: 1.841792 Acc: 0.5625\n",
      "Train Epoch: 6 [832000/906425] Loss: 2.047908 Acc: 0.6250\n",
      "Train Epoch: 6 [848000/906425] Loss: 2.837775 Acc: 0.5625\n",
      "Train Epoch: 6 [864000/906425] Loss: 2.899918 Acc: 0.4375\n",
      "Train Epoch: 6 [880000/906425] Loss: 2.195189 Acc: 0.5000\n",
      "Train Epoch: 6 [896000/906425] Loss: 2.535009 Acc: 0.5000\n",
      "Elapsed 3971.02s, 567.29 s/epoch, 0.01 s/batch, ets 24393.39s\n",
      "\n",
      "Test set: Average loss: 2.4204, Accuracy: 145662/293785 (50%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 7 [16000/906425] Loss: 2.447914 Acc: 0.5625\n",
      "Train Epoch: 7 [32000/906425] Loss: 2.167009 Acc: 0.5625\n",
      "Train Epoch: 7 [48000/906425] Loss: 3.042675 Acc: 0.2500\n",
      "Train Epoch: 7 [64000/906425] Loss: 2.410004 Acc: 0.5000\n",
      "Train Epoch: 7 [80000/906425] Loss: 0.862289 Acc: 0.8750\n",
      "Train Epoch: 7 [96000/906425] Loss: 2.456359 Acc: 0.4375\n",
      "Train Epoch: 7 [112000/906425] Loss: 1.713913 Acc: 0.5625\n",
      "Train Epoch: 7 [128000/906425] Loss: 1.833755 Acc: 0.5625\n",
      "Train Epoch: 7 [144000/906425] Loss: 2.895685 Acc: 0.4375\n",
      "Train Epoch: 7 [160000/906425] Loss: 2.045335 Acc: 0.4375\n",
      "Train Epoch: 7 [176000/906425] Loss: 2.201624 Acc: 0.5000\n",
      "Train Epoch: 7 [192000/906425] Loss: 2.145916 Acc: 0.6250\n",
      "Train Epoch: 7 [208000/906425] Loss: 2.270915 Acc: 0.4375\n",
      "Train Epoch: 7 [224000/906425] Loss: 4.172451 Acc: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [240000/906425] Loss: 1.826709 Acc: 0.5625\n",
      "Train Epoch: 7 [256000/906425] Loss: 2.190669 Acc: 0.5000\n",
      "Train Epoch: 7 [272000/906425] Loss: 2.516171 Acc: 0.5000\n",
      "Train Epoch: 7 [288000/906425] Loss: 2.868063 Acc: 0.3750\n",
      "Train Epoch: 7 [304000/906425] Loss: 2.801751 Acc: 0.5000\n",
      "Train Epoch: 7 [320000/906425] Loss: 2.400268 Acc: 0.5625\n",
      "Train Epoch: 7 [336000/906425] Loss: 1.941291 Acc: 0.4375\n",
      "Train Epoch: 7 [352000/906425] Loss: 1.614802 Acc: 0.5625\n",
      "Train Epoch: 7 [368000/906425] Loss: 3.118908 Acc: 0.5625\n",
      "Train Epoch: 7 [384000/906425] Loss: 2.253629 Acc: 0.4375\n",
      "Train Epoch: 7 [400000/906425] Loss: 2.181247 Acc: 0.7500\n",
      "Train Epoch: 7 [416000/906425] Loss: 2.989047 Acc: 0.4375\n",
      "Train Epoch: 7 [432000/906425] Loss: 2.509284 Acc: 0.5625\n",
      "Train Epoch: 7 [448000/906425] Loss: 2.126413 Acc: 0.5625\n",
      "Train Epoch: 7 [464000/906425] Loss: 2.578050 Acc: 0.5000\n",
      "Train Epoch: 7 [480000/906425] Loss: 2.423970 Acc: 0.3750\n",
      "Train Epoch: 7 [496000/906425] Loss: 2.006725 Acc: 0.5000\n",
      "Train Epoch: 7 [512000/906425] Loss: 1.532955 Acc: 0.5000\n",
      "Train Epoch: 7 [528000/906425] Loss: 2.113974 Acc: 0.5000\n",
      "Train Epoch: 7 [544000/906425] Loss: 2.768368 Acc: 0.2500\n",
      "Train Epoch: 7 [560000/906425] Loss: 2.363687 Acc: 0.5000\n",
      "Train Epoch: 7 [576000/906425] Loss: 2.935678 Acc: 0.3125\n",
      "Train Epoch: 7 [592000/906425] Loss: 1.865097 Acc: 0.5625\n",
      "Train Epoch: 7 [608000/906425] Loss: 1.343605 Acc: 0.6875\n",
      "Train Epoch: 7 [624000/906425] Loss: 2.143024 Acc: 0.5625\n",
      "Train Epoch: 7 [640000/906425] Loss: 1.555077 Acc: 0.6250\n",
      "Train Epoch: 7 [656000/906425] Loss: 1.865860 Acc: 0.7500\n",
      "Train Epoch: 7 [672000/906425] Loss: 2.711439 Acc: 0.5000\n",
      "Train Epoch: 7 [688000/906425] Loss: 2.581851 Acc: 0.5000\n",
      "Train Epoch: 7 [704000/906425] Loss: 1.818691 Acc: 0.6250\n",
      "Train Epoch: 7 [720000/906425] Loss: 3.378682 Acc: 0.3750\n",
      "Train Epoch: 7 [736000/906425] Loss: 2.021965 Acc: 0.5000\n",
      "Train Epoch: 7 [752000/906425] Loss: 3.378568 Acc: 0.4375\n",
      "Train Epoch: 7 [768000/906425] Loss: 3.014857 Acc: 0.5625\n",
      "Train Epoch: 7 [784000/906425] Loss: 2.399577 Acc: 0.5625\n",
      "Train Epoch: 7 [800000/906425] Loss: 2.191479 Acc: 0.5625\n",
      "Train Epoch: 7 [816000/906425] Loss: 2.657053 Acc: 0.5000\n",
      "Train Epoch: 7 [832000/906425] Loss: 2.200306 Acc: 0.5625\n",
      "Train Epoch: 7 [848000/906425] Loss: 1.116339 Acc: 0.6875\n",
      "Train Epoch: 7 [864000/906425] Loss: 2.083087 Acc: 0.5625\n",
      "Train Epoch: 7 [880000/906425] Loss: 4.414654 Acc: 0.3125\n",
      "Train Epoch: 7 [896000/906425] Loss: 2.938115 Acc: 0.4375\n",
      "Elapsed 4550.33s, 568.79 s/epoch, 0.01 s/batch, ets 23889.23s\n",
      "\n",
      "Test set: Average loss: 2.2469, Accuracy: 154208/293785 (52%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 8 [16000/906425] Loss: 1.680528 Acc: 0.5625\n",
      "Train Epoch: 8 [32000/906425] Loss: 2.053450 Acc: 0.5625\n",
      "Train Epoch: 8 [48000/906425] Loss: 2.899403 Acc: 0.5000\n",
      "Train Epoch: 8 [64000/906425] Loss: 2.028333 Acc: 0.5625\n",
      "Train Epoch: 8 [80000/906425] Loss: 1.220652 Acc: 0.7500\n",
      "Train Epoch: 8 [96000/906425] Loss: 2.245720 Acc: 0.4375\n",
      "Train Epoch: 8 [112000/906425] Loss: 2.501057 Acc: 0.3750\n",
      "Train Epoch: 8 [128000/906425] Loss: 1.888651 Acc: 0.6250\n",
      "Train Epoch: 8 [144000/906425] Loss: 2.071857 Acc: 0.5000\n",
      "Train Epoch: 8 [160000/906425] Loss: 1.593539 Acc: 0.5625\n",
      "Train Epoch: 8 [176000/906425] Loss: 2.034304 Acc: 0.5625\n",
      "Train Epoch: 8 [192000/906425] Loss: 1.905081 Acc: 0.4375\n",
      "Train Epoch: 8 [208000/906425] Loss: 2.279923 Acc: 0.6250\n",
      "Train Epoch: 8 [224000/906425] Loss: 2.816861 Acc: 0.3750\n",
      "Train Epoch: 8 [240000/906425] Loss: 3.102545 Acc: 0.4375\n",
      "Train Epoch: 8 [256000/906425] Loss: 1.742925 Acc: 0.6875\n",
      "Train Epoch: 8 [272000/906425] Loss: 2.331110 Acc: 0.4375\n",
      "Train Epoch: 8 [288000/906425] Loss: 2.378028 Acc: 0.4375\n",
      "Train Epoch: 8 [304000/906425] Loss: 1.740162 Acc: 0.6250\n",
      "Train Epoch: 8 [320000/906425] Loss: 1.215681 Acc: 0.7500\n",
      "Train Epoch: 8 [336000/906425] Loss: 2.540265 Acc: 0.5000\n",
      "Train Epoch: 8 [352000/906425] Loss: 2.383856 Acc: 0.5000\n",
      "Train Epoch: 8 [368000/906425] Loss: 2.422947 Acc: 0.5625\n",
      "Train Epoch: 8 [384000/906425] Loss: 2.740578 Acc: 0.6250\n",
      "Train Epoch: 8 [400000/906425] Loss: 1.728574 Acc: 0.6875\n",
      "Train Epoch: 8 [416000/906425] Loss: 1.643075 Acc: 0.6875\n",
      "Train Epoch: 8 [432000/906425] Loss: 1.630332 Acc: 0.6250\n",
      "Train Epoch: 8 [448000/906425] Loss: 1.357802 Acc: 0.7500\n",
      "Train Epoch: 8 [464000/906425] Loss: 1.027776 Acc: 0.7500\n",
      "Train Epoch: 8 [480000/906425] Loss: 2.388883 Acc: 0.2500\n",
      "Train Epoch: 8 [496000/906425] Loss: 1.867461 Acc: 0.5000\n",
      "Train Epoch: 8 [512000/906425] Loss: 0.940528 Acc: 0.8750\n",
      "Train Epoch: 8 [528000/906425] Loss: 1.505307 Acc: 0.6250\n",
      "Train Epoch: 8 [544000/906425] Loss: 1.863406 Acc: 0.7500\n",
      "Train Epoch: 8 [560000/906425] Loss: 1.720420 Acc: 0.6250\n",
      "Train Epoch: 8 [576000/906425] Loss: 3.449486 Acc: 0.4375\n",
      "Train Epoch: 8 [592000/906425] Loss: 2.403768 Acc: 0.5000\n",
      "Train Epoch: 8 [608000/906425] Loss: 2.214221 Acc: 0.6250\n",
      "Train Epoch: 8 [624000/906425] Loss: 4.053266 Acc: 0.2500\n",
      "Train Epoch: 8 [640000/906425] Loss: 2.163602 Acc: 0.5000\n",
      "Train Epoch: 8 [656000/906425] Loss: 2.678199 Acc: 0.5625\n",
      "Train Epoch: 8 [672000/906425] Loss: 2.287141 Acc: 0.4375\n",
      "Train Epoch: 8 [688000/906425] Loss: 2.322807 Acc: 0.5625\n",
      "Train Epoch: 8 [704000/906425] Loss: 2.433182 Acc: 0.5625\n",
      "Train Epoch: 8 [720000/906425] Loss: 1.932466 Acc: 0.5000\n",
      "Train Epoch: 8 [736000/906425] Loss: 2.588384 Acc: 0.4375\n",
      "Train Epoch: 8 [752000/906425] Loss: 1.931749 Acc: 0.5625\n",
      "Train Epoch: 8 [768000/906425] Loss: 2.808607 Acc: 0.4375\n",
      "Train Epoch: 8 [784000/906425] Loss: 1.973201 Acc: 0.5625\n",
      "Train Epoch: 8 [800000/906425] Loss: 1.453620 Acc: 0.6250\n",
      "Train Epoch: 8 [816000/906425] Loss: 0.990895 Acc: 0.7500\n",
      "Train Epoch: 8 [832000/906425] Loss: 2.039614 Acc: 0.4375\n",
      "Train Epoch: 8 [848000/906425] Loss: 3.017720 Acc: 0.3750\n",
      "Train Epoch: 8 [864000/906425] Loss: 1.443206 Acc: 0.6875\n",
      "Train Epoch: 8 [880000/906425] Loss: 1.861837 Acc: 0.5625\n",
      "Train Epoch: 8 [896000/906425] Loss: 1.320874 Acc: 0.6250\n",
      "Elapsed 5131.10s, 570.12 s/epoch, 0.01 s/batch, ets 23374.99s\n",
      "\n",
      "Test set: Average loss: 2.0944, Accuracy: 162471/293785 (55%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 9 [16000/906425] Loss: 2.058547 Acc: 0.5625\n",
      "Train Epoch: 9 [32000/906425] Loss: 2.221322 Acc: 0.4375\n",
      "Train Epoch: 9 [48000/906425] Loss: 2.328515 Acc: 0.5000\n",
      "Train Epoch: 9 [64000/906425] Loss: 1.701977 Acc: 0.6250\n",
      "Train Epoch: 9 [80000/906425] Loss: 2.998264 Acc: 0.5625\n",
      "Train Epoch: 9 [96000/906425] Loss: 2.849309 Acc: 0.3125\n",
      "Train Epoch: 9 [112000/906425] Loss: 1.934762 Acc: 0.5625\n",
      "Train Epoch: 9 [128000/906425] Loss: 1.360421 Acc: 0.6875\n",
      "Train Epoch: 9 [144000/906425] Loss: 2.094239 Acc: 0.6875\n",
      "Train Epoch: 9 [160000/906425] Loss: 1.738913 Acc: 0.5625\n",
      "Train Epoch: 9 [176000/906425] Loss: 1.783608 Acc: 0.6250\n",
      "Train Epoch: 9 [192000/906425] Loss: 2.725364 Acc: 0.5625\n",
      "Train Epoch: 9 [208000/906425] Loss: 2.438464 Acc: 0.3750\n",
      "Train Epoch: 9 [224000/906425] Loss: 2.112352 Acc: 0.5625\n",
      "Train Epoch: 9 [240000/906425] Loss: 1.355642 Acc: 0.6250\n",
      "Train Epoch: 9 [256000/906425] Loss: 1.643647 Acc: 0.5625\n",
      "Train Epoch: 9 [272000/906425] Loss: 2.311876 Acc: 0.3750\n",
      "Train Epoch: 9 [288000/906425] Loss: 1.704019 Acc: 0.6875\n",
      "Train Epoch: 9 [304000/906425] Loss: 1.925244 Acc: 0.5625\n",
      "Train Epoch: 9 [320000/906425] Loss: 1.165012 Acc: 0.6250\n",
      "Train Epoch: 9 [336000/906425] Loss: 1.441244 Acc: 0.6250\n",
      "Train Epoch: 9 [352000/906425] Loss: 1.517049 Acc: 0.7500\n",
      "Train Epoch: 9 [368000/906425] Loss: 1.563719 Acc: 0.6875\n",
      "Train Epoch: 9 [384000/906425] Loss: 2.398421 Acc: 0.5625\n",
      "Train Epoch: 9 [400000/906425] Loss: 2.761444 Acc: 0.4375\n",
      "Train Epoch: 9 [416000/906425] Loss: 3.222156 Acc: 0.2500\n",
      "Train Epoch: 9 [432000/906425] Loss: 1.911093 Acc: 0.5000\n",
      "Train Epoch: 9 [448000/906425] Loss: 2.015562 Acc: 0.4375\n",
      "Train Epoch: 9 [464000/906425] Loss: 1.459415 Acc: 0.6250\n",
      "Train Epoch: 9 [480000/906425] Loss: 1.630694 Acc: 0.5625\n",
      "Train Epoch: 9 [496000/906425] Loss: 2.772116 Acc: 0.3750\n",
      "Train Epoch: 9 [512000/906425] Loss: 2.943908 Acc: 0.3125\n",
      "Train Epoch: 9 [528000/906425] Loss: 3.174268 Acc: 0.4375\n",
      "Train Epoch: 9 [544000/906425] Loss: 2.532418 Acc: 0.5000\n",
      "Train Epoch: 9 [560000/906425] Loss: 2.228394 Acc: 0.4375\n",
      "Train Epoch: 9 [576000/906425] Loss: 3.316247 Acc: 0.2500\n",
      "Train Epoch: 9 [592000/906425] Loss: 1.434892 Acc: 0.5625\n",
      "Train Epoch: 9 [608000/906425] Loss: 1.821551 Acc: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [624000/906425] Loss: 1.999465 Acc: 0.6250\n",
      "Train Epoch: 9 [640000/906425] Loss: 1.584786 Acc: 0.6875\n",
      "Train Epoch: 9 [656000/906425] Loss: 1.715426 Acc: 0.5625\n",
      "Train Epoch: 9 [672000/906425] Loss: 1.362682 Acc: 0.6875\n",
      "Train Epoch: 9 [688000/906425] Loss: 1.518084 Acc: 0.5625\n",
      "Train Epoch: 9 [704000/906425] Loss: 2.016038 Acc: 0.6875\n",
      "Train Epoch: 9 [720000/906425] Loss: 1.232959 Acc: 0.7500\n",
      "Train Epoch: 9 [736000/906425] Loss: 2.606791 Acc: 0.4375\n",
      "Train Epoch: 9 [752000/906425] Loss: 2.057750 Acc: 0.4375\n",
      "Train Epoch: 9 [768000/906425] Loss: 1.271164 Acc: 0.6875\n",
      "Train Epoch: 9 [784000/906425] Loss: 2.670419 Acc: 0.5000\n",
      "Train Epoch: 9 [800000/906425] Loss: 2.135613 Acc: 0.5000\n",
      "Train Epoch: 9 [816000/906425] Loss: 2.254681 Acc: 0.5000\n",
      "Train Epoch: 9 [832000/906425] Loss: 1.657295 Acc: 0.5625\n",
      "Train Epoch: 9 [848000/906425] Loss: 2.587605 Acc: 0.5000\n",
      "Train Epoch: 9 [864000/906425] Loss: 2.019003 Acc: 0.6250\n",
      "Train Epoch: 9 [880000/906425] Loss: 1.512450 Acc: 0.6250\n",
      "Train Epoch: 9 [896000/906425] Loss: 2.006456 Acc: 0.6250\n",
      "Elapsed 5709.73s, 570.97 s/epoch, 0.01 s/batch, ets 22838.90s\n",
      "\n",
      "Test set: Average loss: 2.0203, Accuracy: 166615/293785 (57%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 10 [16000/906425] Loss: 1.596691 Acc: 0.6875\n",
      "Train Epoch: 10 [32000/906425] Loss: 1.831113 Acc: 0.5000\n",
      "Train Epoch: 10 [48000/906425] Loss: 1.120512 Acc: 0.6875\n",
      "Train Epoch: 10 [64000/906425] Loss: 2.906051 Acc: 0.4375\n",
      "Train Epoch: 10 [80000/906425] Loss: 2.464772 Acc: 0.4375\n",
      "Train Epoch: 10 [96000/906425] Loss: 2.282740 Acc: 0.5000\n",
      "Train Epoch: 10 [112000/906425] Loss: 1.242689 Acc: 0.6250\n",
      "Train Epoch: 10 [128000/906425] Loss: 1.743715 Acc: 0.6875\n",
      "Train Epoch: 10 [144000/906425] Loss: 2.606937 Acc: 0.4375\n",
      "Train Epoch: 10 [160000/906425] Loss: 0.914698 Acc: 0.7500\n",
      "Train Epoch: 10 [176000/906425] Loss: 2.269611 Acc: 0.5625\n",
      "Train Epoch: 10 [192000/906425] Loss: 1.399389 Acc: 0.6250\n",
      "Train Epoch: 10 [208000/906425] Loss: 2.347305 Acc: 0.5625\n",
      "Train Epoch: 10 [224000/906425] Loss: 2.070966 Acc: 0.5000\n",
      "Train Epoch: 10 [240000/906425] Loss: 2.236787 Acc: 0.5625\n",
      "Train Epoch: 10 [256000/906425] Loss: 2.264006 Acc: 0.4375\n",
      "Train Epoch: 10 [272000/906425] Loss: 2.380696 Acc: 0.4375\n",
      "Train Epoch: 10 [288000/906425] Loss: 1.684702 Acc: 0.6250\n",
      "Train Epoch: 10 [304000/906425] Loss: 1.029866 Acc: 0.6875\n",
      "Train Epoch: 10 [320000/906425] Loss: 2.640499 Acc: 0.4375\n",
      "Train Epoch: 10 [336000/906425] Loss: 1.643343 Acc: 0.6250\n",
      "Train Epoch: 10 [352000/906425] Loss: 1.664184 Acc: 0.6250\n",
      "Train Epoch: 10 [368000/906425] Loss: 1.783222 Acc: 0.5625\n",
      "Train Epoch: 10 [384000/906425] Loss: 1.464040 Acc: 0.6250\n",
      "Train Epoch: 10 [400000/906425] Loss: 1.188270 Acc: 0.8125\n",
      "Train Epoch: 10 [416000/906425] Loss: 2.154006 Acc: 0.5000\n",
      "Train Epoch: 10 [432000/906425] Loss: 1.080027 Acc: 0.7500\n",
      "Train Epoch: 10 [448000/906425] Loss: 1.535892 Acc: 0.5000\n",
      "Train Epoch: 10 [464000/906425] Loss: 2.072293 Acc: 0.5625\n",
      "Train Epoch: 10 [480000/906425] Loss: 2.128018 Acc: 0.2500\n",
      "Train Epoch: 10 [496000/906425] Loss: 2.922884 Acc: 0.5000\n",
      "Train Epoch: 10 [512000/906425] Loss: 0.921009 Acc: 0.7500\n",
      "Train Epoch: 10 [528000/906425] Loss: 1.342088 Acc: 0.6875\n",
      "Train Epoch: 10 [544000/906425] Loss: 1.456560 Acc: 0.5625\n",
      "Train Epoch: 10 [560000/906425] Loss: 1.702560 Acc: 0.5625\n",
      "Train Epoch: 10 [576000/906425] Loss: 1.467173 Acc: 0.6875\n",
      "Train Epoch: 10 [592000/906425] Loss: 1.703927 Acc: 0.4375\n",
      "Train Epoch: 10 [608000/906425] Loss: 1.566354 Acc: 0.6875\n",
      "Train Epoch: 10 [624000/906425] Loss: 2.782735 Acc: 0.4375\n",
      "Train Epoch: 10 [640000/906425] Loss: 1.101560 Acc: 0.8125\n",
      "Train Epoch: 10 [656000/906425] Loss: 1.547085 Acc: 0.5000\n",
      "Train Epoch: 10 [672000/906425] Loss: 2.689384 Acc: 0.3750\n",
      "Train Epoch: 10 [688000/906425] Loss: 1.118458 Acc: 0.7500\n",
      "Train Epoch: 10 [704000/906425] Loss: 3.061594 Acc: 0.2500\n",
      "Train Epoch: 10 [720000/906425] Loss: 1.776544 Acc: 0.4375\n",
      "Train Epoch: 10 [736000/906425] Loss: 1.931089 Acc: 0.6875\n",
      "Train Epoch: 10 [752000/906425] Loss: 1.734709 Acc: 0.6875\n",
      "Train Epoch: 10 [768000/906425] Loss: 0.864097 Acc: 0.7500\n",
      "Train Epoch: 10 [784000/906425] Loss: 0.917601 Acc: 0.6875\n",
      "Train Epoch: 10 [800000/906425] Loss: 1.588364 Acc: 0.6875\n",
      "Train Epoch: 10 [816000/906425] Loss: 0.881469 Acc: 0.7500\n",
      "Train Epoch: 10 [832000/906425] Loss: 2.436453 Acc: 0.4375\n",
      "Train Epoch: 10 [848000/906425] Loss: 2.558965 Acc: 0.6250\n",
      "Train Epoch: 10 [864000/906425] Loss: 1.822734 Acc: 0.6250\n",
      "Train Epoch: 10 [880000/906425] Loss: 1.111880 Acc: 0.6250\n",
      "Train Epoch: 10 [896000/906425] Loss: 1.472941 Acc: 0.6875\n",
      "Elapsed 6288.44s, 571.68 s/epoch, 0.01 s/batch, ets 22295.39s\n",
      "\n",
      "Test set: Average loss: 1.9520, Accuracy: 170617/293785 (58%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 11 [16000/906425] Loss: 1.005785 Acc: 0.8125\n",
      "Train Epoch: 11 [32000/906425] Loss: 2.469226 Acc: 0.5625\n",
      "Train Epoch: 11 [48000/906425] Loss: 1.834931 Acc: 0.5625\n",
      "Train Epoch: 11 [64000/906425] Loss: 2.066171 Acc: 0.5000\n",
      "Train Epoch: 11 [80000/906425] Loss: 1.650999 Acc: 0.6250\n",
      "Train Epoch: 11 [96000/906425] Loss: 1.974105 Acc: 0.3750\n",
      "Train Epoch: 11 [112000/906425] Loss: 1.265817 Acc: 0.6875\n",
      "Train Epoch: 11 [128000/906425] Loss: 1.667571 Acc: 0.5625\n",
      "Train Epoch: 11 [144000/906425] Loss: 1.648952 Acc: 0.6250\n",
      "Train Epoch: 11 [160000/906425] Loss: 1.879445 Acc: 0.5625\n",
      "Train Epoch: 11 [176000/906425] Loss: 1.488019 Acc: 0.7500\n",
      "Train Epoch: 11 [192000/906425] Loss: 1.145565 Acc: 0.8125\n",
      "Train Epoch: 11 [208000/906425] Loss: 1.535980 Acc: 0.5625\n",
      "Train Epoch: 11 [224000/906425] Loss: 1.080834 Acc: 0.6875\n",
      "Train Epoch: 11 [240000/906425] Loss: 1.355847 Acc: 0.6875\n",
      "Train Epoch: 11 [256000/906425] Loss: 1.021860 Acc: 0.6250\n",
      "Train Epoch: 11 [272000/906425] Loss: 0.883215 Acc: 0.8125\n",
      "Train Epoch: 11 [288000/906425] Loss: 1.020053 Acc: 0.8125\n",
      "Train Epoch: 11 [304000/906425] Loss: 1.944295 Acc: 0.5625\n",
      "Train Epoch: 11 [320000/906425] Loss: 1.938096 Acc: 0.5625\n",
      "Train Epoch: 11 [336000/906425] Loss: 2.365509 Acc: 0.5000\n",
      "Train Epoch: 11 [352000/906425] Loss: 1.388905 Acc: 0.6250\n",
      "Train Epoch: 11 [368000/906425] Loss: 2.112232 Acc: 0.5000\n",
      "Train Epoch: 11 [384000/906425] Loss: 1.347141 Acc: 0.6875\n",
      "Train Epoch: 11 [400000/906425] Loss: 3.762496 Acc: 0.2500\n",
      "Train Epoch: 11 [416000/906425] Loss: 1.390447 Acc: 0.6875\n",
      "Train Epoch: 11 [432000/906425] Loss: 2.205657 Acc: 0.5000\n",
      "Train Epoch: 11 [448000/906425] Loss: 2.511489 Acc: 0.5625\n",
      "Train Epoch: 11 [464000/906425] Loss: 1.151837 Acc: 0.6250\n",
      "Train Epoch: 11 [480000/906425] Loss: 1.200468 Acc: 0.7500\n",
      "Train Epoch: 11 [496000/906425] Loss: 2.726426 Acc: 0.3125\n",
      "Train Epoch: 11 [512000/906425] Loss: 1.757000 Acc: 0.6875\n",
      "Train Epoch: 11 [528000/906425] Loss: 1.229806 Acc: 0.6250\n",
      "Train Epoch: 11 [544000/906425] Loss: 1.033358 Acc: 0.8125\n",
      "Train Epoch: 11 [560000/906425] Loss: 1.839047 Acc: 0.5000\n",
      "Train Epoch: 11 [576000/906425] Loss: 0.947324 Acc: 0.6875\n",
      "Train Epoch: 11 [592000/906425] Loss: 1.079389 Acc: 0.8125\n",
      "Train Epoch: 11 [608000/906425] Loss: 1.268433 Acc: 0.6875\n",
      "Train Epoch: 11 [624000/906425] Loss: 1.506013 Acc: 0.6875\n",
      "Train Epoch: 11 [640000/906425] Loss: 1.973595 Acc: 0.5625\n",
      "Train Epoch: 11 [656000/906425] Loss: 1.142151 Acc: 0.6875\n",
      "Train Epoch: 11 [672000/906425] Loss: 1.168467 Acc: 0.7500\n",
      "Train Epoch: 11 [688000/906425] Loss: 2.273447 Acc: 0.5625\n",
      "Train Epoch: 11 [704000/906425] Loss: 1.694707 Acc: 0.6250\n",
      "Train Epoch: 11 [720000/906425] Loss: 2.024182 Acc: 0.5625\n",
      "Train Epoch: 11 [736000/906425] Loss: 1.769191 Acc: 0.5000\n",
      "Train Epoch: 11 [752000/906425] Loss: 2.184963 Acc: 0.5000\n",
      "Train Epoch: 11 [768000/906425] Loss: 1.505812 Acc: 0.5625\n",
      "Train Epoch: 11 [784000/906425] Loss: 2.352096 Acc: 0.4375\n",
      "Train Epoch: 11 [800000/906425] Loss: 1.881248 Acc: 0.5625\n",
      "Train Epoch: 11 [816000/906425] Loss: 1.646918 Acc: 0.5000\n",
      "Train Epoch: 11 [832000/906425] Loss: 2.429503 Acc: 0.4375\n",
      "Train Epoch: 11 [848000/906425] Loss: 1.035838 Acc: 0.8750\n",
      "Train Epoch: 11 [864000/906425] Loss: 1.700377 Acc: 0.6250\n",
      "Train Epoch: 11 [880000/906425] Loss: 1.329793 Acc: 0.6875\n",
      "Train Epoch: 11 [896000/906425] Loss: 1.463140 Acc: 0.7500\n",
      "Elapsed 6866.91s, 572.24 s/epoch, 0.01 s/batch, ets 21745.22s\n",
      "\n",
      "Test set: Average loss: 1.8975, Accuracy: 173159/293785 (59%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 12 [16000/906425] Loss: 2.064637 Acc: 0.5625\n",
      "Train Epoch: 12 [32000/906425] Loss: 1.434577 Acc: 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [48000/906425] Loss: 1.570056 Acc: 0.6250\n",
      "Train Epoch: 12 [64000/906425] Loss: 1.543611 Acc: 0.6250\n",
      "Train Epoch: 12 [80000/906425] Loss: 0.713555 Acc: 0.8125\n",
      "Train Epoch: 12 [96000/906425] Loss: 2.208194 Acc: 0.3750\n",
      "Train Epoch: 12 [112000/906425] Loss: 0.866841 Acc: 0.7500\n",
      "Train Epoch: 12 [128000/906425] Loss: 1.958547 Acc: 0.5625\n",
      "Train Epoch: 12 [144000/906425] Loss: 1.911539 Acc: 0.6250\n",
      "Train Epoch: 12 [160000/906425] Loss: 1.561190 Acc: 0.5625\n",
      "Train Epoch: 12 [176000/906425] Loss: 1.181630 Acc: 0.5000\n",
      "Train Epoch: 12 [192000/906425] Loss: 1.597079 Acc: 0.6250\n",
      "Train Epoch: 12 [208000/906425] Loss: 1.491073 Acc: 0.6875\n",
      "Train Epoch: 12 [224000/906425] Loss: 1.049982 Acc: 0.8750\n",
      "Train Epoch: 12 [240000/906425] Loss: 1.700780 Acc: 0.6250\n",
      "Train Epoch: 12 [256000/906425] Loss: 2.501415 Acc: 0.6875\n",
      "Train Epoch: 12 [272000/906425] Loss: 1.072501 Acc: 0.6875\n",
      "Train Epoch: 12 [288000/906425] Loss: 1.578200 Acc: 0.5625\n",
      "Train Epoch: 12 [304000/906425] Loss: 1.222769 Acc: 0.8750\n",
      "Train Epoch: 12 [320000/906425] Loss: 1.731363 Acc: 0.5625\n",
      "Train Epoch: 12 [336000/906425] Loss: 1.839159 Acc: 0.5625\n",
      "Train Epoch: 12 [352000/906425] Loss: 1.519253 Acc: 0.6250\n",
      "Train Epoch: 12 [368000/906425] Loss: 1.640570 Acc: 0.5625\n",
      "Train Epoch: 12 [384000/906425] Loss: 1.376280 Acc: 0.5625\n",
      "Train Epoch: 12 [400000/906425] Loss: 1.730252 Acc: 0.6250\n",
      "Train Epoch: 12 [416000/906425] Loss: 2.790443 Acc: 0.4375\n",
      "Train Epoch: 12 [432000/906425] Loss: 2.379285 Acc: 0.5625\n",
      "Train Epoch: 12 [448000/906425] Loss: 1.855625 Acc: 0.6250\n",
      "Train Epoch: 12 [464000/906425] Loss: 1.390633 Acc: 0.5625\n",
      "Train Epoch: 12 [480000/906425] Loss: 1.724123 Acc: 0.6875\n",
      "Train Epoch: 12 [496000/906425] Loss: 1.671726 Acc: 0.6250\n",
      "Train Epoch: 12 [512000/906425] Loss: 1.077458 Acc: 0.6250\n",
      "Train Epoch: 12 [528000/906425] Loss: 1.096925 Acc: 0.6875\n",
      "Train Epoch: 12 [544000/906425] Loss: 1.775804 Acc: 0.5000\n",
      "Train Epoch: 12 [560000/906425] Loss: 0.699854 Acc: 0.8750\n",
      "Train Epoch: 12 [576000/906425] Loss: 1.932651 Acc: 0.5625\n",
      "Train Epoch: 12 [592000/906425] Loss: 1.795251 Acc: 0.6250\n",
      "Train Epoch: 12 [608000/906425] Loss: 1.818018 Acc: 0.5000\n",
      "Train Epoch: 12 [624000/906425] Loss: 1.179512 Acc: 0.7500\n",
      "Train Epoch: 12 [640000/906425] Loss: 1.206680 Acc: 0.7500\n",
      "Train Epoch: 12 [656000/906425] Loss: 1.560312 Acc: 0.5625\n",
      "Train Epoch: 12 [672000/906425] Loss: 2.218701 Acc: 0.3750\n",
      "Train Epoch: 12 [688000/906425] Loss: 0.750575 Acc: 0.8125\n",
      "Train Epoch: 12 [704000/906425] Loss: 1.406762 Acc: 0.5625\n",
      "Train Epoch: 12 [720000/906425] Loss: 0.898873 Acc: 0.8125\n",
      "Train Epoch: 12 [736000/906425] Loss: 2.632282 Acc: 0.4375\n",
      "Train Epoch: 12 [752000/906425] Loss: 0.986201 Acc: 0.8125\n",
      "Train Epoch: 12 [768000/906425] Loss: 1.633951 Acc: 0.6250\n",
      "Train Epoch: 12 [784000/906425] Loss: 1.664836 Acc: 0.5625\n",
      "Train Epoch: 12 [800000/906425] Loss: 2.547923 Acc: 0.3750\n",
      "Train Epoch: 12 [816000/906425] Loss: 2.207407 Acc: 0.6875\n",
      "Train Epoch: 12 [832000/906425] Loss: 1.825245 Acc: 0.5000\n",
      "Train Epoch: 12 [848000/906425] Loss: 2.123697 Acc: 0.4375\n",
      "Train Epoch: 12 [864000/906425] Loss: 1.942516 Acc: 0.4375\n",
      "Train Epoch: 12 [880000/906425] Loss: 0.944855 Acc: 0.7500\n",
      "Train Epoch: 12 [896000/906425] Loss: 2.600180 Acc: 0.3750\n",
      "Elapsed 7445.07s, 572.70 s/epoch, 0.01 s/batch, ets 21189.81s\n",
      "\n",
      "Test set: Average loss: 1.8057, Accuracy: 177946/293785 (61%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 13 [16000/906425] Loss: 2.330554 Acc: 0.5625\n",
      "Train Epoch: 13 [32000/906425] Loss: 1.139805 Acc: 0.7500\n",
      "Train Epoch: 13 [48000/906425] Loss: 2.304980 Acc: 0.5625\n",
      "Train Epoch: 13 [64000/906425] Loss: 0.869258 Acc: 0.8125\n",
      "Train Epoch: 13 [80000/906425] Loss: 1.064505 Acc: 0.6250\n",
      "Train Epoch: 13 [96000/906425] Loss: 1.043541 Acc: 0.8750\n",
      "Train Epoch: 13 [112000/906425] Loss: 1.177710 Acc: 0.7500\n",
      "Train Epoch: 13 [128000/906425] Loss: 0.819407 Acc: 0.6875\n",
      "Train Epoch: 13 [144000/906425] Loss: 1.327468 Acc: 0.7500\n",
      "Train Epoch: 13 [160000/906425] Loss: 1.774276 Acc: 0.5625\n",
      "Train Epoch: 13 [176000/906425] Loss: 1.502020 Acc: 0.5000\n",
      "Train Epoch: 13 [192000/906425] Loss: 1.362997 Acc: 0.6875\n",
      "Train Epoch: 13 [208000/906425] Loss: 1.791463 Acc: 0.5625\n",
      "Train Epoch: 13 [224000/906425] Loss: 1.177229 Acc: 0.8125\n",
      "Train Epoch: 13 [240000/906425] Loss: 1.617319 Acc: 0.6250\n",
      "Train Epoch: 13 [256000/906425] Loss: 0.557551 Acc: 0.8125\n",
      "Train Epoch: 13 [272000/906425] Loss: 2.868928 Acc: 0.3750\n",
      "Train Epoch: 13 [288000/906425] Loss: 1.232674 Acc: 0.6875\n",
      "Train Epoch: 13 [304000/906425] Loss: 1.637015 Acc: 0.4375\n",
      "Train Epoch: 13 [320000/906425] Loss: 1.321216 Acc: 0.7500\n",
      "Train Epoch: 13 [336000/906425] Loss: 0.652530 Acc: 0.8750\n",
      "Train Epoch: 13 [352000/906425] Loss: 1.497082 Acc: 0.6250\n",
      "Train Epoch: 13 [368000/906425] Loss: 1.492261 Acc: 0.5625\n",
      "Train Epoch: 13 [384000/906425] Loss: 2.057824 Acc: 0.5000\n",
      "Train Epoch: 13 [400000/906425] Loss: 1.283700 Acc: 0.6250\n",
      "Train Epoch: 13 [416000/906425] Loss: 1.545682 Acc: 0.6250\n",
      "Train Epoch: 13 [432000/906425] Loss: 2.669357 Acc: 0.4375\n",
      "Train Epoch: 13 [448000/906425] Loss: 1.230871 Acc: 0.6250\n",
      "Train Epoch: 13 [464000/906425] Loss: 1.355114 Acc: 0.6250\n",
      "Train Epoch: 13 [480000/906425] Loss: 1.451910 Acc: 0.6875\n",
      "Train Epoch: 13 [496000/906425] Loss: 1.969008 Acc: 0.5000\n",
      "Train Epoch: 13 [512000/906425] Loss: 0.833168 Acc: 0.8125\n",
      "Train Epoch: 13 [528000/906425] Loss: 0.984201 Acc: 0.6250\n",
      "Train Epoch: 13 [544000/906425] Loss: 1.315879 Acc: 0.6875\n",
      "Train Epoch: 13 [560000/906425] Loss: 0.733815 Acc: 0.8125\n",
      "Train Epoch: 13 [576000/906425] Loss: 1.255244 Acc: 0.6250\n",
      "Train Epoch: 13 [592000/906425] Loss: 1.289592 Acc: 0.7500\n",
      "Train Epoch: 13 [608000/906425] Loss: 1.624636 Acc: 0.6250\n",
      "Train Epoch: 13 [624000/906425] Loss: 1.897720 Acc: 0.6250\n",
      "Train Epoch: 13 [640000/906425] Loss: 1.838352 Acc: 0.6250\n",
      "Train Epoch: 13 [656000/906425] Loss: 1.424716 Acc: 0.5000\n",
      "Train Epoch: 13 [672000/906425] Loss: 1.019585 Acc: 0.7500\n",
      "Train Epoch: 13 [688000/906425] Loss: 1.753810 Acc: 0.5000\n",
      "Train Epoch: 13 [704000/906425] Loss: 1.462387 Acc: 0.7500\n",
      "Train Epoch: 13 [720000/906425] Loss: 1.472148 Acc: 0.6875\n",
      "Train Epoch: 13 [736000/906425] Loss: 1.229127 Acc: 0.6250\n",
      "Train Epoch: 13 [752000/906425] Loss: 1.729724 Acc: 0.5625\n",
      "Train Epoch: 13 [768000/906425] Loss: 0.956024 Acc: 0.8125\n",
      "Train Epoch: 13 [784000/906425] Loss: 1.629655 Acc: 0.5000\n",
      "Train Epoch: 13 [800000/906425] Loss: 1.738827 Acc: 0.7500\n",
      "Train Epoch: 13 [816000/906425] Loss: 3.008569 Acc: 0.5000\n",
      "Train Epoch: 13 [832000/906425] Loss: 1.593475 Acc: 0.6875\n",
      "Train Epoch: 13 [848000/906425] Loss: 2.347685 Acc: 0.5000\n",
      "Train Epoch: 13 [864000/906425] Loss: 2.162529 Acc: 0.5625\n",
      "Train Epoch: 13 [880000/906425] Loss: 1.435145 Acc: 0.5625\n",
      "Train Epoch: 13 [896000/906425] Loss: 1.890940 Acc: 0.4375\n",
      "Elapsed 8023.26s, 573.09 s/epoch, 0.01 s/batch, ets 20631.24s\n",
      "\n",
      "Test set: Average loss: 1.8005, Accuracy: 178055/293785 (61%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 14 [16000/906425] Loss: 1.198072 Acc: 0.7500\n",
      "Train Epoch: 14 [32000/906425] Loss: 2.083945 Acc: 0.6250\n",
      "Train Epoch: 14 [48000/906425] Loss: 2.794395 Acc: 0.5625\n",
      "Train Epoch: 14 [64000/906425] Loss: 1.257161 Acc: 0.5000\n",
      "Train Epoch: 14 [80000/906425] Loss: 0.961355 Acc: 0.7500\n",
      "Train Epoch: 14 [96000/906425] Loss: 0.946984 Acc: 0.6875\n",
      "Train Epoch: 14 [112000/906425] Loss: 1.749161 Acc: 0.5625\n",
      "Train Epoch: 14 [128000/906425] Loss: 1.343482 Acc: 0.6875\n",
      "Train Epoch: 14 [144000/906425] Loss: 2.310934 Acc: 0.6250\n",
      "Train Epoch: 14 [160000/906425] Loss: 1.160142 Acc: 0.6875\n",
      "Train Epoch: 14 [176000/906425] Loss: 1.592762 Acc: 0.5000\n",
      "Train Epoch: 14 [192000/906425] Loss: 1.379166 Acc: 0.6875\n",
      "Train Epoch: 14 [208000/906425] Loss: 1.373857 Acc: 0.5625\n",
      "Train Epoch: 14 [224000/906425] Loss: 1.251753 Acc: 0.7500\n",
      "Train Epoch: 14 [240000/906425] Loss: 1.259723 Acc: 0.6250\n",
      "Train Epoch: 14 [256000/906425] Loss: 1.104335 Acc: 0.7500\n",
      "Train Epoch: 14 [272000/906425] Loss: 1.942843 Acc: 0.4375\n",
      "Train Epoch: 14 [288000/906425] Loss: 0.978671 Acc: 0.6875\n",
      "Train Epoch: 14 [304000/906425] Loss: 1.680425 Acc: 0.5625\n",
      "Train Epoch: 14 [320000/906425] Loss: 1.540854 Acc: 0.5000\n",
      "Train Epoch: 14 [336000/906425] Loss: 1.489464 Acc: 0.6875\n",
      "Train Epoch: 14 [352000/906425] Loss: 1.883180 Acc: 0.5625\n",
      "Train Epoch: 14 [368000/906425] Loss: 1.764786 Acc: 0.6875\n",
      "Train Epoch: 14 [384000/906425] Loss: 0.826735 Acc: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [400000/906425] Loss: 1.949379 Acc: 0.5625\n",
      "Train Epoch: 14 [416000/906425] Loss: 1.625577 Acc: 0.6250\n",
      "Train Epoch: 14 [432000/906425] Loss: 1.098002 Acc: 0.8125\n",
      "Train Epoch: 14 [448000/906425] Loss: 2.305923 Acc: 0.3125\n",
      "Train Epoch: 14 [464000/906425] Loss: 1.024358 Acc: 0.7500\n",
      "Train Epoch: 14 [480000/906425] Loss: 1.449660 Acc: 0.5625\n",
      "Train Epoch: 14 [496000/906425] Loss: 1.212571 Acc: 0.6250\n",
      "Train Epoch: 14 [512000/906425] Loss: 1.368708 Acc: 0.7500\n",
      "Train Epoch: 14 [528000/906425] Loss: 1.208069 Acc: 0.6250\n",
      "Train Epoch: 14 [544000/906425] Loss: 1.605264 Acc: 0.6250\n",
      "Train Epoch: 14 [560000/906425] Loss: 2.359552 Acc: 0.5000\n",
      "Train Epoch: 14 [576000/906425] Loss: 1.862051 Acc: 0.6250\n",
      "Train Epoch: 14 [592000/906425] Loss: 1.159474 Acc: 0.5625\n",
      "Train Epoch: 14 [608000/906425] Loss: 1.985770 Acc: 0.4375\n",
      "Train Epoch: 14 [624000/906425] Loss: 1.596869 Acc: 0.6875\n",
      "Train Epoch: 14 [640000/906425] Loss: 1.234006 Acc: 0.7500\n",
      "Train Epoch: 14 [656000/906425] Loss: 0.891678 Acc: 0.6250\n",
      "Train Epoch: 14 [672000/906425] Loss: 1.168294 Acc: 0.6875\n",
      "Train Epoch: 14 [688000/906425] Loss: 1.285014 Acc: 0.8125\n",
      "Train Epoch: 14 [704000/906425] Loss: 1.141578 Acc: 0.7500\n",
      "Train Epoch: 14 [720000/906425] Loss: 1.910682 Acc: 0.8125\n",
      "Train Epoch: 14 [736000/906425] Loss: 1.200940 Acc: 0.8750\n",
      "Train Epoch: 14 [752000/906425] Loss: 1.128024 Acc: 0.8125\n",
      "Train Epoch: 14 [768000/906425] Loss: 1.526274 Acc: 0.7500\n",
      "Train Epoch: 14 [784000/906425] Loss: 1.523626 Acc: 0.6875\n",
      "Train Epoch: 14 [800000/906425] Loss: 0.842295 Acc: 0.8125\n",
      "Train Epoch: 14 [816000/906425] Loss: 1.488059 Acc: 0.6250\n",
      "Train Epoch: 14 [832000/906425] Loss: 0.967340 Acc: 0.7500\n",
      "Train Epoch: 14 [848000/906425] Loss: 0.874756 Acc: 0.7500\n",
      "Train Epoch: 14 [864000/906425] Loss: 1.996771 Acc: 0.5625\n",
      "Train Epoch: 14 [880000/906425] Loss: 1.323675 Acc: 0.5000\n",
      "Train Epoch: 14 [896000/906425] Loss: 1.512329 Acc: 0.7500\n",
      "Elapsed 8602.06s, 573.47 s/epoch, 0.01 s/batch, ets 20071.46s\n",
      "\n",
      "Test set: Average loss: 1.7251, Accuracy: 182483/293785 (62%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 15 [16000/906425] Loss: 1.403541 Acc: 0.6250\n",
      "Train Epoch: 15 [32000/906425] Loss: 1.143597 Acc: 0.6250\n",
      "Train Epoch: 15 [48000/906425] Loss: 1.336227 Acc: 0.6875\n",
      "Train Epoch: 15 [64000/906425] Loss: 2.420322 Acc: 0.4375\n",
      "Train Epoch: 15 [80000/906425] Loss: 1.017526 Acc: 0.6875\n",
      "Train Epoch: 15 [96000/906425] Loss: 1.567519 Acc: 0.6875\n",
      "Train Epoch: 15 [112000/906425] Loss: 2.120541 Acc: 0.5625\n",
      "Train Epoch: 15 [128000/906425] Loss: 1.610039 Acc: 0.6875\n",
      "Train Epoch: 15 [144000/906425] Loss: 1.080780 Acc: 0.6250\n",
      "Train Epoch: 15 [160000/906425] Loss: 1.357924 Acc: 0.5625\n",
      "Train Epoch: 15 [176000/906425] Loss: 1.310099 Acc: 0.7500\n",
      "Train Epoch: 15 [192000/906425] Loss: 0.995866 Acc: 0.6875\n",
      "Train Epoch: 15 [208000/906425] Loss: 0.923939 Acc: 0.7500\n",
      "Train Epoch: 15 [224000/906425] Loss: 2.595933 Acc: 0.5625\n",
      "Train Epoch: 15 [240000/906425] Loss: 1.421005 Acc: 0.6875\n",
      "Train Epoch: 15 [256000/906425] Loss: 2.759346 Acc: 0.3750\n",
      "Train Epoch: 15 [272000/906425] Loss: 1.696495 Acc: 0.5625\n",
      "Train Epoch: 15 [288000/906425] Loss: 1.938877 Acc: 0.5625\n",
      "Train Epoch: 15 [304000/906425] Loss: 1.547524 Acc: 0.6250\n",
      "Train Epoch: 15 [320000/906425] Loss: 1.039094 Acc: 0.8125\n",
      "Train Epoch: 15 [336000/906425] Loss: 1.099723 Acc: 0.6875\n",
      "Train Epoch: 15 [352000/906425] Loss: 0.969064 Acc: 0.6250\n",
      "Train Epoch: 15 [368000/906425] Loss: 1.448918 Acc: 0.6875\n",
      "Train Epoch: 15 [384000/906425] Loss: 1.355295 Acc: 0.8125\n",
      "Train Epoch: 15 [400000/906425] Loss: 1.097162 Acc: 0.8125\n",
      "Train Epoch: 15 [416000/906425] Loss: 1.190738 Acc: 0.6250\n",
      "Train Epoch: 15 [432000/906425] Loss: 2.243754 Acc: 0.4375\n",
      "Train Epoch: 15 [448000/906425] Loss: 1.434465 Acc: 0.5625\n",
      "Train Epoch: 15 [464000/906425] Loss: 1.687146 Acc: 0.6875\n",
      "Train Epoch: 15 [480000/906425] Loss: 1.112740 Acc: 0.6875\n",
      "Train Epoch: 15 [496000/906425] Loss: 1.143100 Acc: 0.8125\n",
      "Train Epoch: 15 [512000/906425] Loss: 1.610695 Acc: 0.6250\n",
      "Train Epoch: 15 [528000/906425] Loss: 0.769181 Acc: 0.8125\n",
      "Train Epoch: 15 [544000/906425] Loss: 1.079113 Acc: 0.8125\n",
      "Train Epoch: 15 [560000/906425] Loss: 1.004455 Acc: 0.6875\n",
      "Train Epoch: 15 [576000/906425] Loss: 0.766245 Acc: 0.8125\n",
      "Train Epoch: 15 [592000/906425] Loss: 1.284092 Acc: 0.8125\n",
      "Train Epoch: 15 [608000/906425] Loss: 1.689262 Acc: 0.6250\n",
      "Train Epoch: 15 [624000/906425] Loss: 1.202857 Acc: 0.5625\n",
      "Train Epoch: 15 [640000/906425] Loss: 0.705514 Acc: 0.6875\n",
      "Train Epoch: 15 [656000/906425] Loss: 1.933816 Acc: 0.6250\n",
      "Train Epoch: 15 [672000/906425] Loss: 0.960652 Acc: 0.8125\n",
      "Train Epoch: 15 [688000/906425] Loss: 0.865508 Acc: 0.8125\n",
      "Train Epoch: 15 [704000/906425] Loss: 0.664446 Acc: 0.6875\n",
      "Train Epoch: 15 [720000/906425] Loss: 1.127441 Acc: 0.7500\n",
      "Train Epoch: 15 [736000/906425] Loss: 2.035925 Acc: 0.4375\n",
      "Train Epoch: 15 [752000/906425] Loss: 1.579960 Acc: 0.6250\n",
      "Train Epoch: 15 [768000/906425] Loss: 2.140481 Acc: 0.4375\n",
      "Train Epoch: 15 [784000/906425] Loss: 1.193253 Acc: 0.6250\n",
      "Train Epoch: 15 [800000/906425] Loss: 1.650075 Acc: 0.6875\n",
      "Train Epoch: 15 [816000/906425] Loss: 1.487859 Acc: 0.6250\n",
      "Train Epoch: 15 [832000/906425] Loss: 0.826330 Acc: 0.8125\n",
      "Train Epoch: 15 [848000/906425] Loss: 1.525797 Acc: 0.6875\n",
      "Train Epoch: 15 [864000/906425] Loss: 2.586320 Acc: 0.5625\n",
      "Train Epoch: 15 [880000/906425] Loss: 1.010314 Acc: 0.8125\n",
      "Train Epoch: 15 [896000/906425] Loss: 2.280517 Acc: 0.6250\n",
      "Elapsed 9180.88s, 573.81 s/epoch, 0.01 s/batch, ets 19509.37s\n",
      "\n",
      "Test set: Average loss: 1.6715, Accuracy: 186068/293785 (63%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 16 [16000/906425] Loss: 0.640475 Acc: 0.9375\n",
      "Train Epoch: 16 [32000/906425] Loss: 1.062605 Acc: 0.7500\n",
      "Train Epoch: 16 [48000/906425] Loss: 2.426037 Acc: 0.5625\n",
      "Train Epoch: 16 [64000/906425] Loss: 2.227970 Acc: 0.6250\n",
      "Train Epoch: 16 [80000/906425] Loss: 1.555340 Acc: 0.6250\n",
      "Train Epoch: 16 [96000/906425] Loss: 1.205715 Acc: 0.8125\n",
      "Train Epoch: 16 [112000/906425] Loss: 2.309568 Acc: 0.4375\n",
      "Train Epoch: 16 [128000/906425] Loss: 1.124785 Acc: 0.6250\n",
      "Train Epoch: 16 [144000/906425] Loss: 2.077930 Acc: 0.6250\n",
      "Train Epoch: 16 [160000/906425] Loss: 0.677373 Acc: 0.9375\n",
      "Train Epoch: 16 [176000/906425] Loss: 0.963333 Acc: 0.8125\n",
      "Train Epoch: 16 [192000/906425] Loss: 0.672718 Acc: 0.8125\n",
      "Train Epoch: 16 [208000/906425] Loss: 0.378091 Acc: 0.9375\n",
      "Train Epoch: 16 [224000/906425] Loss: 0.997468 Acc: 0.6875\n",
      "Train Epoch: 16 [240000/906425] Loss: 1.881875 Acc: 0.5625\n",
      "Train Epoch: 16 [256000/906425] Loss: 2.053895 Acc: 0.6875\n",
      "Train Epoch: 16 [272000/906425] Loss: 1.543013 Acc: 0.5000\n",
      "Train Epoch: 16 [288000/906425] Loss: 0.656538 Acc: 0.8125\n",
      "Train Epoch: 16 [304000/906425] Loss: 0.638956 Acc: 0.8125\n",
      "Train Epoch: 16 [320000/906425] Loss: 1.270464 Acc: 0.6875\n",
      "Train Epoch: 16 [336000/906425] Loss: 0.874269 Acc: 0.6875\n",
      "Train Epoch: 16 [352000/906425] Loss: 1.078737 Acc: 0.7500\n",
      "Train Epoch: 16 [368000/906425] Loss: 2.227051 Acc: 0.5000\n",
      "Train Epoch: 16 [384000/906425] Loss: 1.646034 Acc: 0.6875\n",
      "Train Epoch: 16 [400000/906425] Loss: 0.891977 Acc: 0.6875\n",
      "Train Epoch: 16 [416000/906425] Loss: 1.289797 Acc: 0.6250\n",
      "Train Epoch: 16 [432000/906425] Loss: 0.381595 Acc: 0.8750\n",
      "Train Epoch: 16 [448000/906425] Loss: 1.034570 Acc: 0.6875\n",
      "Train Epoch: 16 [464000/906425] Loss: 0.897820 Acc: 0.8750\n",
      "Train Epoch: 16 [480000/906425] Loss: 1.656241 Acc: 0.5000\n",
      "Train Epoch: 16 [496000/906425] Loss: 1.269077 Acc: 0.6875\n",
      "Train Epoch: 16 [512000/906425] Loss: 1.305120 Acc: 0.6250\n",
      "Train Epoch: 16 [528000/906425] Loss: 0.939881 Acc: 0.7500\n",
      "Train Epoch: 16 [544000/906425] Loss: 1.347944 Acc: 0.6250\n",
      "Train Epoch: 16 [560000/906425] Loss: 1.185265 Acc: 0.6875\n",
      "Train Epoch: 16 [576000/906425] Loss: 1.215813 Acc: 0.7500\n",
      "Train Epoch: 16 [592000/906425] Loss: 1.633499 Acc: 0.6875\n",
      "Train Epoch: 16 [608000/906425] Loss: 1.260148 Acc: 0.5000\n",
      "Train Epoch: 16 [624000/906425] Loss: 1.534614 Acc: 0.5625\n",
      "Train Epoch: 16 [640000/906425] Loss: 1.858028 Acc: 0.5625\n",
      "Train Epoch: 16 [656000/906425] Loss: 1.109493 Acc: 0.7500\n",
      "Train Epoch: 16 [672000/906425] Loss: 1.027748 Acc: 0.8125\n",
      "Train Epoch: 16 [688000/906425] Loss: 2.132051 Acc: 0.5000\n",
      "Train Epoch: 16 [704000/906425] Loss: 2.184319 Acc: 0.4375\n",
      "Train Epoch: 16 [720000/906425] Loss: 0.832609 Acc: 0.8750\n",
      "Train Epoch: 16 [736000/906425] Loss: 1.515316 Acc: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [752000/906425] Loss: 1.427644 Acc: 0.6250\n",
      "Train Epoch: 16 [768000/906425] Loss: 1.211284 Acc: 0.7500\n",
      "Train Epoch: 16 [784000/906425] Loss: 1.270027 Acc: 0.6250\n",
      "Train Epoch: 16 [800000/906425] Loss: 1.085451 Acc: 0.6875\n",
      "Train Epoch: 16 [816000/906425] Loss: 1.024084 Acc: 0.6875\n",
      "Train Epoch: 16 [832000/906425] Loss: 0.929859 Acc: 0.8125\n",
      "Train Epoch: 16 [848000/906425] Loss: 2.167490 Acc: 0.4375\n",
      "Train Epoch: 16 [864000/906425] Loss: 1.476087 Acc: 0.6250\n",
      "Train Epoch: 16 [880000/906425] Loss: 2.382259 Acc: 0.5000\n",
      "Train Epoch: 16 [896000/906425] Loss: 1.169785 Acc: 0.6875\n",
      "Elapsed 9759.39s, 574.08 s/epoch, 0.01 s/batch, ets 18944.71s\n",
      "\n",
      "Test set: Average loss: 1.6278, Accuracy: 188994/293785 (64%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 17 [16000/906425] Loss: 0.863783 Acc: 0.8125\n",
      "Train Epoch: 17 [32000/906425] Loss: 0.481827 Acc: 0.8750\n",
      "Train Epoch: 17 [48000/906425] Loss: 0.954319 Acc: 0.8125\n",
      "Train Epoch: 17 [64000/906425] Loss: 0.763421 Acc: 0.6875\n",
      "Train Epoch: 17 [80000/906425] Loss: 1.162223 Acc: 0.7500\n",
      "Train Epoch: 17 [96000/906425] Loss: 1.013252 Acc: 0.7500\n",
      "Train Epoch: 17 [112000/906425] Loss: 1.881813 Acc: 0.5625\n",
      "Train Epoch: 17 [128000/906425] Loss: 0.809072 Acc: 0.7500\n",
      "Train Epoch: 17 [144000/906425] Loss: 1.216617 Acc: 0.8125\n",
      "Train Epoch: 17 [160000/906425] Loss: 1.805783 Acc: 0.5625\n",
      "Train Epoch: 17 [176000/906425] Loss: 1.441131 Acc: 0.4375\n",
      "Train Epoch: 17 [192000/906425] Loss: 1.320705 Acc: 0.6250\n",
      "Train Epoch: 17 [208000/906425] Loss: 1.086438 Acc: 0.6875\n",
      "Train Epoch: 17 [224000/906425] Loss: 0.820510 Acc: 0.7500\n",
      "Train Epoch: 17 [240000/906425] Loss: 0.776383 Acc: 0.7500\n",
      "Train Epoch: 17 [256000/906425] Loss: 1.140073 Acc: 0.6875\n",
      "Train Epoch: 17 [272000/906425] Loss: 1.951097 Acc: 0.4375\n",
      "Train Epoch: 17 [288000/906425] Loss: 1.853054 Acc: 0.4375\n",
      "Train Epoch: 17 [304000/906425] Loss: 1.820342 Acc: 0.5625\n",
      "Train Epoch: 17 [320000/906425] Loss: 0.860087 Acc: 0.6875\n",
      "Train Epoch: 17 [336000/906425] Loss: 0.732559 Acc: 0.8750\n",
      "Train Epoch: 17 [352000/906425] Loss: 0.981510 Acc: 0.7500\n",
      "Train Epoch: 17 [368000/906425] Loss: 1.032808 Acc: 0.6875\n",
      "Train Epoch: 17 [384000/906425] Loss: 0.699833 Acc: 0.8750\n",
      "Train Epoch: 17 [400000/906425] Loss: 0.660482 Acc: 0.7500\n",
      "Train Epoch: 17 [416000/906425] Loss: 1.971333 Acc: 0.5625\n",
      "Train Epoch: 17 [432000/906425] Loss: 1.808931 Acc: 0.6875\n",
      "Train Epoch: 17 [448000/906425] Loss: 1.573880 Acc: 0.5000\n",
      "Train Epoch: 17 [464000/906425] Loss: 1.887354 Acc: 0.7500\n",
      "Train Epoch: 17 [480000/906425] Loss: 0.936556 Acc: 0.6875\n",
      "Train Epoch: 17 [496000/906425] Loss: 1.595425 Acc: 0.5000\n",
      "Train Epoch: 17 [512000/906425] Loss: 0.920894 Acc: 0.7500\n",
      "Train Epoch: 17 [528000/906425] Loss: 1.273868 Acc: 0.6250\n",
      "Train Epoch: 17 [544000/906425] Loss: 1.541264 Acc: 0.5625\n",
      "Train Epoch: 17 [560000/906425] Loss: 2.027887 Acc: 0.5625\n",
      "Train Epoch: 17 [576000/906425] Loss: 1.260645 Acc: 0.7500\n",
      "Train Epoch: 17 [592000/906425] Loss: 0.971898 Acc: 0.8125\n",
      "Train Epoch: 17 [608000/906425] Loss: 2.148434 Acc: 0.4375\n",
      "Train Epoch: 17 [624000/906425] Loss: 0.655547 Acc: 0.8750\n",
      "Train Epoch: 17 [640000/906425] Loss: 0.820906 Acc: 0.7500\n",
      "Train Epoch: 17 [656000/906425] Loss: 0.881987 Acc: 0.8125\n",
      "Train Epoch: 17 [672000/906425] Loss: 1.056308 Acc: 0.7500\n",
      "Train Epoch: 17 [688000/906425] Loss: 2.041474 Acc: 0.6250\n",
      "Train Epoch: 17 [704000/906425] Loss: 1.657390 Acc: 0.5625\n",
      "Train Epoch: 17 [720000/906425] Loss: 1.257525 Acc: 0.6250\n",
      "Train Epoch: 17 [736000/906425] Loss: 1.032733 Acc: 0.6250\n",
      "Train Epoch: 17 [752000/906425] Loss: 1.323693 Acc: 0.6875\n",
      "Train Epoch: 17 [768000/906425] Loss: 0.622738 Acc: 0.8750\n",
      "Train Epoch: 17 [784000/906425] Loss: 1.862165 Acc: 0.6250\n",
      "Train Epoch: 17 [800000/906425] Loss: 1.003456 Acc: 0.8125\n",
      "Train Epoch: 17 [816000/906425] Loss: 1.632954 Acc: 0.6875\n",
      "Train Epoch: 17 [832000/906425] Loss: 2.323774 Acc: 0.5625\n",
      "Train Epoch: 17 [848000/906425] Loss: 1.289248 Acc: 0.6250\n",
      "Train Epoch: 17 [864000/906425] Loss: 0.833707 Acc: 0.7500\n",
      "Train Epoch: 17 [880000/906425] Loss: 2.022157 Acc: 0.3750\n",
      "Train Epoch: 17 [896000/906425] Loss: 1.592246 Acc: 0.6250\n",
      "Elapsed 10338.36s, 574.35 s/epoch, 0.01 s/batch, ets 18379.31s\n",
      "\n",
      "Test set: Average loss: 1.6143, Accuracy: 190004/293785 (65%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 18 [16000/906425] Loss: 0.954870 Acc: 0.7500\n",
      "Train Epoch: 18 [32000/906425] Loss: 0.748936 Acc: 0.8125\n",
      "Train Epoch: 18 [48000/906425] Loss: 1.070806 Acc: 0.6875\n",
      "Train Epoch: 18 [64000/906425] Loss: 1.173554 Acc: 0.6875\n",
      "Train Epoch: 18 [80000/906425] Loss: 1.211065 Acc: 0.6250\n",
      "Train Epoch: 18 [96000/906425] Loss: 1.215214 Acc: 0.8125\n",
      "Train Epoch: 18 [112000/906425] Loss: 0.909910 Acc: 0.8125\n",
      "Train Epoch: 18 [128000/906425] Loss: 1.178313 Acc: 0.6875\n",
      "Train Epoch: 18 [144000/906425] Loss: 0.935484 Acc: 0.6875\n",
      "Train Epoch: 18 [160000/906425] Loss: 0.981677 Acc: 0.5625\n",
      "Train Epoch: 18 [176000/906425] Loss: 1.504609 Acc: 0.5625\n",
      "Train Epoch: 18 [192000/906425] Loss: 1.087176 Acc: 0.7500\n",
      "Train Epoch: 18 [208000/906425] Loss: 1.579781 Acc: 0.5625\n",
      "Train Epoch: 18 [224000/906425] Loss: 2.195612 Acc: 0.6250\n",
      "Train Epoch: 18 [240000/906425] Loss: 1.412930 Acc: 0.6875\n",
      "Train Epoch: 18 [256000/906425] Loss: 1.301801 Acc: 0.6250\n",
      "Train Epoch: 18 [272000/906425] Loss: 0.940849 Acc: 0.6875\n",
      "Train Epoch: 18 [288000/906425] Loss: 1.087988 Acc: 0.6250\n",
      "Train Epoch: 18 [304000/906425] Loss: 1.243074 Acc: 0.7500\n",
      "Train Epoch: 18 [320000/906425] Loss: 0.897801 Acc: 0.7500\n",
      "Train Epoch: 18 [336000/906425] Loss: 1.058180 Acc: 0.7500\n",
      "Train Epoch: 18 [352000/906425] Loss: 1.266070 Acc: 0.6250\n",
      "Train Epoch: 18 [368000/906425] Loss: 0.820627 Acc: 0.6250\n",
      "Train Epoch: 18 [384000/906425] Loss: 1.019489 Acc: 0.6250\n",
      "Train Epoch: 18 [400000/906425] Loss: 1.576939 Acc: 0.6250\n",
      "Train Epoch: 18 [416000/906425] Loss: 1.053118 Acc: 0.6250\n",
      "Train Epoch: 18 [432000/906425] Loss: 0.752509 Acc: 0.6875\n",
      "Train Epoch: 18 [448000/906425] Loss: 1.161150 Acc: 0.7500\n",
      "Train Epoch: 18 [464000/906425] Loss: 0.872779 Acc: 0.6875\n",
      "Train Epoch: 18 [480000/906425] Loss: 0.971143 Acc: 0.6875\n",
      "Train Epoch: 18 [496000/906425] Loss: 1.354394 Acc: 0.5625\n",
      "Train Epoch: 18 [512000/906425] Loss: 1.533029 Acc: 0.7500\n",
      "Train Epoch: 18 [528000/906425] Loss: 0.690158 Acc: 0.7500\n",
      "Train Epoch: 18 [544000/906425] Loss: 0.640795 Acc: 0.8750\n",
      "Train Epoch: 18 [560000/906425] Loss: 1.117512 Acc: 0.6875\n",
      "Train Epoch: 18 [576000/906425] Loss: 1.176550 Acc: 0.6875\n",
      "Train Epoch: 18 [592000/906425] Loss: 1.283110 Acc: 0.6250\n",
      "Train Epoch: 18 [608000/906425] Loss: 1.085958 Acc: 0.6250\n",
      "Train Epoch: 18 [624000/906425] Loss: 2.387984 Acc: 0.5000\n",
      "Train Epoch: 18 [640000/906425] Loss: 1.288837 Acc: 0.6250\n",
      "Train Epoch: 18 [656000/906425] Loss: 0.593178 Acc: 0.8750\n",
      "Train Epoch: 18 [672000/906425] Loss: 1.323377 Acc: 0.7500\n",
      "Train Epoch: 18 [688000/906425] Loss: 1.237184 Acc: 0.8125\n",
      "Train Epoch: 18 [704000/906425] Loss: 0.927847 Acc: 0.7500\n",
      "Train Epoch: 18 [720000/906425] Loss: 1.606973 Acc: 0.5625\n",
      "Train Epoch: 18 [736000/906425] Loss: 1.475176 Acc: 0.6875\n",
      "Train Epoch: 18 [752000/906425] Loss: 1.555768 Acc: 0.6875\n",
      "Train Epoch: 18 [768000/906425] Loss: 1.905588 Acc: 0.6875\n",
      "Train Epoch: 18 [784000/906425] Loss: 1.353401 Acc: 0.6250\n",
      "Train Epoch: 18 [800000/906425] Loss: 0.764646 Acc: 0.8125\n",
      "Train Epoch: 18 [816000/906425] Loss: 1.926933 Acc: 0.4375\n",
      "Train Epoch: 18 [832000/906425] Loss: 0.801072 Acc: 0.7500\n",
      "Train Epoch: 18 [848000/906425] Loss: 1.098876 Acc: 0.7500\n",
      "Train Epoch: 18 [864000/906425] Loss: 0.960677 Acc: 0.6875\n",
      "Train Epoch: 18 [880000/906425] Loss: 1.711515 Acc: 0.4375\n",
      "Train Epoch: 18 [896000/906425] Loss: 1.773259 Acc: 0.5625\n",
      "Elapsed 10917.13s, 574.59 s/epoch, 0.01 s/batch, ets 17812.16s\n",
      "\n",
      "Test set: Average loss: 1.6068, Accuracy: 190563/293785 (65%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 19 [16000/906425] Loss: 0.894326 Acc: 0.6875\n",
      "Train Epoch: 19 [32000/906425] Loss: 0.693614 Acc: 0.8750\n",
      "Train Epoch: 19 [48000/906425] Loss: 0.997914 Acc: 0.6875\n",
      "Train Epoch: 19 [64000/906425] Loss: 0.684480 Acc: 0.7500\n",
      "Train Epoch: 19 [80000/906425] Loss: 1.237768 Acc: 0.7500\n",
      "Train Epoch: 19 [96000/906425] Loss: 1.165509 Acc: 0.6875\n",
      "Train Epoch: 19 [112000/906425] Loss: 0.723971 Acc: 0.8750\n",
      "Train Epoch: 19 [128000/906425] Loss: 1.176505 Acc: 0.6250\n",
      "Train Epoch: 19 [144000/906425] Loss: 1.062334 Acc: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [160000/906425] Loss: 1.614864 Acc: 0.5000\n",
      "Train Epoch: 19 [176000/906425] Loss: 1.142356 Acc: 0.7500\n",
      "Train Epoch: 19 [192000/906425] Loss: 1.065521 Acc: 0.6250\n",
      "Train Epoch: 19 [208000/906425] Loss: 1.487500 Acc: 0.6875\n",
      "Train Epoch: 19 [224000/906425] Loss: 0.656476 Acc: 0.7500\n",
      "Train Epoch: 19 [240000/906425] Loss: 1.532922 Acc: 0.5000\n",
      "Train Epoch: 19 [256000/906425] Loss: 1.203478 Acc: 0.8125\n",
      "Train Epoch: 19 [272000/906425] Loss: 1.220850 Acc: 0.5625\n",
      "Train Epoch: 19 [288000/906425] Loss: 0.704680 Acc: 0.8125\n",
      "Train Epoch: 19 [304000/906425] Loss: 1.301394 Acc: 0.6875\n",
      "Train Epoch: 19 [320000/906425] Loss: 1.010945 Acc: 0.8125\n",
      "Train Epoch: 19 [336000/906425] Loss: 0.568646 Acc: 0.8125\n",
      "Train Epoch: 19 [352000/906425] Loss: 0.750595 Acc: 0.7500\n",
      "Train Epoch: 19 [368000/906425] Loss: 1.286197 Acc: 0.6875\n",
      "Train Epoch: 19 [384000/906425] Loss: 0.842657 Acc: 0.8750\n",
      "Train Epoch: 19 [400000/906425] Loss: 0.976295 Acc: 0.6875\n",
      "Train Epoch: 19 [416000/906425] Loss: 1.237879 Acc: 0.7500\n",
      "Train Epoch: 19 [432000/906425] Loss: 0.654243 Acc: 0.8750\n",
      "Train Epoch: 19 [448000/906425] Loss: 0.682832 Acc: 0.8125\n",
      "Train Epoch: 19 [464000/906425] Loss: 1.558899 Acc: 0.6250\n",
      "Train Epoch: 19 [480000/906425] Loss: 1.507908 Acc: 0.6875\n",
      "Train Epoch: 19 [496000/906425] Loss: 2.743193 Acc: 0.4375\n",
      "Train Epoch: 19 [512000/906425] Loss: 0.475122 Acc: 0.8750\n",
      "Train Epoch: 19 [528000/906425] Loss: 1.120978 Acc: 0.6875\n",
      "Train Epoch: 19 [544000/906425] Loss: 1.248271 Acc: 0.6875\n",
      "Train Epoch: 19 [560000/906425] Loss: 1.406378 Acc: 0.6250\n",
      "Train Epoch: 19 [576000/906425] Loss: 1.048177 Acc: 0.7500\n",
      "Train Epoch: 19 [592000/906425] Loss: 0.685034 Acc: 0.8125\n",
      "Train Epoch: 19 [608000/906425] Loss: 1.134330 Acc: 0.6875\n",
      "Train Epoch: 19 [624000/906425] Loss: 0.969835 Acc: 0.6250\n",
      "Train Epoch: 19 [640000/906425] Loss: 1.425733 Acc: 0.6250\n",
      "Train Epoch: 19 [656000/906425] Loss: 1.267711 Acc: 0.6875\n",
      "Train Epoch: 19 [672000/906425] Loss: 1.160209 Acc: 0.6875\n",
      "Train Epoch: 19 [688000/906425] Loss: 2.118630 Acc: 0.5625\n",
      "Train Epoch: 19 [704000/906425] Loss: 0.980677 Acc: 0.6875\n",
      "Train Epoch: 19 [720000/906425] Loss: 0.925637 Acc: 0.7500\n",
      "Train Epoch: 19 [736000/906425] Loss: 1.709149 Acc: 0.5625\n",
      "Train Epoch: 19 [752000/906425] Loss: 0.957204 Acc: 0.8125\n",
      "Train Epoch: 19 [768000/906425] Loss: 1.722916 Acc: 0.6250\n",
      "Train Epoch: 19 [784000/906425] Loss: 0.578871 Acc: 0.8125\n",
      "Train Epoch: 19 [800000/906425] Loss: 0.762844 Acc: 0.8750\n",
      "Train Epoch: 19 [816000/906425] Loss: 0.693625 Acc: 0.8125\n",
      "Train Epoch: 19 [832000/906425] Loss: 0.987485 Acc: 0.8125\n",
      "Train Epoch: 19 [848000/906425] Loss: 1.632832 Acc: 0.6875\n",
      "Train Epoch: 19 [864000/906425] Loss: 1.955971 Acc: 0.5625\n",
      "Train Epoch: 19 [880000/906425] Loss: 1.448889 Acc: 0.7500\n",
      "Train Epoch: 19 [896000/906425] Loss: 1.401085 Acc: 0.7500\n",
      "Elapsed 11495.83s, 574.79 s/epoch, 0.01 s/batch, ets 17243.74s\n",
      "\n",
      "Test set: Average loss: 1.5895, Accuracy: 191670/293785 (65%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 20 [16000/906425] Loss: 0.679055 Acc: 0.7500\n",
      "Train Epoch: 20 [32000/906425] Loss: 0.956591 Acc: 0.8125\n",
      "Train Epoch: 20 [48000/906425] Loss: 1.543840 Acc: 0.5625\n",
      "Train Epoch: 20 [64000/906425] Loss: 1.727287 Acc: 0.5625\n",
      "Train Epoch: 20 [80000/906425] Loss: 0.338654 Acc: 0.8750\n",
      "Train Epoch: 20 [96000/906425] Loss: 1.461001 Acc: 0.6250\n",
      "Train Epoch: 20 [112000/906425] Loss: 0.778111 Acc: 0.8125\n",
      "Train Epoch: 20 [128000/906425] Loss: 0.752435 Acc: 0.8125\n",
      "Train Epoch: 20 [144000/906425] Loss: 1.233968 Acc: 0.6250\n",
      "Train Epoch: 20 [160000/906425] Loss: 0.808748 Acc: 0.7500\n",
      "Train Epoch: 20 [176000/906425] Loss: 0.844039 Acc: 0.7500\n",
      "Train Epoch: 20 [192000/906425] Loss: 0.620837 Acc: 0.8125\n",
      "Train Epoch: 20 [208000/906425] Loss: 0.565368 Acc: 0.8750\n",
      "Train Epoch: 20 [224000/906425] Loss: 0.959931 Acc: 0.8750\n",
      "Train Epoch: 20 [240000/906425] Loss: 0.746350 Acc: 0.8125\n",
      "Train Epoch: 20 [256000/906425] Loss: 1.178235 Acc: 0.6250\n",
      "Train Epoch: 20 [272000/906425] Loss: 1.058517 Acc: 0.7500\n",
      "Train Epoch: 20 [288000/906425] Loss: 1.176074 Acc: 0.6250\n",
      "Train Epoch: 20 [304000/906425] Loss: 2.066224 Acc: 0.4375\n",
      "Train Epoch: 20 [320000/906425] Loss: 1.384306 Acc: 0.6250\n",
      "Train Epoch: 20 [336000/906425] Loss: 1.465888 Acc: 0.6875\n",
      "Train Epoch: 20 [352000/906425] Loss: 0.913946 Acc: 0.7500\n",
      "Train Epoch: 20 [368000/906425] Loss: 0.993323 Acc: 0.6875\n",
      "Train Epoch: 20 [384000/906425] Loss: 2.496304 Acc: 0.5000\n",
      "Train Epoch: 20 [400000/906425] Loss: 0.818376 Acc: 0.8125\n",
      "Train Epoch: 20 [416000/906425] Loss: 1.055563 Acc: 0.6250\n",
      "Train Epoch: 20 [432000/906425] Loss: 0.526579 Acc: 0.8125\n",
      "Train Epoch: 20 [448000/906425] Loss: 0.942653 Acc: 0.6875\n",
      "Train Epoch: 20 [464000/906425] Loss: 0.602948 Acc: 0.8750\n",
      "Train Epoch: 20 [480000/906425] Loss: 0.977251 Acc: 0.6875\n",
      "Train Epoch: 20 [496000/906425] Loss: 0.530920 Acc: 0.8750\n",
      "Train Epoch: 20 [512000/906425] Loss: 0.783238 Acc: 0.7500\n",
      "Train Epoch: 20 [528000/906425] Loss: 0.362047 Acc: 0.8750\n",
      "Train Epoch: 20 [544000/906425] Loss: 1.014587 Acc: 0.6250\n",
      "Train Epoch: 20 [560000/906425] Loss: 1.840714 Acc: 0.6250\n",
      "Train Epoch: 20 [576000/906425] Loss: 1.386033 Acc: 0.7500\n",
      "Train Epoch: 20 [592000/906425] Loss: 0.987726 Acc: 0.6875\n",
      "Train Epoch: 20 [608000/906425] Loss: 1.205353 Acc: 0.6875\n",
      "Train Epoch: 20 [624000/906425] Loss: 0.740674 Acc: 0.7500\n",
      "Train Epoch: 20 [640000/906425] Loss: 0.953714 Acc: 0.6875\n",
      "Train Epoch: 20 [656000/906425] Loss: 1.188271 Acc: 0.6875\n",
      "Train Epoch: 20 [672000/906425] Loss: 2.103985 Acc: 0.5625\n",
      "Train Epoch: 20 [688000/906425] Loss: 0.489028 Acc: 0.9375\n",
      "Train Epoch: 20 [704000/906425] Loss: 0.784970 Acc: 0.6875\n",
      "Train Epoch: 20 [720000/906425] Loss: 0.712750 Acc: 0.8125\n",
      "Train Epoch: 20 [736000/906425] Loss: 1.136448 Acc: 0.7500\n",
      "Train Epoch: 20 [752000/906425] Loss: 0.840952 Acc: 0.8125\n",
      "Train Epoch: 20 [768000/906425] Loss: 0.829797 Acc: 0.8750\n",
      "Train Epoch: 20 [784000/906425] Loss: 0.980968 Acc: 0.6250\n",
      "Train Epoch: 20 [800000/906425] Loss: 2.110049 Acc: 0.4375\n",
      "Train Epoch: 20 [816000/906425] Loss: 1.455622 Acc: 0.6875\n",
      "Train Epoch: 20 [832000/906425] Loss: 0.876287 Acc: 0.7500\n",
      "Train Epoch: 20 [848000/906425] Loss: 0.788085 Acc: 0.7500\n",
      "Train Epoch: 20 [864000/906425] Loss: 0.724450 Acc: 0.8125\n",
      "Train Epoch: 20 [880000/906425] Loss: 1.109783 Acc: 0.8125\n",
      "Train Epoch: 20 [896000/906425] Loss: 1.020779 Acc: 0.7500\n",
      "Elapsed 12074.73s, 574.99 s/epoch, 0.01 s/batch, ets 16674.62s\n",
      "\n",
      "Test set: Average loss: 1.5505, Accuracy: 193907/293785 (66%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 21 [16000/906425] Loss: 1.231518 Acc: 0.6250\n",
      "Train Epoch: 21 [32000/906425] Loss: 1.427745 Acc: 0.6875\n",
      "Train Epoch: 21 [48000/906425] Loss: 1.091521 Acc: 0.7500\n",
      "Train Epoch: 21 [64000/906425] Loss: 0.582156 Acc: 0.8750\n",
      "Train Epoch: 21 [80000/906425] Loss: 1.216374 Acc: 0.6250\n",
      "Train Epoch: 21 [96000/906425] Loss: 0.970418 Acc: 0.6250\n",
      "Train Epoch: 21 [112000/906425] Loss: 1.065637 Acc: 0.7500\n",
      "Train Epoch: 21 [128000/906425] Loss: 0.659352 Acc: 0.8125\n",
      "Train Epoch: 21 [144000/906425] Loss: 0.937736 Acc: 0.7500\n",
      "Train Epoch: 21 [160000/906425] Loss: 1.616382 Acc: 0.5625\n",
      "Train Epoch: 21 [176000/906425] Loss: 1.026002 Acc: 0.6250\n",
      "Train Epoch: 21 [192000/906425] Loss: 0.891311 Acc: 0.8125\n",
      "Train Epoch: 21 [208000/906425] Loss: 1.088244 Acc: 0.6875\n",
      "Train Epoch: 21 [224000/906425] Loss: 0.490468 Acc: 0.8750\n",
      "Train Epoch: 21 [240000/906425] Loss: 0.603779 Acc: 0.8750\n",
      "Train Epoch: 21 [256000/906425] Loss: 1.210095 Acc: 0.7500\n",
      "Train Epoch: 21 [272000/906425] Loss: 0.966593 Acc: 0.8125\n",
      "Train Epoch: 21 [288000/906425] Loss: 0.382708 Acc: 0.8750\n",
      "Train Epoch: 21 [304000/906425] Loss: 0.857765 Acc: 0.6875\n",
      "Train Epoch: 21 [320000/906425] Loss: 1.374077 Acc: 0.5625\n",
      "Train Epoch: 21 [336000/906425] Loss: 0.984533 Acc: 0.8750\n",
      "Train Epoch: 21 [352000/906425] Loss: 1.293656 Acc: 0.6875\n",
      "Train Epoch: 21 [368000/906425] Loss: 0.475249 Acc: 0.8750\n",
      "Train Epoch: 21 [384000/906425] Loss: 1.435118 Acc: 0.5625\n",
      "Train Epoch: 21 [400000/906425] Loss: 1.291776 Acc: 0.6875\n",
      "Train Epoch: 21 [416000/906425] Loss: 1.129039 Acc: 0.7500\n",
      "Train Epoch: 21 [432000/906425] Loss: 1.394183 Acc: 0.6875\n",
      "Train Epoch: 21 [448000/906425] Loss: 1.313238 Acc: 0.6250\n",
      "Train Epoch: 21 [464000/906425] Loss: 0.953466 Acc: 0.7500\n",
      "Train Epoch: 21 [480000/906425] Loss: 1.338719 Acc: 0.6875\n",
      "Train Epoch: 21 [496000/906425] Loss: 1.003492 Acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [512000/906425] Loss: 1.662295 Acc: 0.6250\n",
      "Train Epoch: 21 [528000/906425] Loss: 1.573022 Acc: 0.6250\n",
      "Train Epoch: 21 [544000/906425] Loss: 1.913705 Acc: 0.6875\n",
      "Train Epoch: 21 [560000/906425] Loss: 0.842629 Acc: 0.8125\n",
      "Train Epoch: 21 [576000/906425] Loss: 0.658595 Acc: 0.8125\n",
      "Train Epoch: 21 [592000/906425] Loss: 1.333133 Acc: 0.7500\n",
      "Train Epoch: 21 [608000/906425] Loss: 0.977949 Acc: 0.7500\n",
      "Train Epoch: 21 [624000/906425] Loss: 1.250558 Acc: 0.6875\n",
      "Train Epoch: 21 [640000/906425] Loss: 0.786709 Acc: 0.7500\n",
      "Train Epoch: 21 [656000/906425] Loss: 1.551231 Acc: 0.4375\n",
      "Train Epoch: 21 [672000/906425] Loss: 0.489814 Acc: 0.8750\n",
      "Train Epoch: 21 [688000/906425] Loss: 0.609918 Acc: 0.8125\n",
      "Train Epoch: 21 [704000/906425] Loss: 1.259617 Acc: 0.6875\n",
      "Train Epoch: 21 [720000/906425] Loss: 1.553630 Acc: 0.6875\n",
      "Train Epoch: 21 [736000/906425] Loss: 0.825492 Acc: 0.6250\n",
      "Train Epoch: 21 [752000/906425] Loss: 0.357430 Acc: 0.9375\n",
      "Train Epoch: 21 [768000/906425] Loss: 1.531343 Acc: 0.6875\n",
      "Train Epoch: 21 [784000/906425] Loss: 1.633318 Acc: 0.5625\n",
      "Train Epoch: 21 [800000/906425] Loss: 1.632060 Acc: 0.7500\n",
      "Train Epoch: 21 [816000/906425] Loss: 0.563602 Acc: 0.8125\n",
      "Train Epoch: 21 [832000/906425] Loss: 0.931311 Acc: 0.8125\n",
      "Train Epoch: 21 [848000/906425] Loss: 1.095270 Acc: 0.6875\n",
      "Train Epoch: 21 [864000/906425] Loss: 1.373381 Acc: 0.5000\n",
      "Train Epoch: 21 [880000/906425] Loss: 0.825748 Acc: 0.8125\n",
      "Train Epoch: 21 [896000/906425] Loss: 1.404180 Acc: 0.8125\n",
      "Elapsed 12653.71s, 575.17 s/epoch, 0.01 s/batch, ets 16104.72s\n",
      "\n",
      "Test set: Average loss: 1.5542, Accuracy: 195001/293785 (66%)\n",
      "\n",
      "Train Epoch: 22 [16000/906425] Loss: 0.560172 Acc: 0.9375\n",
      "Train Epoch: 22 [32000/906425] Loss: 1.375713 Acc: 0.7500\n",
      "Train Epoch: 22 [48000/906425] Loss: 1.236551 Acc: 0.7500\n",
      "Train Epoch: 22 [64000/906425] Loss: 1.048990 Acc: 0.6875\n",
      "Train Epoch: 22 [80000/906425] Loss: 0.721149 Acc: 0.8750\n",
      "Train Epoch: 22 [96000/906425] Loss: 1.220346 Acc: 0.8125\n",
      "Train Epoch: 22 [112000/906425] Loss: 0.960651 Acc: 0.8125\n",
      "Train Epoch: 22 [128000/906425] Loss: 1.157347 Acc: 0.6875\n",
      "Train Epoch: 22 [144000/906425] Loss: 0.520300 Acc: 0.9375\n",
      "Train Epoch: 22 [160000/906425] Loss: 1.747234 Acc: 0.5000\n",
      "Train Epoch: 22 [176000/906425] Loss: 1.287430 Acc: 0.6875\n",
      "Train Epoch: 22 [192000/906425] Loss: 1.619480 Acc: 0.5625\n",
      "Train Epoch: 22 [208000/906425] Loss: 1.154755 Acc: 0.6875\n",
      "Train Epoch: 22 [224000/906425] Loss: 0.697321 Acc: 0.8125\n",
      "Train Epoch: 22 [240000/906425] Loss: 1.541899 Acc: 0.6875\n",
      "Train Epoch: 22 [256000/906425] Loss: 1.481259 Acc: 0.7500\n",
      "Train Epoch: 22 [272000/906425] Loss: 0.495926 Acc: 0.8125\n",
      "Train Epoch: 22 [288000/906425] Loss: 1.245768 Acc: 0.6875\n",
      "Train Epoch: 22 [304000/906425] Loss: 0.674612 Acc: 0.6875\n",
      "Train Epoch: 22 [320000/906425] Loss: 0.833926 Acc: 0.6250\n",
      "Train Epoch: 22 [336000/906425] Loss: 0.829390 Acc: 0.8750\n",
      "Train Epoch: 22 [352000/906425] Loss: 0.971095 Acc: 0.8750\n",
      "Train Epoch: 22 [368000/906425] Loss: 0.989852 Acc: 0.8125\n",
      "Train Epoch: 22 [384000/906425] Loss: 1.107874 Acc: 0.8125\n",
      "Train Epoch: 22 [400000/906425] Loss: 1.237680 Acc: 0.6250\n",
      "Train Epoch: 22 [416000/906425] Loss: 0.993367 Acc: 0.7500\n",
      "Train Epoch: 22 [432000/906425] Loss: 1.261442 Acc: 0.8125\n",
      "Train Epoch: 22 [448000/906425] Loss: 0.790412 Acc: 0.6250\n",
      "Train Epoch: 22 [464000/906425] Loss: 1.201244 Acc: 0.6250\n",
      "Train Epoch: 22 [480000/906425] Loss: 0.938195 Acc: 0.6875\n",
      "Train Epoch: 22 [496000/906425] Loss: 0.720139 Acc: 0.8125\n",
      "Train Epoch: 22 [512000/906425] Loss: 0.969689 Acc: 0.7500\n",
      "Train Epoch: 22 [528000/906425] Loss: 0.906107 Acc: 0.7500\n",
      "Train Epoch: 22 [544000/906425] Loss: 0.458334 Acc: 0.8750\n",
      "Train Epoch: 22 [560000/906425] Loss: 0.640472 Acc: 0.8125\n",
      "Train Epoch: 22 [576000/906425] Loss: 0.885954 Acc: 0.6875\n",
      "Train Epoch: 22 [592000/906425] Loss: 0.802527 Acc: 0.7500\n",
      "Train Epoch: 22 [608000/906425] Loss: 1.228056 Acc: 0.5000\n",
      "Train Epoch: 22 [624000/906425] Loss: 1.737171 Acc: 0.6875\n",
      "Train Epoch: 22 [640000/906425] Loss: 0.742072 Acc: 0.8125\n",
      "Train Epoch: 22 [656000/906425] Loss: 0.488539 Acc: 0.8750\n",
      "Train Epoch: 22 [672000/906425] Loss: 1.289456 Acc: 0.6250\n",
      "Train Epoch: 22 [688000/906425] Loss: 0.871889 Acc: 0.6875\n",
      "Train Epoch: 22 [704000/906425] Loss: 0.895598 Acc: 0.6875\n",
      "Train Epoch: 22 [720000/906425] Loss: 0.338920 Acc: 0.8750\n",
      "Train Epoch: 22 [736000/906425] Loss: 0.868162 Acc: 0.8125\n",
      "Train Epoch: 22 [752000/906425] Loss: 2.233689 Acc: 0.5000\n",
      "Train Epoch: 22 [768000/906425] Loss: 1.138257 Acc: 0.6250\n",
      "Train Epoch: 22 [784000/906425] Loss: 2.227639 Acc: 0.5625\n",
      "Train Epoch: 22 [800000/906425] Loss: 1.376123 Acc: 0.6250\n",
      "Train Epoch: 22 [816000/906425] Loss: 0.794891 Acc: 0.8125\n",
      "Train Epoch: 22 [832000/906425] Loss: 0.906863 Acc: 0.8125\n",
      "Train Epoch: 22 [848000/906425] Loss: 0.759700 Acc: 0.7500\n",
      "Train Epoch: 22 [864000/906425] Loss: 1.000759 Acc: 0.6250\n",
      "Train Epoch: 22 [880000/906425] Loss: 0.513474 Acc: 0.9375\n",
      "Train Epoch: 22 [896000/906425] Loss: 0.997922 Acc: 0.7500\n",
      "Elapsed 13232.41s, 575.32 s/epoch, 0.01 s/batch, ets 15533.70s\n",
      "\n",
      "Test set: Average loss: 1.5335, Accuracy: 195936/293785 (67%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 23 [16000/906425] Loss: 0.587277 Acc: 0.7500\n",
      "Train Epoch: 23 [32000/906425] Loss: 0.683743 Acc: 0.8125\n",
      "Train Epoch: 23 [48000/906425] Loss: 0.767974 Acc: 0.8125\n",
      "Train Epoch: 23 [64000/906425] Loss: 0.696117 Acc: 0.8125\n",
      "Train Epoch: 23 [80000/906425] Loss: 0.968832 Acc: 0.6875\n",
      "Train Epoch: 23 [96000/906425] Loss: 1.743972 Acc: 0.5625\n",
      "Train Epoch: 23 [112000/906425] Loss: 0.968646 Acc: 0.8125\n",
      "Train Epoch: 23 [128000/906425] Loss: 0.503042 Acc: 0.8125\n",
      "Train Epoch: 23 [144000/906425] Loss: 0.478995 Acc: 0.8125\n",
      "Train Epoch: 23 [160000/906425] Loss: 1.083764 Acc: 0.6875\n",
      "Train Epoch: 23 [176000/906425] Loss: 0.667469 Acc: 0.6250\n",
      "Train Epoch: 23 [192000/906425] Loss: 0.333406 Acc: 0.8750\n",
      "Train Epoch: 23 [208000/906425] Loss: 1.495931 Acc: 0.6875\n",
      "Train Epoch: 23 [224000/906425] Loss: 0.736640 Acc: 0.8125\n",
      "Train Epoch: 23 [240000/906425] Loss: 0.929770 Acc: 0.8125\n",
      "Train Epoch: 23 [256000/906425] Loss: 0.643650 Acc: 0.7500\n",
      "Train Epoch: 23 [272000/906425] Loss: 1.002660 Acc: 0.6875\n",
      "Train Epoch: 23 [288000/906425] Loss: 0.550779 Acc: 0.8750\n",
      "Train Epoch: 23 [304000/906425] Loss: 1.394794 Acc: 0.6875\n",
      "Train Epoch: 23 [320000/906425] Loss: 1.394994 Acc: 0.7500\n",
      "Train Epoch: 23 [336000/906425] Loss: 1.117070 Acc: 0.5625\n",
      "Train Epoch: 23 [352000/906425] Loss: 1.276691 Acc: 0.8125\n",
      "Train Epoch: 23 [368000/906425] Loss: 0.712928 Acc: 0.8125\n",
      "Train Epoch: 23 [384000/906425] Loss: 0.737773 Acc: 0.8125\n",
      "Train Epoch: 23 [400000/906425] Loss: 0.859726 Acc: 0.8125\n",
      "Train Epoch: 23 [416000/906425] Loss: 0.543752 Acc: 0.8125\n",
      "Train Epoch: 23 [432000/906425] Loss: 1.095120 Acc: 0.6875\n",
      "Train Epoch: 23 [448000/906425] Loss: 1.019253 Acc: 0.6250\n",
      "Train Epoch: 23 [464000/906425] Loss: 1.289669 Acc: 0.6875\n",
      "Train Epoch: 23 [480000/906425] Loss: 1.630773 Acc: 0.5625\n",
      "Train Epoch: 23 [496000/906425] Loss: 0.251565 Acc: 0.8750\n",
      "Train Epoch: 23 [512000/906425] Loss: 0.964374 Acc: 0.7500\n",
      "Train Epoch: 23 [528000/906425] Loss: 0.784904 Acc: 0.6875\n",
      "Train Epoch: 23 [544000/906425] Loss: 0.817742 Acc: 0.7500\n",
      "Train Epoch: 23 [560000/906425] Loss: 1.618722 Acc: 0.6875\n",
      "Train Epoch: 23 [576000/906425] Loss: 1.213817 Acc: 0.6250\n",
      "Train Epoch: 23 [592000/906425] Loss: 0.418216 Acc: 0.9375\n",
      "Train Epoch: 23 [608000/906425] Loss: 0.720614 Acc: 0.8750\n",
      "Train Epoch: 23 [624000/906425] Loss: 0.484155 Acc: 0.8750\n",
      "Train Epoch: 23 [640000/906425] Loss: 0.661555 Acc: 0.8125\n",
      "Train Epoch: 23 [656000/906425] Loss: 1.658777 Acc: 0.6250\n",
      "Train Epoch: 23 [672000/906425] Loss: 0.714018 Acc: 0.7500\n",
      "Train Epoch: 23 [688000/906425] Loss: 1.303710 Acc: 0.5625\n",
      "Train Epoch: 23 [704000/906425] Loss: 2.487044 Acc: 0.5625\n",
      "Train Epoch: 23 [720000/906425] Loss: 0.259865 Acc: 0.8750\n",
      "Train Epoch: 23 [736000/906425] Loss: 2.596507 Acc: 0.4375\n",
      "Train Epoch: 23 [752000/906425] Loss: 0.925773 Acc: 0.7500\n",
      "Train Epoch: 23 [768000/906425] Loss: 0.643943 Acc: 0.6875\n",
      "Train Epoch: 23 [784000/906425] Loss: 0.221131 Acc: 1.0000\n",
      "Train Epoch: 23 [800000/906425] Loss: 1.200321 Acc: 0.8125\n",
      "Train Epoch: 23 [816000/906425] Loss: 1.676187 Acc: 0.6875\n",
      "Train Epoch: 23 [832000/906425] Loss: 1.262102 Acc: 0.8125\n",
      "Train Epoch: 23 [848000/906425] Loss: 0.962005 Acc: 0.7500\n",
      "Train Epoch: 23 [864000/906425] Loss: 1.101028 Acc: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [880000/906425] Loss: 0.785440 Acc: 0.7500\n",
      "Train Epoch: 23 [896000/906425] Loss: 1.071691 Acc: 0.6875\n",
      "Elapsed 13811.40s, 575.47 s/epoch, 0.01 s/batch, ets 14962.35s\n",
      "\n",
      "Test set: Average loss: 1.4970, Accuracy: 198544/293785 (68%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 24 [16000/906425] Loss: 0.157688 Acc: 1.0000\n",
      "Train Epoch: 24 [32000/906425] Loss: 1.020755 Acc: 0.7500\n",
      "Train Epoch: 24 [48000/906425] Loss: 1.866416 Acc: 0.5625\n",
      "Train Epoch: 24 [64000/906425] Loss: 0.610102 Acc: 0.8125\n",
      "Train Epoch: 24 [80000/906425] Loss: 0.562736 Acc: 0.7500\n",
      "Train Epoch: 24 [96000/906425] Loss: 1.149680 Acc: 0.7500\n",
      "Train Epoch: 24 [112000/906425] Loss: 0.572255 Acc: 0.8750\n",
      "Train Epoch: 24 [128000/906425] Loss: 1.250431 Acc: 0.6250\n",
      "Train Epoch: 24 [144000/906425] Loss: 0.938160 Acc: 0.8125\n",
      "Train Epoch: 24 [160000/906425] Loss: 0.739662 Acc: 0.8125\n",
      "Train Epoch: 24 [176000/906425] Loss: 0.569846 Acc: 0.8125\n",
      "Train Epoch: 24 [192000/906425] Loss: 0.659771 Acc: 0.7500\n",
      "Train Epoch: 24 [208000/906425] Loss: 0.984826 Acc: 0.7500\n",
      "Train Epoch: 24 [224000/906425] Loss: 1.004255 Acc: 0.7500\n",
      "Train Epoch: 24 [240000/906425] Loss: 0.463583 Acc: 0.8750\n",
      "Train Epoch: 24 [256000/906425] Loss: 0.547713 Acc: 0.7500\n",
      "Train Epoch: 24 [272000/906425] Loss: 0.527473 Acc: 0.8125\n",
      "Train Epoch: 24 [288000/906425] Loss: 0.712754 Acc: 0.8750\n",
      "Train Epoch: 24 [304000/906425] Loss: 1.108904 Acc: 0.6875\n",
      "Train Epoch: 24 [320000/906425] Loss: 0.708835 Acc: 0.8750\n",
      "Train Epoch: 24 [336000/906425] Loss: 0.836681 Acc: 0.7500\n",
      "Train Epoch: 24 [352000/906425] Loss: 1.485905 Acc: 0.6250\n",
      "Train Epoch: 24 [368000/906425] Loss: 0.645509 Acc: 0.8750\n",
      "Train Epoch: 24 [384000/906425] Loss: 0.836055 Acc: 0.6875\n",
      "Train Epoch: 24 [400000/906425] Loss: 0.804255 Acc: 0.7500\n",
      "Train Epoch: 24 [416000/906425] Loss: 0.978562 Acc: 0.7500\n",
      "Train Epoch: 24 [432000/906425] Loss: 0.664713 Acc: 0.8125\n",
      "Train Epoch: 24 [448000/906425] Loss: 0.973053 Acc: 0.7500\n",
      "Train Epoch: 24 [464000/906425] Loss: 0.767323 Acc: 0.8750\n",
      "Train Epoch: 24 [480000/906425] Loss: 1.897092 Acc: 0.5625\n",
      "Train Epoch: 24 [496000/906425] Loss: 1.749439 Acc: 0.6250\n",
      "Train Epoch: 24 [512000/906425] Loss: 1.019899 Acc: 0.7500\n",
      "Train Epoch: 24 [528000/906425] Loss: 0.889349 Acc: 0.8125\n",
      "Train Epoch: 24 [544000/906425] Loss: 0.938879 Acc: 0.7500\n",
      "Train Epoch: 24 [560000/906425] Loss: 1.144517 Acc: 0.5625\n",
      "Train Epoch: 24 [576000/906425] Loss: 1.138082 Acc: 0.8125\n",
      "Train Epoch: 24 [592000/906425] Loss: 0.466445 Acc: 0.8125\n",
      "Train Epoch: 24 [608000/906425] Loss: 1.692120 Acc: 0.5625\n",
      "Train Epoch: 24 [624000/906425] Loss: 0.783256 Acc: 0.8750\n",
      "Train Epoch: 24 [640000/906425] Loss: 0.804245 Acc: 0.8125\n",
      "Train Epoch: 24 [656000/906425] Loss: 0.535394 Acc: 0.8125\n",
      "Train Epoch: 24 [672000/906425] Loss: 0.929426 Acc: 0.6250\n",
      "Train Epoch: 24 [688000/906425] Loss: 1.679072 Acc: 0.6250\n",
      "Train Epoch: 24 [704000/906425] Loss: 0.731456 Acc: 0.8750\n",
      "Train Epoch: 24 [720000/906425] Loss: 0.698549 Acc: 0.8125\n",
      "Train Epoch: 24 [736000/906425] Loss: 1.007500 Acc: 0.5625\n",
      "Train Epoch: 24 [752000/906425] Loss: 0.893139 Acc: 0.6875\n",
      "Train Epoch: 24 [768000/906425] Loss: 0.883253 Acc: 0.6875\n",
      "Train Epoch: 24 [784000/906425] Loss: 1.052228 Acc: 0.6250\n",
      "Train Epoch: 24 [800000/906425] Loss: 0.909039 Acc: 0.6875\n",
      "Train Epoch: 24 [816000/906425] Loss: 1.330133 Acc: 0.5625\n",
      "Train Epoch: 24 [832000/906425] Loss: 1.149516 Acc: 0.6250\n",
      "Train Epoch: 24 [848000/906425] Loss: 0.911817 Acc: 0.7500\n",
      "Train Epoch: 24 [864000/906425] Loss: 0.977671 Acc: 0.8750\n",
      "Train Epoch: 24 [880000/906425] Loss: 1.364242 Acc: 0.6875\n",
      "Train Epoch: 24 [896000/906425] Loss: 0.641719 Acc: 0.8125\n",
      "Elapsed 14390.60s, 575.62 s/epoch, 0.01 s/batch, ets 14390.60s\n",
      "\n",
      "Test set: Average loss: 1.5018, Accuracy: 198701/293785 (68%)\n",
      "\n",
      "Train Epoch: 25 [16000/906425] Loss: 1.338822 Acc: 0.6875\n",
      "Train Epoch: 25 [32000/906425] Loss: 0.919652 Acc: 0.8125\n",
      "Train Epoch: 25 [48000/906425] Loss: 1.249706 Acc: 0.6250\n",
      "Train Epoch: 25 [64000/906425] Loss: 1.063605 Acc: 0.7500\n",
      "Train Epoch: 25 [80000/906425] Loss: 1.385125 Acc: 0.6875\n",
      "Train Epoch: 25 [96000/906425] Loss: 0.747839 Acc: 0.7500\n",
      "Train Epoch: 25 [112000/906425] Loss: 0.364548 Acc: 0.8750\n",
      "Train Epoch: 25 [128000/906425] Loss: 1.100894 Acc: 0.6875\n",
      "Train Epoch: 25 [144000/906425] Loss: 0.858911 Acc: 0.7500\n",
      "Train Epoch: 25 [160000/906425] Loss: 1.473239 Acc: 0.6875\n",
      "Train Epoch: 25 [176000/906425] Loss: 1.111752 Acc: 0.6875\n",
      "Train Epoch: 25 [192000/906425] Loss: 0.570376 Acc: 0.8125\n",
      "Train Epoch: 25 [208000/906425] Loss: 0.373972 Acc: 0.9375\n",
      "Train Epoch: 25 [224000/906425] Loss: 0.610568 Acc: 0.8125\n",
      "Train Epoch: 25 [240000/906425] Loss: 0.923594 Acc: 0.6875\n",
      "Train Epoch: 25 [256000/906425] Loss: 0.515065 Acc: 0.8750\n",
      "Train Epoch: 25 [272000/906425] Loss: 0.670216 Acc: 0.7500\n",
      "Train Epoch: 25 [288000/906425] Loss: 1.039418 Acc: 0.8125\n",
      "Train Epoch: 25 [304000/906425] Loss: 1.746275 Acc: 0.5625\n",
      "Train Epoch: 25 [320000/906425] Loss: 1.293399 Acc: 0.6250\n",
      "Train Epoch: 25 [336000/906425] Loss: 0.336714 Acc: 0.9375\n",
      "Train Epoch: 25 [352000/906425] Loss: 1.126061 Acc: 0.6875\n",
      "Train Epoch: 25 [368000/906425] Loss: 0.513456 Acc: 0.8125\n",
      "Train Epoch: 25 [384000/906425] Loss: 0.999969 Acc: 0.7500\n",
      "Train Epoch: 25 [400000/906425] Loss: 0.940454 Acc: 0.6875\n",
      "Train Epoch: 25 [416000/906425] Loss: 1.221443 Acc: 0.6875\n",
      "Train Epoch: 25 [432000/906425] Loss: 0.745961 Acc: 0.7500\n",
      "Train Epoch: 25 [448000/906425] Loss: 0.617481 Acc: 0.8750\n",
      "Train Epoch: 25 [464000/906425] Loss: 0.685396 Acc: 0.8125\n",
      "Train Epoch: 25 [480000/906425] Loss: 1.405910 Acc: 0.6250\n",
      "Train Epoch: 25 [496000/906425] Loss: 0.719816 Acc: 0.8750\n",
      "Train Epoch: 25 [512000/906425] Loss: 1.472420 Acc: 0.5625\n",
      "Train Epoch: 25 [528000/906425] Loss: 0.454304 Acc: 0.8750\n",
      "Train Epoch: 25 [544000/906425] Loss: 1.311612 Acc: 0.6875\n",
      "Train Epoch: 25 [560000/906425] Loss: 1.437968 Acc: 0.5625\n",
      "Train Epoch: 25 [576000/906425] Loss: 0.744720 Acc: 0.7500\n",
      "Train Epoch: 25 [592000/906425] Loss: 1.760493 Acc: 0.3750\n",
      "Train Epoch: 25 [608000/906425] Loss: 1.180635 Acc: 0.6875\n",
      "Train Epoch: 25 [624000/906425] Loss: 1.018654 Acc: 0.8125\n",
      "Train Epoch: 25 [640000/906425] Loss: 0.909428 Acc: 0.7500\n",
      "Train Epoch: 25 [656000/906425] Loss: 0.200740 Acc: 0.9375\n",
      "Train Epoch: 25 [672000/906425] Loss: 0.864407 Acc: 0.6875\n",
      "Train Epoch: 25 [688000/906425] Loss: 1.418296 Acc: 0.6875\n",
      "Train Epoch: 25 [704000/906425] Loss: 0.929329 Acc: 0.7500\n",
      "Train Epoch: 25 [720000/906425] Loss: 0.314430 Acc: 0.8750\n",
      "Train Epoch: 25 [736000/906425] Loss: 1.013032 Acc: 0.8750\n",
      "Train Epoch: 25 [752000/906425] Loss: 0.735780 Acc: 0.7500\n",
      "Train Epoch: 25 [768000/906425] Loss: 0.859253 Acc: 0.6875\n",
      "Train Epoch: 25 [784000/906425] Loss: 0.337109 Acc: 0.9375\n",
      "Train Epoch: 25 [800000/906425] Loss: 0.969158 Acc: 0.7500\n",
      "Train Epoch: 25 [816000/906425] Loss: 0.830679 Acc: 0.6875\n",
      "Train Epoch: 25 [832000/906425] Loss: 1.376519 Acc: 0.6250\n",
      "Train Epoch: 25 [848000/906425] Loss: 0.873392 Acc: 0.6875\n",
      "Train Epoch: 25 [864000/906425] Loss: 1.791265 Acc: 0.5625\n",
      "Train Epoch: 25 [880000/906425] Loss: 1.848859 Acc: 0.6875\n",
      "Train Epoch: 25 [896000/906425] Loss: 0.814612 Acc: 0.6875\n",
      "Elapsed 14969.52s, 575.75 s/epoch, 0.01 s/batch, ets 13818.01s\n",
      "\n",
      "Test set: Average loss: 1.4746, Accuracy: 200067/293785 (68%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 26 [16000/906425] Loss: 0.620689 Acc: 0.8750\n",
      "Train Epoch: 26 [32000/906425] Loss: 1.236845 Acc: 0.6875\n",
      "Train Epoch: 26 [48000/906425] Loss: 1.221450 Acc: 0.6875\n",
      "Train Epoch: 26 [64000/906425] Loss: 0.569139 Acc: 0.8125\n",
      "Train Epoch: 26 [80000/906425] Loss: 0.702473 Acc: 0.6875\n",
      "Train Epoch: 26 [96000/906425] Loss: 1.335393 Acc: 0.6250\n",
      "Train Epoch: 26 [112000/906425] Loss: 1.058550 Acc: 0.5625\n",
      "Train Epoch: 26 [128000/906425] Loss: 0.575476 Acc: 0.8750\n",
      "Train Epoch: 26 [144000/906425] Loss: 0.714114 Acc: 0.8125\n",
      "Train Epoch: 26 [160000/906425] Loss: 0.773492 Acc: 0.6875\n",
      "Train Epoch: 26 [176000/906425] Loss: 0.480491 Acc: 0.8125\n",
      "Train Epoch: 26 [192000/906425] Loss: 0.618096 Acc: 0.8125\n",
      "Train Epoch: 26 [208000/906425] Loss: 1.060931 Acc: 0.6875\n",
      "Train Epoch: 26 [224000/906425] Loss: 1.385032 Acc: 0.6250\n",
      "Train Epoch: 26 [240000/906425] Loss: 0.851257 Acc: 0.8125\n",
      "Train Epoch: 26 [256000/906425] Loss: 1.422374 Acc: 0.8750\n",
      "Train Epoch: 26 [272000/906425] Loss: 0.681362 Acc: 0.8750\n",
      "Train Epoch: 26 [288000/906425] Loss: 0.493717 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [304000/906425] Loss: 1.305403 Acc: 0.6875\n",
      "Train Epoch: 26 [320000/906425] Loss: 1.488582 Acc: 0.8125\n",
      "Train Epoch: 26 [336000/906425] Loss: 1.096550 Acc: 0.7500\n",
      "Train Epoch: 26 [352000/906425] Loss: 0.890921 Acc: 0.6875\n",
      "Train Epoch: 26 [368000/906425] Loss: 0.360652 Acc: 1.0000\n",
      "Train Epoch: 26 [384000/906425] Loss: 1.095946 Acc: 0.6875\n",
      "Train Epoch: 26 [400000/906425] Loss: 0.887884 Acc: 0.7500\n",
      "Train Epoch: 26 [416000/906425] Loss: 0.743272 Acc: 0.8125\n",
      "Train Epoch: 26 [432000/906425] Loss: 0.655818 Acc: 0.8750\n",
      "Train Epoch: 26 [448000/906425] Loss: 0.447526 Acc: 0.8125\n",
      "Train Epoch: 26 [464000/906425] Loss: 0.844817 Acc: 0.7500\n",
      "Train Epoch: 26 [480000/906425] Loss: 0.900430 Acc: 0.6875\n",
      "Train Epoch: 26 [496000/906425] Loss: 0.944187 Acc: 0.8125\n",
      "Train Epoch: 26 [512000/906425] Loss: 0.809742 Acc: 0.8750\n",
      "Train Epoch: 26 [528000/906425] Loss: 1.162813 Acc: 0.7500\n",
      "Train Epoch: 26 [544000/906425] Loss: 1.035329 Acc: 0.6250\n",
      "Train Epoch: 26 [560000/906425] Loss: 0.851176 Acc: 0.8125\n",
      "Train Epoch: 26 [576000/906425] Loss: 0.359300 Acc: 0.8750\n",
      "Train Epoch: 26 [592000/906425] Loss: 0.639672 Acc: 0.8125\n",
      "Train Epoch: 26 [608000/906425] Loss: 1.216568 Acc: 0.6250\n",
      "Train Epoch: 26 [624000/906425] Loss: 0.604204 Acc: 0.8750\n",
      "Train Epoch: 26 [640000/906425] Loss: 1.315143 Acc: 0.7500\n",
      "Train Epoch: 26 [656000/906425] Loss: 1.512844 Acc: 0.5625\n",
      "Train Epoch: 26 [672000/906425] Loss: 0.775635 Acc: 0.6875\n",
      "Train Epoch: 26 [688000/906425] Loss: 0.440708 Acc: 0.7500\n",
      "Train Epoch: 26 [704000/906425] Loss: 0.315286 Acc: 0.8750\n",
      "Train Epoch: 26 [720000/906425] Loss: 1.041866 Acc: 0.6875\n",
      "Train Epoch: 26 [736000/906425] Loss: 1.197357 Acc: 0.6250\n",
      "Train Epoch: 26 [752000/906425] Loss: 0.423903 Acc: 0.8750\n",
      "Train Epoch: 26 [768000/906425] Loss: 1.356506 Acc: 0.8125\n",
      "Train Epoch: 26 [784000/906425] Loss: 1.222849 Acc: 0.6875\n",
      "Train Epoch: 26 [800000/906425] Loss: 1.146070 Acc: 0.6875\n",
      "Train Epoch: 26 [816000/906425] Loss: 1.256282 Acc: 0.6875\n",
      "Train Epoch: 26 [832000/906425] Loss: 0.840595 Acc: 0.6250\n",
      "Train Epoch: 26 [848000/906425] Loss: 0.654441 Acc: 0.8125\n",
      "Train Epoch: 26 [864000/906425] Loss: 0.283928 Acc: 0.9375\n",
      "Train Epoch: 26 [880000/906425] Loss: 0.864073 Acc: 0.7500\n",
      "Train Epoch: 26 [896000/906425] Loss: 1.037465 Acc: 0.8125\n",
      "Elapsed 15548.08s, 575.85 s/epoch, 0.01 s/batch, ets 13244.66s\n",
      "\n",
      "Test set: Average loss: 1.4898, Accuracy: 199924/293785 (68%)\n",
      "\n",
      "Train Epoch: 27 [16000/906425] Loss: 0.349327 Acc: 0.9375\n",
      "Train Epoch: 27 [32000/906425] Loss: 1.111701 Acc: 0.8125\n",
      "Train Epoch: 27 [48000/906425] Loss: 1.210816 Acc: 0.6875\n",
      "Train Epoch: 27 [64000/906425] Loss: 0.408710 Acc: 0.8125\n",
      "Train Epoch: 27 [80000/906425] Loss: 0.960638 Acc: 0.6875\n",
      "Train Epoch: 27 [96000/906425] Loss: 0.341425 Acc: 0.9375\n",
      "Train Epoch: 27 [112000/906425] Loss: 0.782507 Acc: 0.8750\n",
      "Train Epoch: 27 [128000/906425] Loss: 0.984453 Acc: 0.6875\n",
      "Train Epoch: 27 [144000/906425] Loss: 0.619552 Acc: 0.8125\n",
      "Train Epoch: 27 [160000/906425] Loss: 0.745410 Acc: 0.8750\n",
      "Train Epoch: 27 [176000/906425] Loss: 1.033174 Acc: 0.6875\n",
      "Train Epoch: 27 [192000/906425] Loss: 0.765990 Acc: 0.8125\n",
      "Train Epoch: 27 [208000/906425] Loss: 1.244024 Acc: 0.6250\n",
      "Train Epoch: 27 [224000/906425] Loss: 0.689296 Acc: 0.6250\n",
      "Train Epoch: 27 [240000/906425] Loss: 0.718297 Acc: 0.8125\n",
      "Train Epoch: 27 [256000/906425] Loss: 1.590284 Acc: 0.5625\n",
      "Train Epoch: 27 [272000/906425] Loss: 1.532789 Acc: 0.5625\n",
      "Train Epoch: 27 [288000/906425] Loss: 0.275108 Acc: 1.0000\n",
      "Train Epoch: 27 [304000/906425] Loss: 1.093728 Acc: 0.7500\n",
      "Train Epoch: 27 [320000/906425] Loss: 0.572125 Acc: 0.8125\n",
      "Train Epoch: 27 [336000/906425] Loss: 0.665662 Acc: 0.8125\n",
      "Train Epoch: 27 [352000/906425] Loss: 1.202519 Acc: 0.7500\n",
      "Train Epoch: 27 [368000/906425] Loss: 1.042095 Acc: 0.8125\n",
      "Train Epoch: 27 [384000/906425] Loss: 0.610250 Acc: 0.7500\n",
      "Train Epoch: 27 [400000/906425] Loss: 0.711709 Acc: 0.8125\n",
      "Train Epoch: 27 [416000/906425] Loss: 0.499172 Acc: 0.8750\n",
      "Train Epoch: 27 [432000/906425] Loss: 0.719132 Acc: 0.8750\n",
      "Train Epoch: 27 [448000/906425] Loss: 1.239303 Acc: 0.7500\n",
      "Train Epoch: 27 [464000/906425] Loss: 0.774730 Acc: 0.8125\n",
      "Train Epoch: 27 [480000/906425] Loss: 1.537663 Acc: 0.5625\n",
      "Train Epoch: 27 [496000/906425] Loss: 0.907457 Acc: 0.7500\n",
      "Train Epoch: 27 [512000/906425] Loss: 0.961630 Acc: 0.7500\n",
      "Train Epoch: 27 [528000/906425] Loss: 1.742447 Acc: 0.6875\n",
      "Train Epoch: 27 [544000/906425] Loss: 0.958860 Acc: 0.7500\n",
      "Train Epoch: 27 [560000/906425] Loss: 0.328237 Acc: 0.8750\n",
      "Train Epoch: 27 [576000/906425] Loss: 0.919706 Acc: 0.7500\n",
      "Train Epoch: 27 [592000/906425] Loss: 0.575819 Acc: 0.8125\n",
      "Train Epoch: 27 [608000/906425] Loss: 0.287556 Acc: 0.8750\n",
      "Train Epoch: 27 [624000/906425] Loss: 0.792743 Acc: 0.7500\n",
      "Train Epoch: 27 [640000/906425] Loss: 1.439394 Acc: 0.6875\n",
      "Train Epoch: 27 [656000/906425] Loss: 0.489139 Acc: 0.8125\n",
      "Train Epoch: 27 [672000/906425] Loss: 0.587540 Acc: 0.9375\n",
      "Train Epoch: 27 [688000/906425] Loss: 1.470712 Acc: 0.5625\n",
      "Train Epoch: 27 [704000/906425] Loss: 0.566508 Acc: 0.8125\n",
      "Train Epoch: 27 [720000/906425] Loss: 0.540646 Acc: 0.8750\n",
      "Train Epoch: 27 [736000/906425] Loss: 1.175820 Acc: 0.7500\n",
      "Train Epoch: 27 [752000/906425] Loss: 0.704496 Acc: 0.8125\n",
      "Train Epoch: 27 [768000/906425] Loss: 0.546731 Acc: 0.8125\n",
      "Train Epoch: 27 [784000/906425] Loss: 0.812083 Acc: 0.8750\n",
      "Train Epoch: 27 [800000/906425] Loss: 0.696321 Acc: 0.8750\n",
      "Train Epoch: 27 [816000/906425] Loss: 1.523286 Acc: 0.6875\n",
      "Train Epoch: 27 [832000/906425] Loss: 0.475145 Acc: 0.8125\n",
      "Train Epoch: 27 [848000/906425] Loss: 0.819020 Acc: 0.8750\n",
      "Train Epoch: 27 [864000/906425] Loss: 0.759890 Acc: 0.8125\n",
      "Train Epoch: 27 [880000/906425] Loss: 1.032111 Acc: 0.7500\n",
      "Train Epoch: 27 [896000/906425] Loss: 1.085718 Acc: 0.7500\n",
      "Elapsed 16126.80s, 575.96 s/epoch, 0.01 s/batch, ets 12671.06s\n",
      "\n",
      "Test set: Average loss: 1.4826, Accuracy: 201033/293785 (68%)\n",
      "\n",
      "Train Epoch: 28 [16000/906425] Loss: 0.962957 Acc: 0.8125\n",
      "Train Epoch: 28 [32000/906425] Loss: 0.893682 Acc: 0.6875\n",
      "Train Epoch: 28 [48000/906425] Loss: 0.733369 Acc: 0.6875\n",
      "Train Epoch: 28 [64000/906425] Loss: 0.656667 Acc: 0.7500\n",
      "Train Epoch: 28 [80000/906425] Loss: 0.827766 Acc: 0.8125\n",
      "Train Epoch: 28 [96000/906425] Loss: 1.433451 Acc: 0.5625\n",
      "Train Epoch: 28 [112000/906425] Loss: 0.468148 Acc: 0.9375\n",
      "Train Epoch: 28 [128000/906425] Loss: 0.767450 Acc: 0.8125\n",
      "Train Epoch: 28 [144000/906425] Loss: 0.706903 Acc: 0.8125\n",
      "Train Epoch: 28 [160000/906425] Loss: 0.532786 Acc: 0.8125\n",
      "Train Epoch: 28 [176000/906425] Loss: 1.138789 Acc: 0.6250\n",
      "Train Epoch: 28 [192000/906425] Loss: 0.439450 Acc: 0.8125\n",
      "Train Epoch: 28 [208000/906425] Loss: 0.772040 Acc: 0.9375\n",
      "Train Epoch: 28 [224000/906425] Loss: 0.615418 Acc: 0.8125\n",
      "Train Epoch: 28 [240000/906425] Loss: 1.791556 Acc: 0.6250\n",
      "Train Epoch: 28 [256000/906425] Loss: 0.671597 Acc: 0.8750\n",
      "Train Epoch: 28 [272000/906425] Loss: 0.521066 Acc: 0.8750\n",
      "Train Epoch: 28 [288000/906425] Loss: 0.677076 Acc: 0.7500\n",
      "Train Epoch: 28 [304000/906425] Loss: 0.883331 Acc: 0.6875\n",
      "Train Epoch: 28 [320000/906425] Loss: 1.080322 Acc: 0.7500\n",
      "Train Epoch: 28 [336000/906425] Loss: 0.934148 Acc: 0.8125\n",
      "Train Epoch: 28 [352000/906425] Loss: 0.936057 Acc: 0.6875\n",
      "Train Epoch: 28 [368000/906425] Loss: 1.005525 Acc: 0.7500\n",
      "Train Epoch: 28 [384000/906425] Loss: 1.254331 Acc: 0.7500\n",
      "Train Epoch: 28 [400000/906425] Loss: 0.547727 Acc: 0.9375\n",
      "Train Epoch: 28 [416000/906425] Loss: 0.887120 Acc: 0.6875\n",
      "Train Epoch: 28 [432000/906425] Loss: 0.985320 Acc: 0.6875\n",
      "Train Epoch: 28 [448000/906425] Loss: 0.185638 Acc: 0.9375\n",
      "Train Epoch: 28 [464000/906425] Loss: 0.505471 Acc: 0.8750\n",
      "Train Epoch: 28 [480000/906425] Loss: 0.751215 Acc: 0.8750\n",
      "Train Epoch: 28 [496000/906425] Loss: 0.426158 Acc: 0.8125\n",
      "Train Epoch: 28 [512000/906425] Loss: 1.055201 Acc: 0.8125\n",
      "Train Epoch: 28 [528000/906425] Loss: 0.303451 Acc: 1.0000\n",
      "Train Epoch: 28 [544000/906425] Loss: 0.662259 Acc: 0.8750\n",
      "Train Epoch: 28 [560000/906425] Loss: 0.497976 Acc: 0.8125\n",
      "Train Epoch: 28 [576000/906425] Loss: 1.105043 Acc: 0.6250\n",
      "Train Epoch: 28 [592000/906425] Loss: 1.445411 Acc: 0.7500\n",
      "Train Epoch: 28 [608000/906425] Loss: 0.612862 Acc: 0.8750\n",
      "Train Epoch: 28 [624000/906425] Loss: 1.139146 Acc: 0.6875\n",
      "Train Epoch: 28 [640000/906425] Loss: 0.384593 Acc: 0.8750\n",
      "Train Epoch: 28 [656000/906425] Loss: 0.579871 Acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [672000/906425] Loss: 0.576602 Acc: 0.9375\n",
      "Train Epoch: 28 [688000/906425] Loss: 0.849735 Acc: 0.7500\n",
      "Train Epoch: 28 [704000/906425] Loss: 1.047731 Acc: 0.6250\n",
      "Train Epoch: 28 [720000/906425] Loss: 0.928314 Acc: 0.7500\n",
      "Train Epoch: 28 [736000/906425] Loss: 0.338260 Acc: 0.8125\n",
      "Train Epoch: 28 [752000/906425] Loss: 1.577792 Acc: 0.6250\n",
      "Train Epoch: 28 [768000/906425] Loss: 1.014066 Acc: 0.6875\n",
      "Train Epoch: 28 [784000/906425] Loss: 0.644579 Acc: 0.6875\n",
      "Train Epoch: 28 [800000/906425] Loss: 1.137550 Acc: 0.5625\n",
      "Train Epoch: 28 [816000/906425] Loss: 0.651181 Acc: 0.8750\n",
      "Train Epoch: 28 [832000/906425] Loss: 0.782577 Acc: 0.7500\n",
      "Train Epoch: 28 [848000/906425] Loss: 1.134025 Acc: 0.6250\n",
      "Train Epoch: 28 [864000/906425] Loss: 0.868254 Acc: 0.6875\n",
      "Train Epoch: 28 [880000/906425] Loss: 1.893712 Acc: 0.5625\n",
      "Train Epoch: 28 [896000/906425] Loss: 1.059577 Acc: 0.7500\n",
      "Elapsed 16705.38s, 576.05 s/epoch, 0.01 s/batch, ets 12097.00s\n",
      "\n",
      "Test set: Average loss: 1.4734, Accuracy: 201572/293785 (69%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 29 [16000/906425] Loss: 0.987698 Acc: 0.8125\n",
      "Train Epoch: 29 [32000/906425] Loss: 0.702282 Acc: 0.7500\n",
      "Train Epoch: 29 [48000/906425] Loss: 1.874267 Acc: 0.6250\n",
      "Train Epoch: 29 [64000/906425] Loss: 0.261057 Acc: 0.9375\n",
      "Train Epoch: 29 [80000/906425] Loss: 0.666510 Acc: 0.6875\n",
      "Train Epoch: 29 [96000/906425] Loss: 0.580748 Acc: 0.8750\n",
      "Train Epoch: 29 [112000/906425] Loss: 0.544717 Acc: 0.7500\n",
      "Train Epoch: 29 [128000/906425] Loss: 0.607646 Acc: 0.8125\n",
      "Train Epoch: 29 [144000/906425] Loss: 1.007869 Acc: 0.7500\n",
      "Train Epoch: 29 [160000/906425] Loss: 0.819620 Acc: 0.8750\n",
      "Train Epoch: 29 [176000/906425] Loss: 1.277341 Acc: 0.6250\n",
      "Train Epoch: 29 [192000/906425] Loss: 0.720282 Acc: 0.7500\n",
      "Train Epoch: 29 [208000/906425] Loss: 0.993536 Acc: 0.8750\n",
      "Train Epoch: 29 [224000/906425] Loss: 0.688383 Acc: 0.8125\n",
      "Train Epoch: 29 [240000/906425] Loss: 0.778966 Acc: 0.6250\n",
      "Train Epoch: 29 [256000/906425] Loss: 1.297705 Acc: 0.6875\n",
      "Train Epoch: 29 [272000/906425] Loss: 1.086483 Acc: 0.8125\n",
      "Train Epoch: 29 [288000/906425] Loss: 1.186381 Acc: 0.6250\n",
      "Train Epoch: 29 [304000/906425] Loss: 1.001141 Acc: 0.8125\n",
      "Train Epoch: 29 [320000/906425] Loss: 0.738213 Acc: 0.6250\n",
      "Train Epoch: 29 [336000/906425] Loss: 0.853626 Acc: 0.7500\n",
      "Train Epoch: 29 [352000/906425] Loss: 0.349634 Acc: 0.8750\n",
      "Train Epoch: 29 [368000/906425] Loss: 0.645526 Acc: 0.7500\n",
      "Train Epoch: 29 [384000/906425] Loss: 1.086859 Acc: 0.7500\n",
      "Train Epoch: 29 [400000/906425] Loss: 0.245863 Acc: 1.0000\n",
      "Train Epoch: 29 [416000/906425] Loss: 0.626608 Acc: 0.8750\n",
      "Train Epoch: 29 [432000/906425] Loss: 0.417578 Acc: 0.8125\n",
      "Train Epoch: 29 [448000/906425] Loss: 0.518342 Acc: 0.8750\n",
      "Train Epoch: 29 [464000/906425] Loss: 1.294763 Acc: 0.8125\n",
      "Train Epoch: 29 [480000/906425] Loss: 1.201624 Acc: 0.8125\n",
      "Train Epoch: 29 [496000/906425] Loss: 0.652791 Acc: 0.6875\n",
      "Train Epoch: 29 [512000/906425] Loss: 0.525549 Acc: 0.8750\n",
      "Train Epoch: 29 [528000/906425] Loss: 0.765547 Acc: 0.8750\n",
      "Train Epoch: 29 [544000/906425] Loss: 0.705590 Acc: 0.7500\n",
      "Train Epoch: 29 [560000/906425] Loss: 0.829830 Acc: 0.8125\n",
      "Train Epoch: 29 [576000/906425] Loss: 0.738472 Acc: 0.8125\n",
      "Train Epoch: 29 [592000/906425] Loss: 1.446166 Acc: 0.6875\n",
      "Train Epoch: 29 [608000/906425] Loss: 1.044768 Acc: 0.6875\n",
      "Train Epoch: 29 [624000/906425] Loss: 0.324550 Acc: 0.8750\n",
      "Train Epoch: 29 [640000/906425] Loss: 0.338652 Acc: 0.9375\n",
      "Train Epoch: 29 [656000/906425] Loss: 0.996945 Acc: 0.8125\n",
      "Train Epoch: 29 [672000/906425] Loss: 1.448892 Acc: 0.6875\n",
      "Train Epoch: 29 [688000/906425] Loss: 1.250467 Acc: 0.7500\n",
      "Train Epoch: 29 [704000/906425] Loss: 0.479169 Acc: 0.7500\n",
      "Train Epoch: 29 [720000/906425] Loss: 1.593705 Acc: 0.5625\n",
      "Train Epoch: 29 [736000/906425] Loss: 0.843660 Acc: 0.6250\n",
      "Train Epoch: 29 [752000/906425] Loss: 0.558622 Acc: 0.7500\n",
      "Train Epoch: 29 [768000/906425] Loss: 0.359236 Acc: 0.9375\n",
      "Train Epoch: 29 [784000/906425] Loss: 0.370182 Acc: 0.8750\n",
      "Train Epoch: 29 [800000/906425] Loss: 1.030141 Acc: 0.7500\n",
      "Train Epoch: 29 [816000/906425] Loss: 1.087668 Acc: 0.5625\n",
      "Train Epoch: 29 [832000/906425] Loss: 1.185047 Acc: 0.5625\n",
      "Train Epoch: 29 [848000/906425] Loss: 1.035497 Acc: 0.7500\n",
      "Train Epoch: 29 [864000/906425] Loss: 0.582312 Acc: 0.9375\n",
      "Train Epoch: 29 [880000/906425] Loss: 0.803839 Acc: 0.7500\n",
      "Train Epoch: 29 [896000/906425] Loss: 0.820359 Acc: 0.6250\n",
      "Elapsed 17284.59s, 576.15 s/epoch, 0.01 s/batch, ets 11523.06s\n",
      "\n",
      "Test set: Average loss: 1.4563, Accuracy: 203574/293785 (69%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 30 [16000/906425] Loss: 0.512950 Acc: 0.7500\n",
      "Train Epoch: 30 [32000/906425] Loss: 0.422951 Acc: 0.8750\n",
      "Train Epoch: 30 [48000/906425] Loss: 0.494437 Acc: 0.9375\n",
      "Train Epoch: 30 [64000/906425] Loss: 0.684649 Acc: 0.9375\n",
      "Train Epoch: 30 [80000/906425] Loss: 0.446325 Acc: 0.8125\n",
      "Train Epoch: 30 [96000/906425] Loss: 1.040243 Acc: 0.7500\n",
      "Train Epoch: 30 [112000/906425] Loss: 1.739174 Acc: 0.5000\n",
      "Train Epoch: 30 [128000/906425] Loss: 0.444071 Acc: 0.6875\n",
      "Train Epoch: 30 [144000/906425] Loss: 1.322581 Acc: 0.7500\n",
      "Train Epoch: 30 [160000/906425] Loss: 2.217311 Acc: 0.4375\n",
      "Train Epoch: 30 [176000/906425] Loss: 0.669266 Acc: 0.7500\n",
      "Train Epoch: 30 [192000/906425] Loss: 1.390273 Acc: 0.6250\n",
      "Train Epoch: 30 [208000/906425] Loss: 0.403860 Acc: 0.9375\n",
      "Train Epoch: 30 [224000/906425] Loss: 1.210851 Acc: 0.6875\n",
      "Train Epoch: 30 [240000/906425] Loss: 0.730642 Acc: 0.8125\n",
      "Train Epoch: 30 [256000/906425] Loss: 1.065583 Acc: 0.8125\n",
      "Train Epoch: 30 [272000/906425] Loss: 0.544969 Acc: 0.8125\n",
      "Train Epoch: 30 [288000/906425] Loss: 0.695653 Acc: 0.8125\n",
      "Train Epoch: 30 [304000/906425] Loss: 0.885971 Acc: 0.6875\n",
      "Train Epoch: 30 [320000/906425] Loss: 0.952553 Acc: 0.5625\n",
      "Train Epoch: 30 [336000/906425] Loss: 0.464213 Acc: 0.8125\n",
      "Train Epoch: 30 [352000/906425] Loss: 0.769888 Acc: 0.8750\n",
      "Train Epoch: 30 [368000/906425] Loss: 0.945860 Acc: 0.7500\n",
      "Train Epoch: 30 [384000/906425] Loss: 0.194563 Acc: 0.9375\n",
      "Train Epoch: 30 [400000/906425] Loss: 0.155624 Acc: 1.0000\n",
      "Train Epoch: 30 [416000/906425] Loss: 0.863485 Acc: 0.7500\n",
      "Train Epoch: 30 [432000/906425] Loss: 1.390788 Acc: 0.5000\n",
      "Train Epoch: 30 [448000/906425] Loss: 0.391705 Acc: 0.9375\n",
      "Train Epoch: 30 [464000/906425] Loss: 0.796175 Acc: 0.7500\n",
      "Train Epoch: 30 [480000/906425] Loss: 0.655941 Acc: 0.8125\n",
      "Train Epoch: 30 [496000/906425] Loss: 0.946615 Acc: 0.6875\n",
      "Train Epoch: 30 [512000/906425] Loss: 1.165286 Acc: 0.6250\n",
      "Train Epoch: 30 [528000/906425] Loss: 0.542024 Acc: 0.8750\n",
      "Train Epoch: 30 [544000/906425] Loss: 0.548131 Acc: 0.8750\n",
      "Train Epoch: 30 [560000/906425] Loss: 1.277307 Acc: 0.7500\n",
      "Train Epoch: 30 [576000/906425] Loss: 1.077081 Acc: 0.7500\n",
      "Train Epoch: 30 [592000/906425] Loss: 0.956506 Acc: 0.8125\n",
      "Train Epoch: 30 [608000/906425] Loss: 0.985113 Acc: 0.8125\n",
      "Train Epoch: 30 [624000/906425] Loss: 0.497581 Acc: 0.8750\n",
      "Train Epoch: 30 [640000/906425] Loss: 0.706864 Acc: 0.7500\n",
      "Train Epoch: 30 [656000/906425] Loss: 0.743245 Acc: 0.8125\n",
      "Train Epoch: 30 [672000/906425] Loss: 0.574711 Acc: 0.8125\n",
      "Train Epoch: 30 [688000/906425] Loss: 0.722053 Acc: 0.7500\n",
      "Train Epoch: 30 [704000/906425] Loss: 0.670591 Acc: 0.8750\n",
      "Train Epoch: 30 [720000/906425] Loss: 0.496091 Acc: 0.8750\n",
      "Train Epoch: 30 [736000/906425] Loss: 1.098782 Acc: 0.7500\n",
      "Train Epoch: 30 [752000/906425] Loss: 1.083910 Acc: 0.6250\n",
      "Train Epoch: 30 [768000/906425] Loss: 0.652992 Acc: 0.8750\n",
      "Train Epoch: 30 [784000/906425] Loss: 1.183280 Acc: 0.7500\n",
      "Train Epoch: 30 [800000/906425] Loss: 1.185003 Acc: 0.6875\n",
      "Train Epoch: 30 [816000/906425] Loss: 0.810550 Acc: 0.8125\n",
      "Train Epoch: 30 [832000/906425] Loss: 0.826168 Acc: 0.7500\n",
      "Train Epoch: 30 [848000/906425] Loss: 1.127832 Acc: 0.6875\n",
      "Train Epoch: 30 [864000/906425] Loss: 1.523858 Acc: 0.6250\n",
      "Train Epoch: 30 [880000/906425] Loss: 1.216027 Acc: 0.6875\n",
      "Train Epoch: 30 [896000/906425] Loss: 1.857683 Acc: 0.5000\n",
      "Elapsed 17863.66s, 576.25 s/epoch, 0.01 s/batch, ets 10948.70s\n",
      "\n",
      "Test set: Average loss: 1.4674, Accuracy: 202531/293785 (69%)\n",
      "\n",
      "Train Epoch: 31 [16000/906425] Loss: 0.860752 Acc: 0.8750\n",
      "Train Epoch: 31 [32000/906425] Loss: 0.986852 Acc: 0.7500\n",
      "Train Epoch: 31 [48000/906425] Loss: 0.660443 Acc: 0.8125\n",
      "Train Epoch: 31 [64000/906425] Loss: 0.721655 Acc: 0.8750\n",
      "Train Epoch: 31 [80000/906425] Loss: 0.782222 Acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [96000/906425] Loss: 0.518069 Acc: 0.8125\n",
      "Train Epoch: 31 [112000/906425] Loss: 0.734704 Acc: 0.7500\n",
      "Train Epoch: 31 [128000/906425] Loss: 0.592658 Acc: 0.8125\n",
      "Train Epoch: 31 [144000/906425] Loss: 0.323558 Acc: 0.9375\n",
      "Train Epoch: 31 [160000/906425] Loss: 0.718796 Acc: 0.7500\n",
      "Train Epoch: 31 [176000/906425] Loss: 1.482507 Acc: 0.6875\n",
      "Train Epoch: 31 [192000/906425] Loss: 0.503562 Acc: 0.8750\n",
      "Train Epoch: 31 [208000/906425] Loss: 0.292537 Acc: 0.9375\n",
      "Train Epoch: 31 [224000/906425] Loss: 0.955565 Acc: 0.8750\n",
      "Train Epoch: 31 [240000/906425] Loss: 0.254513 Acc: 0.9375\n",
      "Train Epoch: 31 [256000/906425] Loss: 0.601350 Acc: 0.8750\n",
      "Train Epoch: 31 [272000/906425] Loss: 0.942169 Acc: 0.6875\n",
      "Train Epoch: 31 [288000/906425] Loss: 0.926300 Acc: 0.6875\n",
      "Train Epoch: 31 [304000/906425] Loss: 0.827477 Acc: 0.7500\n",
      "Train Epoch: 31 [320000/906425] Loss: 0.927550 Acc: 0.7500\n",
      "Train Epoch: 31 [336000/906425] Loss: 1.758231 Acc: 0.6250\n",
      "Train Epoch: 31 [352000/906425] Loss: 0.720044 Acc: 0.8125\n",
      "Train Epoch: 31 [368000/906425] Loss: 0.350266 Acc: 0.9375\n",
      "Train Epoch: 31 [384000/906425] Loss: 1.309885 Acc: 0.7500\n",
      "Train Epoch: 31 [400000/906425] Loss: 0.678503 Acc: 0.8125\n",
      "Train Epoch: 31 [416000/906425] Loss: 0.962440 Acc: 0.7500\n",
      "Train Epoch: 31 [432000/906425] Loss: 0.399466 Acc: 0.8750\n",
      "Train Epoch: 31 [448000/906425] Loss: 0.696571 Acc: 0.7500\n",
      "Train Epoch: 31 [464000/906425] Loss: 0.671045 Acc: 0.8750\n",
      "Train Epoch: 31 [480000/906425] Loss: 1.737466 Acc: 0.5000\n",
      "Train Epoch: 31 [496000/906425] Loss: 0.987704 Acc: 0.6875\n",
      "Train Epoch: 31 [512000/906425] Loss: 1.207084 Acc: 0.8750\n",
      "Train Epoch: 31 [528000/906425] Loss: 0.917317 Acc: 0.8125\n",
      "Train Epoch: 31 [544000/906425] Loss: 0.627630 Acc: 0.8125\n",
      "Train Epoch: 31 [560000/906425] Loss: 1.108475 Acc: 0.7500\n",
      "Train Epoch: 31 [576000/906425] Loss: 0.688218 Acc: 0.8125\n",
      "Train Epoch: 31 [592000/906425] Loss: 0.890060 Acc: 0.6250\n",
      "Train Epoch: 31 [608000/906425] Loss: 0.919031 Acc: 0.7500\n",
      "Train Epoch: 31 [624000/906425] Loss: 0.490334 Acc: 0.8125\n",
      "Train Epoch: 31 [640000/906425] Loss: 0.796182 Acc: 0.7500\n",
      "Train Epoch: 31 [656000/906425] Loss: 0.699853 Acc: 0.7500\n",
      "Train Epoch: 31 [672000/906425] Loss: 0.246195 Acc: 0.9375\n",
      "Train Epoch: 31 [688000/906425] Loss: 0.704817 Acc: 0.8125\n",
      "Train Epoch: 31 [704000/906425] Loss: 1.407112 Acc: 0.5625\n",
      "Train Epoch: 31 [720000/906425] Loss: 1.968374 Acc: 0.5625\n",
      "Train Epoch: 31 [736000/906425] Loss: 0.306507 Acc: 0.8750\n",
      "Train Epoch: 31 [752000/906425] Loss: 1.276868 Acc: 0.7500\n",
      "Train Epoch: 31 [768000/906425] Loss: 0.582399 Acc: 0.9375\n",
      "Train Epoch: 31 [784000/906425] Loss: 1.274459 Acc: 0.8125\n",
      "Train Epoch: 31 [800000/906425] Loss: 0.821642 Acc: 0.6875\n",
      "Train Epoch: 31 [816000/906425] Loss: 0.779500 Acc: 0.7500\n",
      "Train Epoch: 31 [832000/906425] Loss: 0.575222 Acc: 0.9375\n",
      "Train Epoch: 31 [848000/906425] Loss: 0.958988 Acc: 0.7500\n",
      "Train Epoch: 31 [864000/906425] Loss: 0.909653 Acc: 0.8125\n",
      "Train Epoch: 31 [880000/906425] Loss: 0.652794 Acc: 0.6875\n",
      "Train Epoch: 31 [896000/906425] Loss: 0.929630 Acc: 0.8125\n",
      "Elapsed 18442.42s, 576.33 s/epoch, 0.01 s/batch, ets 10373.86s\n",
      "\n",
      "Test set: Average loss: 1.4440, Accuracy: 204810/293785 (70%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 32 [16000/906425] Loss: 0.520647 Acc: 0.7500\n",
      "Train Epoch: 32 [32000/906425] Loss: 1.029832 Acc: 0.6875\n",
      "Train Epoch: 32 [48000/906425] Loss: 0.835472 Acc: 0.6875\n",
      "Train Epoch: 32 [64000/906425] Loss: 0.577901 Acc: 0.8125\n",
      "Train Epoch: 32 [80000/906425] Loss: 0.355690 Acc: 0.9375\n",
      "Train Epoch: 32 [96000/906425] Loss: 1.066461 Acc: 0.6250\n",
      "Train Epoch: 32 [112000/906425] Loss: 0.593379 Acc: 0.8750\n",
      "Train Epoch: 32 [128000/906425] Loss: 0.341568 Acc: 0.8750\n",
      "Train Epoch: 32 [144000/906425] Loss: 0.214440 Acc: 1.0000\n",
      "Train Epoch: 32 [160000/906425] Loss: 0.686314 Acc: 0.7500\n",
      "Train Epoch: 32 [176000/906425] Loss: 1.421653 Acc: 0.6875\n",
      "Train Epoch: 32 [192000/906425] Loss: 0.563034 Acc: 0.8750\n",
      "Train Epoch: 32 [208000/906425] Loss: 1.173938 Acc: 0.7500\n",
      "Train Epoch: 32 [224000/906425] Loss: 0.297633 Acc: 0.9375\n",
      "Train Epoch: 32 [240000/906425] Loss: 1.358427 Acc: 0.6250\n",
      "Train Epoch: 32 [256000/906425] Loss: 0.578951 Acc: 0.8750\n",
      "Train Epoch: 32 [272000/906425] Loss: 0.893475 Acc: 0.8125\n",
      "Train Epoch: 32 [288000/906425] Loss: 0.611226 Acc: 0.7500\n",
      "Train Epoch: 32 [304000/906425] Loss: 0.991035 Acc: 0.6875\n",
      "Train Epoch: 32 [320000/906425] Loss: 0.283599 Acc: 0.9375\n",
      "Train Epoch: 32 [336000/906425] Loss: 0.985789 Acc: 0.7500\n",
      "Train Epoch: 32 [352000/906425] Loss: 1.161630 Acc: 0.6250\n",
      "Train Epoch: 32 [368000/906425] Loss: 1.411632 Acc: 0.6250\n",
      "Train Epoch: 32 [384000/906425] Loss: 0.989552 Acc: 0.7500\n",
      "Train Epoch: 32 [400000/906425] Loss: 1.120988 Acc: 0.7500\n",
      "Train Epoch: 32 [416000/906425] Loss: 0.685501 Acc: 0.8125\n",
      "Train Epoch: 32 [432000/906425] Loss: 0.752539 Acc: 0.8125\n",
      "Train Epoch: 32 [448000/906425] Loss: 0.357564 Acc: 0.8750\n",
      "Train Epoch: 32 [464000/906425] Loss: 0.737475 Acc: 0.7500\n",
      "Train Epoch: 32 [480000/906425] Loss: 0.607311 Acc: 0.9375\n",
      "Train Epoch: 32 [496000/906425] Loss: 0.132743 Acc: 0.9375\n",
      "Train Epoch: 32 [512000/906425] Loss: 1.372784 Acc: 0.6250\n",
      "Train Epoch: 32 [528000/906425] Loss: 0.865160 Acc: 0.8125\n",
      "Train Epoch: 32 [544000/906425] Loss: 0.448131 Acc: 0.8750\n",
      "Train Epoch: 32 [560000/906425] Loss: 0.333252 Acc: 0.8750\n",
      "Train Epoch: 32 [576000/906425] Loss: 1.349870 Acc: 0.5625\n",
      "Train Epoch: 32 [592000/906425] Loss: 0.840788 Acc: 0.8125\n",
      "Train Epoch: 32 [608000/906425] Loss: 0.893594 Acc: 0.8125\n",
      "Train Epoch: 32 [624000/906425] Loss: 1.178654 Acc: 0.6875\n",
      "Train Epoch: 32 [640000/906425] Loss: 1.097216 Acc: 0.6875\n",
      "Train Epoch: 32 [656000/906425] Loss: 0.462682 Acc: 0.9375\n",
      "Train Epoch: 32 [672000/906425] Loss: 0.954435 Acc: 0.8125\n",
      "Train Epoch: 32 [688000/906425] Loss: 0.202766 Acc: 0.9375\n",
      "Train Epoch: 32 [704000/906425] Loss: 0.461566 Acc: 0.8750\n",
      "Train Epoch: 32 [720000/906425] Loss: 0.141427 Acc: 1.0000\n",
      "Train Epoch: 32 [736000/906425] Loss: 0.577404 Acc: 0.8750\n",
      "Train Epoch: 32 [752000/906425] Loss: 0.407072 Acc: 0.8750\n",
      "Train Epoch: 32 [768000/906425] Loss: 0.781744 Acc: 0.8125\n",
      "Train Epoch: 32 [784000/906425] Loss: 1.174327 Acc: 0.5625\n",
      "Train Epoch: 32 [800000/906425] Loss: 0.126132 Acc: 1.0000\n",
      "Train Epoch: 32 [816000/906425] Loss: 0.890184 Acc: 0.7500\n",
      "Train Epoch: 32 [832000/906425] Loss: 1.205432 Acc: 0.6250\n",
      "Train Epoch: 32 [848000/906425] Loss: 1.023567 Acc: 0.6875\n",
      "Train Epoch: 32 [864000/906425] Loss: 0.698012 Acc: 0.8125\n",
      "Train Epoch: 32 [880000/906425] Loss: 0.841311 Acc: 0.7500\n",
      "Train Epoch: 32 [896000/906425] Loss: 0.538410 Acc: 0.8750\n",
      "Elapsed 19021.66s, 576.41 s/epoch, 0.01 s/batch, ets 9799.04s\n",
      "\n",
      "Test set: Average loss: 1.4356, Accuracy: 205948/293785 (70%)\n",
      "\n",
      "Loss decreases, saving the model.\n",
      "\n",
      "Train Epoch: 33 [16000/906425] Loss: 0.689629 Acc: 0.9375\n",
      "Train Epoch: 33 [32000/906425] Loss: 0.846707 Acc: 0.7500\n",
      "Train Epoch: 33 [48000/906425] Loss: 1.345441 Acc: 0.6250\n",
      "Train Epoch: 33 [64000/906425] Loss: 1.207398 Acc: 0.6875\n",
      "Train Epoch: 33 [80000/906425] Loss: 1.078199 Acc: 0.6875\n",
      "Train Epoch: 33 [96000/906425] Loss: 0.708526 Acc: 0.7500\n",
      "Train Epoch: 33 [112000/906425] Loss: 0.680305 Acc: 0.8125\n",
      "Train Epoch: 33 [128000/906425] Loss: 0.961152 Acc: 0.6250\n",
      "Train Epoch: 33 [144000/906425] Loss: 0.957596 Acc: 0.7500\n",
      "Train Epoch: 33 [160000/906425] Loss: 0.489183 Acc: 0.8125\n",
      "Train Epoch: 33 [176000/906425] Loss: 0.492444 Acc: 0.8125\n",
      "Train Epoch: 33 [192000/906425] Loss: 0.688603 Acc: 0.7500\n",
      "Train Epoch: 33 [208000/906425] Loss: 0.616633 Acc: 0.7500\n",
      "Train Epoch: 33 [224000/906425] Loss: 0.725372 Acc: 0.6875\n",
      "Train Epoch: 33 [240000/906425] Loss: 0.465521 Acc: 0.8750\n",
      "Train Epoch: 33 [256000/906425] Loss: 0.447150 Acc: 0.8125\n",
      "Train Epoch: 33 [272000/906425] Loss: 0.415306 Acc: 0.9375\n",
      "Train Epoch: 33 [288000/906425] Loss: 0.527375 Acc: 0.8750\n",
      "Train Epoch: 33 [304000/906425] Loss: 0.544857 Acc: 0.7500\n",
      "Train Epoch: 33 [320000/906425] Loss: 1.103101 Acc: 0.6875\n",
      "Train Epoch: 33 [336000/906425] Loss: 0.888568 Acc: 0.7500\n",
      "Train Epoch: 33 [352000/906425] Loss: 1.310386 Acc: 0.6250\n",
      "Train Epoch: 33 [368000/906425] Loss: 0.946981 Acc: 0.6875\n",
      "Train Epoch: 33 [384000/906425] Loss: 0.844337 Acc: 0.7500\n",
      "Train Epoch: 33 [400000/906425] Loss: 0.758234 Acc: 0.7500\n",
      "Train Epoch: 33 [416000/906425] Loss: 0.513812 Acc: 0.8125\n",
      "Train Epoch: 33 [432000/906425] Loss: 0.317439 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [448000/906425] Loss: 0.411357 Acc: 0.8750\n",
      "Train Epoch: 33 [464000/906425] Loss: 0.872488 Acc: 0.7500\n",
      "Train Epoch: 33 [480000/906425] Loss: 1.092809 Acc: 0.8125\n",
      "Train Epoch: 33 [496000/906425] Loss: 0.602323 Acc: 0.7500\n",
      "Train Epoch: 33 [512000/906425] Loss: 0.513874 Acc: 0.8750\n",
      "Train Epoch: 33 [528000/906425] Loss: 0.766363 Acc: 0.7500\n",
      "Train Epoch: 33 [544000/906425] Loss: 0.561193 Acc: 0.8125\n",
      "Train Epoch: 33 [560000/906425] Loss: 1.141042 Acc: 0.7500\n",
      "Train Epoch: 33 [576000/906425] Loss: 0.683662 Acc: 0.7500\n",
      "Train Epoch: 33 [592000/906425] Loss: 0.847224 Acc: 0.6875\n",
      "Train Epoch: 33 [608000/906425] Loss: 0.701248 Acc: 0.8125\n",
      "Train Epoch: 33 [624000/906425] Loss: 0.741116 Acc: 0.7500\n",
      "Train Epoch: 33 [640000/906425] Loss: 0.779173 Acc: 0.7500\n",
      "Train Epoch: 33 [656000/906425] Loss: 1.630859 Acc: 0.7500\n",
      "Train Epoch: 33 [672000/906425] Loss: 2.164981 Acc: 0.5625\n",
      "Train Epoch: 33 [688000/906425] Loss: 1.153666 Acc: 0.6875\n",
      "Train Epoch: 33 [704000/906425] Loss: 1.598678 Acc: 0.6875\n",
      "Train Epoch: 33 [720000/906425] Loss: 0.299120 Acc: 0.9375\n",
      "Train Epoch: 33 [736000/906425] Loss: 0.913292 Acc: 0.7500\n",
      "Train Epoch: 33 [752000/906425] Loss: 0.506750 Acc: 0.8750\n",
      "Train Epoch: 33 [768000/906425] Loss: 1.021001 Acc: 0.6250\n",
      "Train Epoch: 33 [784000/906425] Loss: 1.129423 Acc: 0.6875\n",
      "Train Epoch: 33 [800000/906425] Loss: 0.741172 Acc: 0.7500\n",
      "Train Epoch: 33 [816000/906425] Loss: 0.311015 Acc: 0.9375\n",
      "Train Epoch: 33 [832000/906425] Loss: 0.425203 Acc: 0.8125\n",
      "Train Epoch: 33 [848000/906425] Loss: 0.829783 Acc: 0.8125\n",
      "Train Epoch: 33 [864000/906425] Loss: 0.869935 Acc: 0.6875\n",
      "Train Epoch: 33 [880000/906425] Loss: 1.148398 Acc: 0.7500\n",
      "Train Epoch: 33 [896000/906425] Loss: 1.192403 Acc: 0.6250\n",
      "Elapsed 19601.08s, 576.50 s/epoch, 0.01 s/batch, ets 9224.04s\n",
      "\n",
      "Test set: Average loss: 1.4529, Accuracy: 205461/293785 (70%)\n",
      "\n",
      "Train Epoch: 34 [16000/906425] Loss: 0.616008 Acc: 0.7500\n",
      "Train Epoch: 34 [32000/906425] Loss: 0.647720 Acc: 0.7500\n",
      "Train Epoch: 34 [48000/906425] Loss: 0.322554 Acc: 0.8750\n",
      "Train Epoch: 34 [64000/906425] Loss: 0.841737 Acc: 0.7500\n",
      "Train Epoch: 34 [80000/906425] Loss: 0.836203 Acc: 0.6875\n",
      "Train Epoch: 34 [96000/906425] Loss: 0.790032 Acc: 0.6875\n",
      "Train Epoch: 34 [112000/906425] Loss: 0.279545 Acc: 0.8750\n",
      "Train Epoch: 34 [128000/906425] Loss: 1.246862 Acc: 0.7500\n",
      "Train Epoch: 34 [144000/906425] Loss: 0.605746 Acc: 0.7500\n",
      "Train Epoch: 34 [160000/906425] Loss: 1.012986 Acc: 0.8750\n",
      "Train Epoch: 34 [176000/906425] Loss: 1.367577 Acc: 0.6250\n",
      "Train Epoch: 34 [192000/906425] Loss: 0.532206 Acc: 0.8125\n",
      "Train Epoch: 34 [208000/906425] Loss: 0.521494 Acc: 0.9375\n",
      "Train Epoch: 34 [224000/906425] Loss: 0.423751 Acc: 0.9375\n",
      "Train Epoch: 34 [240000/906425] Loss: 0.331298 Acc: 0.8125\n",
      "Train Epoch: 34 [256000/906425] Loss: 0.648194 Acc: 0.8125\n",
      "Train Epoch: 34 [272000/906425] Loss: 0.430909 Acc: 0.8125\n",
      "Train Epoch: 34 [288000/906425] Loss: 1.247257 Acc: 0.5625\n",
      "Train Epoch: 34 [304000/906425] Loss: 0.683264 Acc: 0.8125\n",
      "Train Epoch: 34 [320000/906425] Loss: 0.929557 Acc: 0.7500\n",
      "Train Epoch: 34 [336000/906425] Loss: 0.263687 Acc: 0.8750\n",
      "Train Epoch: 34 [352000/906425] Loss: 0.561912 Acc: 0.6875\n",
      "Train Epoch: 34 [368000/906425] Loss: 0.623812 Acc: 0.8750\n",
      "Train Epoch: 34 [384000/906425] Loss: 0.837583 Acc: 0.8125\n",
      "Train Epoch: 34 [400000/906425] Loss: 0.287795 Acc: 1.0000\n",
      "Train Epoch: 34 [416000/906425] Loss: 0.180630 Acc: 1.0000\n",
      "Train Epoch: 34 [432000/906425] Loss: 0.535320 Acc: 0.8125\n",
      "Train Epoch: 34 [448000/906425] Loss: 0.427532 Acc: 0.8750\n",
      "Train Epoch: 34 [464000/906425] Loss: 0.259813 Acc: 0.8750\n",
      "Train Epoch: 34 [480000/906425] Loss: 0.388957 Acc: 0.9375\n",
      "Train Epoch: 34 [496000/906425] Loss: 0.626517 Acc: 0.6250\n",
      "Train Epoch: 34 [512000/906425] Loss: 0.852440 Acc: 0.6875\n",
      "Train Epoch: 34 [528000/906425] Loss: 0.929561 Acc: 0.6875\n",
      "Train Epoch: 34 [544000/906425] Loss: 0.731820 Acc: 0.8125\n",
      "Train Epoch: 34 [560000/906425] Loss: 0.617202 Acc: 0.8750\n",
      "Train Epoch: 34 [576000/906425] Loss: 0.825320 Acc: 0.8125\n",
      "Train Epoch: 34 [592000/906425] Loss: 1.154136 Acc: 0.7500\n",
      "Train Epoch: 34 [608000/906425] Loss: 1.633296 Acc: 0.6875\n",
      "Train Epoch: 34 [624000/906425] Loss: 1.520195 Acc: 0.5000\n",
      "Train Epoch: 34 [640000/906425] Loss: 0.582945 Acc: 0.8750\n",
      "Train Epoch: 34 [656000/906425] Loss: 1.834307 Acc: 0.5625\n",
      "Train Epoch: 34 [672000/906425] Loss: 1.298734 Acc: 0.6250\n",
      "Train Epoch: 34 [688000/906425] Loss: 0.918968 Acc: 0.8125\n",
      "Train Epoch: 34 [704000/906425] Loss: 1.254575 Acc: 0.6875\n",
      "Train Epoch: 34 [720000/906425] Loss: 0.232802 Acc: 1.0000\n",
      "Train Epoch: 34 [736000/906425] Loss: 0.963464 Acc: 0.6875\n",
      "Train Epoch: 34 [752000/906425] Loss: 0.720850 Acc: 0.8125\n",
      "Train Epoch: 34 [768000/906425] Loss: 0.322597 Acc: 0.9375\n",
      "Train Epoch: 34 [784000/906425] Loss: 0.873886 Acc: 0.7500\n",
      "Train Epoch: 34 [800000/906425] Loss: 1.216059 Acc: 0.7500\n",
      "Train Epoch: 34 [816000/906425] Loss: 1.166910 Acc: 0.6875\n",
      "Train Epoch: 34 [832000/906425] Loss: 0.770711 Acc: 0.6875\n",
      "Train Epoch: 34 [848000/906425] Loss: 1.254550 Acc: 0.7500\n",
      "Train Epoch: 34 [864000/906425] Loss: 0.684442 Acc: 0.8125\n",
      "Train Epoch: 34 [880000/906425] Loss: 0.323171 Acc: 0.9375\n",
      "Train Epoch: 34 [896000/906425] Loss: 0.582085 Acc: 0.8750\n",
      "Elapsed 20179.57s, 576.56 s/epoch, 0.01 s/batch, ets 8648.39s\n",
      "\n",
      "Test set: Average loss: 1.4570, Accuracy: 205991/293785 (70%)\n",
      "\n",
      "Train Epoch: 35 [16000/906425] Loss: 0.783837 Acc: 0.8750\n",
      "Train Epoch: 35 [32000/906425] Loss: 0.646330 Acc: 0.8125\n",
      "Train Epoch: 35 [48000/906425] Loss: 0.480932 Acc: 0.8750\n",
      "Train Epoch: 35 [64000/906425] Loss: 0.574653 Acc: 0.9375\n",
      "Train Epoch: 35 [80000/906425] Loss: 0.767692 Acc: 0.9375\n",
      "Train Epoch: 35 [96000/906425] Loss: 0.687830 Acc: 0.8750\n",
      "Train Epoch: 35 [112000/906425] Loss: 0.570470 Acc: 0.8125\n",
      "Train Epoch: 35 [128000/906425] Loss: 0.942610 Acc: 0.8125\n",
      "Train Epoch: 35 [144000/906425] Loss: 1.259960 Acc: 0.6875\n",
      "Train Epoch: 35 [160000/906425] Loss: 0.596481 Acc: 0.8750\n",
      "Train Epoch: 35 [176000/906425] Loss: 0.986346 Acc: 0.7500\n",
      "Train Epoch: 35 [192000/906425] Loss: 0.644812 Acc: 0.8750\n",
      "Train Epoch: 35 [208000/906425] Loss: 1.229264 Acc: 0.6875\n",
      "Train Epoch: 35 [224000/906425] Loss: 0.641732 Acc: 0.8125\n",
      "Train Epoch: 35 [240000/906425] Loss: 0.330033 Acc: 0.8750\n",
      "Train Epoch: 35 [256000/906425] Loss: 0.828897 Acc: 0.9375\n",
      "Train Epoch: 35 [272000/906425] Loss: 1.434497 Acc: 0.6875\n",
      "Train Epoch: 35 [288000/906425] Loss: 0.998142 Acc: 0.6875\n",
      "Train Epoch: 35 [304000/906425] Loss: 0.598395 Acc: 0.8125\n",
      "Train Epoch: 35 [320000/906425] Loss: 0.818907 Acc: 0.8125\n",
      "Train Epoch: 35 [336000/906425] Loss: 0.775102 Acc: 0.8125\n",
      "Train Epoch: 35 [352000/906425] Loss: 1.014076 Acc: 0.8125\n",
      "Train Epoch: 35 [368000/906425] Loss: 0.914111 Acc: 0.7500\n",
      "Train Epoch: 35 [384000/906425] Loss: 0.768115 Acc: 0.8125\n",
      "Train Epoch: 35 [400000/906425] Loss: 1.332048 Acc: 0.6250\n",
      "Train Epoch: 35 [416000/906425] Loss: 0.858258 Acc: 0.8125\n",
      "Train Epoch: 35 [432000/906425] Loss: 0.408950 Acc: 0.8750\n",
      "Train Epoch: 35 [448000/906425] Loss: 0.647856 Acc: 0.8125\n",
      "Train Epoch: 35 [464000/906425] Loss: 1.125185 Acc: 0.8125\n",
      "Train Epoch: 35 [480000/906425] Loss: 1.337965 Acc: 0.6875\n",
      "Train Epoch: 35 [496000/906425] Loss: 1.144182 Acc: 0.7500\n",
      "Train Epoch: 35 [512000/906425] Loss: 0.226525 Acc: 1.0000\n",
      "Train Epoch: 35 [528000/906425] Loss: 1.189845 Acc: 0.6875\n",
      "Train Epoch: 35 [544000/906425] Loss: 0.580639 Acc: 0.7500\n",
      "Train Epoch: 35 [560000/906425] Loss: 0.825853 Acc: 0.8750\n",
      "Train Epoch: 35 [576000/906425] Loss: 0.960311 Acc: 0.8125\n",
      "Train Epoch: 35 [592000/906425] Loss: 1.113107 Acc: 0.7500\n",
      "Train Epoch: 35 [608000/906425] Loss: 0.553120 Acc: 0.7500\n",
      "Train Epoch: 35 [624000/906425] Loss: 0.827028 Acc: 0.6250\n",
      "Train Epoch: 35 [640000/906425] Loss: 0.817154 Acc: 0.8125\n",
      "Train Epoch: 35 [656000/906425] Loss: 0.128568 Acc: 0.9375\n",
      "Train Epoch: 35 [672000/906425] Loss: 0.700827 Acc: 0.7500\n",
      "Train Epoch: 35 [688000/906425] Loss: 0.775496 Acc: 0.8125\n",
      "Train Epoch: 35 [704000/906425] Loss: 1.565105 Acc: 0.6250\n",
      "Train Epoch: 35 [720000/906425] Loss: 1.112205 Acc: 0.8750\n",
      "Train Epoch: 35 [736000/906425] Loss: 1.277439 Acc: 0.7500\n",
      "Train Epoch: 35 [752000/906425] Loss: 0.654660 Acc: 0.7500\n",
      "Train Epoch: 35 [768000/906425] Loss: 0.535513 Acc: 0.8750\n",
      "Train Epoch: 35 [784000/906425] Loss: 0.808873 Acc: 0.8125\n",
      "Train Epoch: 35 [800000/906425] Loss: 0.280052 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [816000/906425] Loss: 0.872499 Acc: 0.6875\n",
      "Train Epoch: 35 [832000/906425] Loss: 0.139417 Acc: 1.0000\n",
      "Train Epoch: 35 [848000/906425] Loss: 1.382111 Acc: 0.6875\n",
      "Train Epoch: 35 [864000/906425] Loss: 0.267756 Acc: 0.9375\n",
      "Train Epoch: 35 [880000/906425] Loss: 0.346392 Acc: 0.7500\n",
      "Train Epoch: 35 [896000/906425] Loss: 0.998576 Acc: 0.6875\n",
      "Elapsed 20758.27s, 576.62 s/epoch, 0.01 s/batch, ets 8072.66s\n",
      "\n",
      "Test set: Average loss: 1.4507, Accuracy: 206671/293785 (70%)\n",
      "\n",
      "Train Epoch: 36 [16000/906425] Loss: 1.554818 Acc: 0.5625\n",
      "Train Epoch: 36 [32000/906425] Loss: 0.838172 Acc: 0.8125\n",
      "Train Epoch: 36 [48000/906425] Loss: 1.130947 Acc: 0.7500\n",
      "Train Epoch: 36 [64000/906425] Loss: 0.363632 Acc: 0.8750\n",
      "Train Epoch: 36 [80000/906425] Loss: 0.933908 Acc: 0.7500\n",
      "Train Epoch: 36 [96000/906425] Loss: 0.807146 Acc: 0.8125\n",
      "Train Epoch: 36 [112000/906425] Loss: 0.285988 Acc: 0.9375\n",
      "Train Epoch: 36 [128000/906425] Loss: 0.489803 Acc: 0.8125\n",
      "Train Epoch: 36 [144000/906425] Loss: 0.645725 Acc: 0.8750\n",
      "Train Epoch: 36 [160000/906425] Loss: 1.358723 Acc: 0.6875\n",
      "Train Epoch: 36 [176000/906425] Loss: 0.478685 Acc: 0.8750\n",
      "Train Epoch: 36 [192000/906425] Loss: 0.856548 Acc: 0.7500\n",
      "Train Epoch: 36 [208000/906425] Loss: 0.637247 Acc: 0.8125\n",
      "Train Epoch: 36 [224000/906425] Loss: 0.604621 Acc: 0.8750\n",
      "Train Epoch: 36 [240000/906425] Loss: 0.714536 Acc: 0.8125\n",
      "Train Epoch: 36 [256000/906425] Loss: 1.245362 Acc: 0.7500\n",
      "Train Epoch: 36 [272000/906425] Loss: 0.679862 Acc: 0.8125\n",
      "Train Epoch: 36 [288000/906425] Loss: 0.317996 Acc: 0.8750\n",
      "Train Epoch: 36 [304000/906425] Loss: 0.656788 Acc: 0.8750\n",
      "Train Epoch: 36 [320000/906425] Loss: 1.012701 Acc: 0.5625\n",
      "Train Epoch: 36 [336000/906425] Loss: 0.875522 Acc: 0.7500\n",
      "Train Epoch: 36 [352000/906425] Loss: 0.651088 Acc: 0.8125\n",
      "Train Epoch: 36 [368000/906425] Loss: 0.406076 Acc: 0.8750\n",
      "Train Epoch: 36 [384000/906425] Loss: 0.510392 Acc: 0.8125\n",
      "Train Epoch: 36 [400000/906425] Loss: 1.040438 Acc: 0.6875\n",
      "Train Epoch: 36 [416000/906425] Loss: 0.696628 Acc: 0.7500\n",
      "Train Epoch: 36 [432000/906425] Loss: 0.850373 Acc: 0.7500\n",
      "Train Epoch: 36 [448000/906425] Loss: 0.895895 Acc: 0.7500\n",
      "Train Epoch: 36 [464000/906425] Loss: 0.907557 Acc: 0.6875\n",
      "Train Epoch: 36 [480000/906425] Loss: 0.484616 Acc: 0.8750\n",
      "Train Epoch: 36 [496000/906425] Loss: 1.780008 Acc: 0.5625\n",
      "Train Epoch: 36 [512000/906425] Loss: 0.690913 Acc: 0.8125\n",
      "Train Epoch: 36 [528000/906425] Loss: 1.056930 Acc: 0.6250\n",
      "Train Epoch: 36 [544000/906425] Loss: 0.152505 Acc: 0.9375\n",
      "Train Epoch: 36 [560000/906425] Loss: 0.910747 Acc: 0.8125\n",
      "Train Epoch: 36 [576000/906425] Loss: 0.547422 Acc: 0.9375\n",
      "Train Epoch: 36 [592000/906425] Loss: 0.919424 Acc: 0.7500\n",
      "Train Epoch: 36 [608000/906425] Loss: 0.990874 Acc: 0.6875\n",
      "Train Epoch: 36 [624000/906425] Loss: 1.347283 Acc: 0.7500\n",
      "Train Epoch: 36 [640000/906425] Loss: 0.829673 Acc: 0.8125\n",
      "Train Epoch: 36 [656000/906425] Loss: 0.275140 Acc: 0.9375\n",
      "Train Epoch: 36 [672000/906425] Loss: 1.075817 Acc: 0.8125\n",
      "Train Epoch: 36 [688000/906425] Loss: 0.721890 Acc: 0.6875\n",
      "Train Epoch: 36 [704000/906425] Loss: 1.232395 Acc: 0.6875\n",
      "Train Epoch: 36 [720000/906425] Loss: 0.635227 Acc: 0.8125\n",
      "Train Epoch: 36 [736000/906425] Loss: 0.696230 Acc: 0.8125\n",
      "Train Epoch: 36 [752000/906425] Loss: 0.833315 Acc: 0.8750\n",
      "Train Epoch: 36 [768000/906425] Loss: 0.435750 Acc: 0.9375\n",
      "Train Epoch: 36 [784000/906425] Loss: 0.195275 Acc: 0.9375\n",
      "Train Epoch: 36 [800000/906425] Loss: 0.411901 Acc: 0.8750\n",
      "Train Epoch: 36 [816000/906425] Loss: 0.477545 Acc: 0.8125\n",
      "Train Epoch: 36 [832000/906425] Loss: 1.005076 Acc: 0.8125\n",
      "Train Epoch: 36 [848000/906425] Loss: 1.403763 Acc: 0.7500\n",
      "Train Epoch: 36 [864000/906425] Loss: 0.930450 Acc: 0.7500\n",
      "Train Epoch: 36 [880000/906425] Loss: 1.267804 Acc: 0.7500\n",
      "Train Epoch: 36 [896000/906425] Loss: 1.639275 Acc: 0.6250\n",
      "Elapsed 21336.83s, 576.67 s/epoch, 0.01 s/batch, ets 7496.72s\n",
      "\n",
      "Test set: Average loss: 1.4593, Accuracy: 206046/293785 (70%)\n",
      "\n",
      "Train Epoch: 37 [16000/906425] Loss: 0.980004 Acc: 0.6250\n",
      "Train Epoch: 37 [32000/906425] Loss: 1.413389 Acc: 0.6875\n",
      "Train Epoch: 37 [48000/906425] Loss: 0.321097 Acc: 0.8750\n",
      "Train Epoch: 37 [64000/906425] Loss: 0.229146 Acc: 0.9375\n",
      "Train Epoch: 37 [80000/906425] Loss: 0.626176 Acc: 0.7500\n",
      "Train Epoch: 37 [96000/906425] Loss: 0.722355 Acc: 0.7500\n",
      "Train Epoch: 37 [112000/906425] Loss: 0.796523 Acc: 0.8125\n",
      "Train Epoch: 37 [128000/906425] Loss: 0.712481 Acc: 0.7500\n",
      "Train Epoch: 37 [144000/906425] Loss: 0.928645 Acc: 0.7500\n",
      "Train Epoch: 37 [160000/906425] Loss: 0.820336 Acc: 0.6875\n",
      "Train Epoch: 37 [176000/906425] Loss: 0.572264 Acc: 0.8125\n",
      "Train Epoch: 37 [192000/906425] Loss: 0.295692 Acc: 0.9375\n",
      "Train Epoch: 37 [208000/906425] Loss: 0.557282 Acc: 0.8750\n",
      "Train Epoch: 37 [224000/906425] Loss: 0.705747 Acc: 0.8125\n",
      "Train Epoch: 37 [240000/906425] Loss: 0.268276 Acc: 0.8750\n",
      "Train Epoch: 37 [256000/906425] Loss: 0.462919 Acc: 0.8750\n",
      "Train Epoch: 37 [272000/906425] Loss: 0.563356 Acc: 0.8750\n",
      "Train Epoch: 37 [288000/906425] Loss: 0.569637 Acc: 0.8125\n",
      "Train Epoch: 37 [304000/906425] Loss: 0.595309 Acc: 0.6875\n",
      "Train Epoch: 37 [320000/906425] Loss: 1.124148 Acc: 0.6875\n",
      "Train Epoch: 37 [336000/906425] Loss: 1.037369 Acc: 0.8125\n",
      "Train Epoch: 37 [352000/906425] Loss: 0.365487 Acc: 0.9375\n",
      "Train Epoch: 37 [368000/906425] Loss: 1.183939 Acc: 0.6875\n",
      "Train Epoch: 37 [384000/906425] Loss: 1.279639 Acc: 0.8750\n",
      "Train Epoch: 37 [400000/906425] Loss: 1.412196 Acc: 0.5625\n",
      "Train Epoch: 37 [416000/906425] Loss: 0.873375 Acc: 0.8125\n",
      "Train Epoch: 37 [432000/906425] Loss: 1.033775 Acc: 0.8125\n",
      "Train Epoch: 37 [448000/906425] Loss: 1.535463 Acc: 0.9375\n",
      "Train Epoch: 37 [464000/906425] Loss: 0.944777 Acc: 0.7500\n",
      "Train Epoch: 37 [480000/906425] Loss: 0.677127 Acc: 0.7500\n",
      "Train Epoch: 37 [496000/906425] Loss: 0.995963 Acc: 0.7500\n",
      "Train Epoch: 37 [512000/906425] Loss: 0.440863 Acc: 0.8125\n",
      "Train Epoch: 37 [528000/906425] Loss: 0.494382 Acc: 0.7500\n",
      "Train Epoch: 37 [544000/906425] Loss: 0.596673 Acc: 0.7500\n",
      "Train Epoch: 37 [560000/906425] Loss: 0.812095 Acc: 0.7500\n",
      "Train Epoch: 37 [576000/906425] Loss: 0.580138 Acc: 0.7500\n",
      "Train Epoch: 37 [592000/906425] Loss: 0.785632 Acc: 0.7500\n",
      "Train Epoch: 37 [608000/906425] Loss: 0.386149 Acc: 0.8750\n",
      "Train Epoch: 37 [624000/906425] Loss: 1.145154 Acc: 0.7500\n",
      "Train Epoch: 37 [640000/906425] Loss: 0.454711 Acc: 0.8750\n",
      "Train Epoch: 37 [656000/906425] Loss: 0.569251 Acc: 0.8125\n",
      "Train Epoch: 37 [672000/906425] Loss: 0.466727 Acc: 0.8125\n",
      "Train Epoch: 37 [688000/906425] Loss: 1.365923 Acc: 0.5625\n",
      "Train Epoch: 37 [704000/906425] Loss: 0.914440 Acc: 0.7500\n",
      "Train Epoch: 37 [720000/906425] Loss: 0.908500 Acc: 0.7500\n",
      "Train Epoch: 37 [736000/906425] Loss: 1.246867 Acc: 0.7500\n",
      "Train Epoch: 37 [752000/906425] Loss: 1.081333 Acc: 0.6875\n",
      "Train Epoch: 37 [768000/906425] Loss: 0.253534 Acc: 0.9375\n",
      "Train Epoch: 37 [784000/906425] Loss: 0.624686 Acc: 0.8750\n",
      "Train Epoch: 37 [800000/906425] Loss: 0.244403 Acc: 0.9375\n",
      "Train Epoch: 37 [816000/906425] Loss: 0.348140 Acc: 0.8750\n",
      "Train Epoch: 37 [832000/906425] Loss: 1.293492 Acc: 0.6250\n",
      "Train Epoch: 37 [848000/906425] Loss: 0.332462 Acc: 0.8750\n",
      "Train Epoch: 37 [864000/906425] Loss: 1.169207 Acc: 0.6875\n",
      "Train Epoch: 37 [880000/906425] Loss: 0.831113 Acc: 0.6250\n",
      "Train Epoch: 37 [896000/906425] Loss: 0.517433 Acc: 0.8750\n",
      "Elapsed 21915.69s, 576.73 s/epoch, 0.01 s/batch, ets 6920.75s\n",
      "\n",
      "Test set: Average loss: 1.4404, Accuracy: 208072/293785 (71%)\n",
      "\n",
      "Train Epoch: 38 [16000/906425] Loss: 0.797457 Acc: 0.8750\n",
      "Train Epoch: 38 [32000/906425] Loss: 1.427135 Acc: 0.6875\n",
      "Train Epoch: 38 [48000/906425] Loss: 0.714853 Acc: 0.7500\n",
      "Train Epoch: 38 [64000/906425] Loss: 0.754475 Acc: 0.7500\n",
      "Train Epoch: 38 [80000/906425] Loss: 0.684327 Acc: 0.6875\n",
      "Train Epoch: 38 [96000/906425] Loss: 0.749114 Acc: 0.7500\n",
      "Train Epoch: 38 [112000/906425] Loss: 0.506834 Acc: 0.8750\n",
      "Train Epoch: 38 [128000/906425] Loss: 0.122027 Acc: 1.0000\n",
      "Train Epoch: 38 [144000/906425] Loss: 0.464512 Acc: 0.9375\n",
      "Train Epoch: 38 [160000/906425] Loss: 0.720973 Acc: 0.8125\n",
      "Train Epoch: 38 [176000/906425] Loss: 0.241298 Acc: 0.8750\n",
      "Train Epoch: 38 [192000/906425] Loss: 0.407067 Acc: 0.9375\n",
      "Train Epoch: 38 [208000/906425] Loss: 0.377366 Acc: 0.8750\n",
      "Train Epoch: 38 [224000/906425] Loss: 0.346168 Acc: 0.8125\n",
      "Train Epoch: 38 [240000/906425] Loss: 0.406155 Acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [256000/906425] Loss: 0.796673 Acc: 0.7500\n",
      "Train Epoch: 38 [272000/906425] Loss: 1.198884 Acc: 0.7500\n",
      "Train Epoch: 38 [288000/906425] Loss: 0.385548 Acc: 0.8750\n",
      "Train Epoch: 38 [304000/906425] Loss: 0.547601 Acc: 0.7500\n",
      "Train Epoch: 38 [320000/906425] Loss: 0.229773 Acc: 0.9375\n",
      "Train Epoch: 38 [336000/906425] Loss: 0.747809 Acc: 0.8750\n",
      "Train Epoch: 38 [352000/906425] Loss: 0.334065 Acc: 0.9375\n",
      "Train Epoch: 38 [368000/906425] Loss: 0.579222 Acc: 0.8750\n",
      "Train Epoch: 38 [384000/906425] Loss: 0.458334 Acc: 0.8125\n",
      "Train Epoch: 38 [400000/906425] Loss: 0.538898 Acc: 0.8750\n",
      "Train Epoch: 38 [416000/906425] Loss: 0.726452 Acc: 0.8750\n",
      "Train Epoch: 38 [432000/906425] Loss: 0.934358 Acc: 0.8125\n",
      "Train Epoch: 38 [448000/906425] Loss: 0.924004 Acc: 0.6875\n",
      "Train Epoch: 38 [464000/906425] Loss: 0.901877 Acc: 0.8750\n",
      "Train Epoch: 38 [480000/906425] Loss: 1.541222 Acc: 0.6875\n",
      "Train Epoch: 38 [496000/906425] Loss: 0.556441 Acc: 0.8750\n",
      "Train Epoch: 38 [512000/906425] Loss: 1.024019 Acc: 0.8125\n",
      "Train Epoch: 38 [528000/906425] Loss: 1.167628 Acc: 0.6875\n",
      "Train Epoch: 38 [544000/906425] Loss: 1.387361 Acc: 0.6875\n",
      "Train Epoch: 38 [560000/906425] Loss: 0.413833 Acc: 0.8125\n",
      "Train Epoch: 38 [576000/906425] Loss: 0.893978 Acc: 0.6875\n",
      "Train Epoch: 38 [592000/906425] Loss: 0.390578 Acc: 0.8750\n",
      "Train Epoch: 38 [608000/906425] Loss: 0.654574 Acc: 0.8125\n",
      "Train Epoch: 38 [624000/906425] Loss: 1.107508 Acc: 0.6250\n",
      "Train Epoch: 38 [640000/906425] Loss: 0.322731 Acc: 0.9375\n",
      "Train Epoch: 38 [656000/906425] Loss: 0.834171 Acc: 0.8750\n",
      "Train Epoch: 38 [672000/906425] Loss: 0.551588 Acc: 0.9375\n",
      "Train Epoch: 38 [688000/906425] Loss: 0.672236 Acc: 0.8125\n",
      "Train Epoch: 38 [704000/906425] Loss: 0.464407 Acc: 0.9375\n",
      "Train Epoch: 38 [720000/906425] Loss: 0.951143 Acc: 0.8125\n",
      "Train Epoch: 38 [736000/906425] Loss: 1.319981 Acc: 0.7500\n",
      "Train Epoch: 38 [752000/906425] Loss: 0.799731 Acc: 0.7500\n",
      "Train Epoch: 38 [768000/906425] Loss: 0.491153 Acc: 0.8750\n",
      "Train Epoch: 38 [784000/906425] Loss: 0.440815 Acc: 0.8750\n",
      "Train Epoch: 38 [800000/906425] Loss: 0.910595 Acc: 0.8750\n",
      "Train Epoch: 38 [816000/906425] Loss: 0.871440 Acc: 0.8125\n",
      "Train Epoch: 38 [832000/906425] Loss: 0.303538 Acc: 0.9375\n",
      "Train Epoch: 38 [848000/906425] Loss: 0.779417 Acc: 0.7500\n",
      "Train Epoch: 38 [864000/906425] Loss: 0.794296 Acc: 0.6875\n",
      "Train Epoch: 38 [880000/906425] Loss: 0.233724 Acc: 0.9375\n",
      "Train Epoch: 38 [896000/906425] Loss: 0.827778 Acc: 0.7500\n",
      "Elapsed 22494.64s, 576.79 s/epoch, 0.01 s/batch, ets 6344.64s\n",
      "\n",
      "Test set: Average loss: 1.4486, Accuracy: 207642/293785 (71%)\n",
      "\n",
      "Train Epoch: 39 [16000/906425] Loss: 0.989292 Acc: 0.7500\n",
      "Train Epoch: 39 [32000/906425] Loss: 0.570421 Acc: 0.8125\n",
      "Train Epoch: 39 [48000/906425] Loss: 0.553499 Acc: 0.8750\n",
      "Train Epoch: 39 [64000/906425] Loss: 1.479100 Acc: 0.6250\n",
      "Train Epoch: 39 [80000/906425] Loss: 0.844511 Acc: 0.8125\n",
      "Train Epoch: 39 [96000/906425] Loss: 0.548313 Acc: 0.8125\n",
      "Train Epoch: 39 [112000/906425] Loss: 0.394189 Acc: 0.8125\n",
      "Train Epoch: 39 [128000/906425] Loss: 0.642647 Acc: 0.8750\n",
      "Train Epoch: 39 [144000/906425] Loss: 0.972557 Acc: 0.8125\n",
      "Train Epoch: 39 [160000/906425] Loss: 0.769850 Acc: 0.8125\n",
      "Train Epoch: 39 [176000/906425] Loss: 0.496899 Acc: 0.8750\n",
      "Train Epoch: 39 [192000/906425] Loss: 0.564876 Acc: 0.8125\n",
      "Train Epoch: 39 [208000/906425] Loss: 0.282724 Acc: 0.8750\n",
      "Train Epoch: 39 [224000/906425] Loss: 0.455438 Acc: 0.8125\n",
      "Train Epoch: 39 [240000/906425] Loss: 0.687274 Acc: 0.6875\n",
      "Train Epoch: 39 [256000/906425] Loss: 1.011320 Acc: 0.6875\n",
      "Train Epoch: 39 [272000/906425] Loss: 0.579408 Acc: 0.8125\n",
      "Train Epoch: 39 [288000/906425] Loss: 0.744443 Acc: 0.7500\n",
      "Train Epoch: 39 [304000/906425] Loss: 1.128914 Acc: 0.6875\n",
      "Train Epoch: 39 [320000/906425] Loss: 1.208305 Acc: 0.6250\n",
      "Train Epoch: 39 [336000/906425] Loss: 0.539747 Acc: 0.9375\n",
      "Train Epoch: 39 [352000/906425] Loss: 0.496171 Acc: 0.8125\n",
      "Train Epoch: 39 [368000/906425] Loss: 1.196428 Acc: 0.6250\n",
      "Train Epoch: 39 [384000/906425] Loss: 0.483459 Acc: 0.8125\n",
      "Train Epoch: 39 [400000/906425] Loss: 0.467694 Acc: 0.8750\n",
      "Train Epoch: 39 [416000/906425] Loss: 0.629845 Acc: 0.8125\n",
      "Train Epoch: 39 [432000/906425] Loss: 0.397087 Acc: 0.8125\n",
      "Train Epoch: 39 [448000/906425] Loss: 0.524281 Acc: 0.8125\n",
      "Train Epoch: 39 [464000/906425] Loss: 0.562725 Acc: 0.8125\n",
      "Train Epoch: 39 [480000/906425] Loss: 0.842110 Acc: 0.8125\n",
      "Train Epoch: 39 [496000/906425] Loss: 0.513771 Acc: 0.8750\n",
      "Train Epoch: 39 [512000/906425] Loss: 0.353752 Acc: 0.8750\n",
      "Train Epoch: 39 [528000/906425] Loss: 0.698483 Acc: 0.8750\n",
      "Train Epoch: 39 [544000/906425] Loss: 1.374283 Acc: 0.6875\n",
      "Train Epoch: 39 [560000/906425] Loss: 0.907591 Acc: 0.8125\n",
      "Train Epoch: 39 [576000/906425] Loss: 0.203089 Acc: 1.0000\n",
      "Train Epoch: 39 [592000/906425] Loss: 0.296534 Acc: 0.9375\n",
      "Train Epoch: 39 [608000/906425] Loss: 1.017926 Acc: 0.6875\n",
      "Train Epoch: 39 [624000/906425] Loss: 0.857810 Acc: 0.6250\n",
      "Train Epoch: 39 [640000/906425] Loss: 0.216214 Acc: 0.9375\n",
      "Train Epoch: 39 [656000/906425] Loss: 0.820826 Acc: 0.8125\n",
      "Train Epoch: 39 [672000/906425] Loss: 0.711185 Acc: 0.8125\n",
      "Train Epoch: 39 [688000/906425] Loss: 0.674226 Acc: 0.7500\n",
      "Train Epoch: 39 [704000/906425] Loss: 0.837092 Acc: 0.7500\n",
      "Train Epoch: 39 [720000/906425] Loss: 0.609098 Acc: 0.8750\n",
      "Train Epoch: 39 [736000/906425] Loss: 1.194924 Acc: 0.7500\n",
      "Train Epoch: 39 [752000/906425] Loss: 0.758145 Acc: 0.6875\n",
      "Train Epoch: 39 [768000/906425] Loss: 0.379044 Acc: 0.9375\n",
      "Train Epoch: 39 [784000/906425] Loss: 0.612326 Acc: 0.8750\n",
      "Train Epoch: 39 [800000/906425] Loss: 0.468649 Acc: 0.8750\n",
      "Train Epoch: 39 [816000/906425] Loss: 0.121416 Acc: 1.0000\n",
      "Train Epoch: 39 [832000/906425] Loss: 0.546031 Acc: 0.7500\n",
      "Train Epoch: 39 [848000/906425] Loss: 0.204938 Acc: 0.9375\n",
      "Train Epoch: 39 [864000/906425] Loss: 0.202800 Acc: 0.9375\n",
      "Train Epoch: 39 [880000/906425] Loss: 0.410264 Acc: 0.8750\n",
      "Train Epoch: 39 [896000/906425] Loss: 0.396894 Acc: 0.9375\n",
      "Elapsed 23073.78s, 576.84 s/epoch, 0.01 s/batch, ets 5768.44s\n",
      "\n",
      "Test set: Average loss: 1.4585, Accuracy: 208311/293785 (71%)\n",
      "\n",
      "Train Epoch: 40 [16000/906425] Loss: 0.395261 Acc: 0.7500\n",
      "Train Epoch: 40 [32000/906425] Loss: 0.951982 Acc: 0.7500\n",
      "Train Epoch: 40 [48000/906425] Loss: 0.657709 Acc: 0.7500\n",
      "Train Epoch: 40 [64000/906425] Loss: 0.928621 Acc: 0.8125\n",
      "Train Epoch: 40 [80000/906425] Loss: 0.810402 Acc: 0.7500\n",
      "Train Epoch: 40 [96000/906425] Loss: 0.394342 Acc: 0.8750\n",
      "Train Epoch: 40 [112000/906425] Loss: 0.822733 Acc: 0.8125\n",
      "Train Epoch: 40 [128000/906425] Loss: 1.521918 Acc: 0.6875\n",
      "Train Epoch: 40 [144000/906425] Loss: 0.240754 Acc: 0.9375\n",
      "Train Epoch: 40 [160000/906425] Loss: 0.269685 Acc: 0.9375\n",
      "Train Epoch: 40 [176000/906425] Loss: 1.168341 Acc: 0.6875\n",
      "Train Epoch: 40 [192000/906425] Loss: 0.816148 Acc: 0.8125\n",
      "Train Epoch: 40 [208000/906425] Loss: 0.876866 Acc: 0.8125\n",
      "Train Epoch: 40 [224000/906425] Loss: 0.662380 Acc: 0.8125\n",
      "Train Epoch: 40 [240000/906425] Loss: 0.268578 Acc: 0.9375\n",
      "Train Epoch: 40 [256000/906425] Loss: 0.553275 Acc: 0.8125\n",
      "Train Epoch: 40 [272000/906425] Loss: 0.580245 Acc: 0.8750\n",
      "Train Epoch: 40 [288000/906425] Loss: 1.305768 Acc: 0.7500\n",
      "Train Epoch: 40 [304000/906425] Loss: 0.724044 Acc: 0.7500\n",
      "Train Epoch: 40 [320000/906425] Loss: 0.519429 Acc: 0.9375\n",
      "Train Epoch: 40 [336000/906425] Loss: 1.216046 Acc: 0.6250\n",
      "Train Epoch: 40 [352000/906425] Loss: 0.827934 Acc: 0.7500\n",
      "Train Epoch: 40 [368000/906425] Loss: 0.506821 Acc: 0.8750\n",
      "Train Epoch: 40 [384000/906425] Loss: 0.251125 Acc: 0.9375\n",
      "Train Epoch: 40 [400000/906425] Loss: 0.600222 Acc: 0.8125\n",
      "Train Epoch: 40 [416000/906425] Loss: 0.237127 Acc: 1.0000\n",
      "Train Epoch: 40 [432000/906425] Loss: 0.330185 Acc: 0.8750\n",
      "Train Epoch: 40 [448000/906425] Loss: 0.302261 Acc: 0.9375\n",
      "Train Epoch: 40 [464000/906425] Loss: 0.320415 Acc: 0.8750\n",
      "Train Epoch: 40 [480000/906425] Loss: 1.061069 Acc: 0.7500\n",
      "Train Epoch: 40 [496000/906425] Loss: 0.631611 Acc: 0.8125\n",
      "Train Epoch: 40 [512000/906425] Loss: 0.649817 Acc: 0.8750\n",
      "Train Epoch: 40 [528000/906425] Loss: 0.671740 Acc: 0.8125\n",
      "Train Epoch: 40 [544000/906425] Loss: 0.739549 Acc: 0.8750\n",
      "Train Epoch: 40 [560000/906425] Loss: 0.850808 Acc: 0.7500\n",
      "Train Epoch: 40 [576000/906425] Loss: 0.710435 Acc: 0.7500\n",
      "Train Epoch: 40 [592000/906425] Loss: 0.260589 Acc: 1.0000\n",
      "Train Epoch: 40 [608000/906425] Loss: 0.311800 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [624000/906425] Loss: 1.270602 Acc: 0.6875\n",
      "Train Epoch: 40 [640000/906425] Loss: 0.675103 Acc: 0.6875\n",
      "Train Epoch: 40 [656000/906425] Loss: 0.777602 Acc: 0.6875\n",
      "Train Epoch: 40 [672000/906425] Loss: 0.203607 Acc: 0.8750\n",
      "Train Epoch: 40 [688000/906425] Loss: 0.752371 Acc: 0.8125\n",
      "Train Epoch: 40 [704000/906425] Loss: 0.485736 Acc: 0.8750\n",
      "Train Epoch: 40 [720000/906425] Loss: 2.009912 Acc: 0.6250\n",
      "Train Epoch: 40 [736000/906425] Loss: 1.057082 Acc: 0.5625\n",
      "Train Epoch: 40 [752000/906425] Loss: 0.409539 Acc: 0.8750\n",
      "Train Epoch: 40 [768000/906425] Loss: 0.456521 Acc: 0.8750\n",
      "Train Epoch: 40 [784000/906425] Loss: 0.669117 Acc: 0.8125\n",
      "Train Epoch: 40 [800000/906425] Loss: 0.502295 Acc: 0.8750\n",
      "Train Epoch: 40 [816000/906425] Loss: 0.598506 Acc: 0.8125\n",
      "Train Epoch: 40 [832000/906425] Loss: 0.775858 Acc: 0.8125\n",
      "Train Epoch: 40 [848000/906425] Loss: 0.309485 Acc: 0.8750\n",
      "Train Epoch: 40 [864000/906425] Loss: 0.546619 Acc: 0.8125\n",
      "Train Epoch: 40 [880000/906425] Loss: 0.816958 Acc: 0.8125\n",
      "Train Epoch: 40 [896000/906425] Loss: 0.274470 Acc: 0.9375\n",
      "Elapsed 23652.80s, 576.90 s/epoch, 0.01 s/batch, ets 5192.08s\n",
      "\n",
      "Test set: Average loss: 1.4733, Accuracy: 208202/293785 (71%)\n",
      "\n",
      "Train Epoch: 41 [16000/906425] Loss: 0.637331 Acc: 0.8125\n",
      "Train Epoch: 41 [32000/906425] Loss: 0.236704 Acc: 1.0000\n",
      "Train Epoch: 41 [48000/906425] Loss: 0.300806 Acc: 0.8750\n",
      "Train Epoch: 41 [64000/906425] Loss: 0.493883 Acc: 0.7500\n",
      "Train Epoch: 41 [80000/906425] Loss: 1.512920 Acc: 0.6250\n",
      "Train Epoch: 41 [96000/906425] Loss: 0.110303 Acc: 1.0000\n",
      "Train Epoch: 41 [112000/906425] Loss: 0.488694 Acc: 0.8750\n",
      "Train Epoch: 41 [128000/906425] Loss: 0.148453 Acc: 1.0000\n",
      "Train Epoch: 41 [144000/906425] Loss: 0.425696 Acc: 0.8750\n",
      "Train Epoch: 41 [160000/906425] Loss: 0.672942 Acc: 0.6875\n",
      "Train Epoch: 41 [176000/906425] Loss: 0.585525 Acc: 0.8750\n",
      "Train Epoch: 41 [192000/906425] Loss: 0.360572 Acc: 0.8750\n",
      "Train Epoch: 41 [208000/906425] Loss: 0.422615 Acc: 0.8750\n",
      "Train Epoch: 41 [224000/906425] Loss: 0.461243 Acc: 0.8750\n",
      "Train Epoch: 41 [240000/906425] Loss: 0.399661 Acc: 0.8125\n",
      "Train Epoch: 41 [256000/906425] Loss: 0.787902 Acc: 0.7500\n",
      "Train Epoch: 41 [272000/906425] Loss: 0.770297 Acc: 0.7500\n",
      "Train Epoch: 41 [288000/906425] Loss: 0.211834 Acc: 0.9375\n",
      "Train Epoch: 41 [304000/906425] Loss: 0.304291 Acc: 0.8125\n",
      "Train Epoch: 41 [320000/906425] Loss: 0.522971 Acc: 0.8125\n",
      "Train Epoch: 41 [336000/906425] Loss: 0.537717 Acc: 0.8750\n",
      "Train Epoch: 41 [352000/906425] Loss: 0.787913 Acc: 0.7500\n",
      "Train Epoch: 41 [368000/906425] Loss: 0.619023 Acc: 0.8125\n",
      "Train Epoch: 41 [384000/906425] Loss: 0.484309 Acc: 0.7500\n",
      "Train Epoch: 41 [400000/906425] Loss: 0.763352 Acc: 0.6875\n",
      "Train Epoch: 41 [416000/906425] Loss: 0.661210 Acc: 0.8125\n",
      "Train Epoch: 41 [432000/906425] Loss: 0.440363 Acc: 0.9375\n",
      "Train Epoch: 41 [448000/906425] Loss: 0.733036 Acc: 0.8750\n",
      "Train Epoch: 41 [464000/906425] Loss: 0.270758 Acc: 0.9375\n",
      "Train Epoch: 41 [480000/906425] Loss: 0.719383 Acc: 0.8750\n",
      "Train Epoch: 41 [496000/906425] Loss: 0.201795 Acc: 0.9375\n",
      "Train Epoch: 41 [512000/906425] Loss: 0.492327 Acc: 0.8125\n",
      "Train Epoch: 41 [528000/906425] Loss: 0.891670 Acc: 0.6875\n",
      "Train Epoch: 41 [544000/906425] Loss: 0.337058 Acc: 0.9375\n",
      "Train Epoch: 41 [560000/906425] Loss: 0.305040 Acc: 0.9375\n",
      "Train Epoch: 41 [576000/906425] Loss: 1.292535 Acc: 0.8125\n",
      "Train Epoch: 41 [592000/906425] Loss: 0.852139 Acc: 0.8125\n",
      "Train Epoch: 41 [608000/906425] Loss: 0.731488 Acc: 0.8125\n",
      "Train Epoch: 41 [624000/906425] Loss: 0.373864 Acc: 0.8750\n",
      "Train Epoch: 41 [640000/906425] Loss: 0.262262 Acc: 0.9375\n",
      "Train Epoch: 41 [656000/906425] Loss: 0.946094 Acc: 0.8125\n",
      "Train Epoch: 41 [672000/906425] Loss: 0.372020 Acc: 0.8750\n",
      "Train Epoch: 41 [688000/906425] Loss: 1.181555 Acc: 0.6875\n",
      "Train Epoch: 41 [704000/906425] Loss: 0.598386 Acc: 0.8750\n",
      "Train Epoch: 41 [720000/906425] Loss: 0.359905 Acc: 0.8125\n",
      "Train Epoch: 41 [736000/906425] Loss: 0.607949 Acc: 0.9375\n",
      "Train Epoch: 41 [752000/906425] Loss: 0.998914 Acc: 0.7500\n",
      "Train Epoch: 41 [768000/906425] Loss: 0.438635 Acc: 0.8750\n",
      "Train Epoch: 41 [784000/906425] Loss: 0.055964 Acc: 1.0000\n",
      "Train Epoch: 41 [800000/906425] Loss: 0.198970 Acc: 0.9375\n",
      "Train Epoch: 41 [816000/906425] Loss: 0.481450 Acc: 0.8750\n",
      "Train Epoch: 41 [832000/906425] Loss: 0.460938 Acc: 0.8750\n",
      "Train Epoch: 41 [848000/906425] Loss: 0.594778 Acc: 0.8750\n",
      "Train Epoch: 41 [864000/906425] Loss: 1.014952 Acc: 0.7500\n",
      "Train Epoch: 41 [880000/906425] Loss: 0.902348 Acc: 0.6875\n",
      "Train Epoch: 41 [896000/906425] Loss: 1.286155 Acc: 0.7500\n",
      "Elapsed 24231.43s, 576.94 s/epoch, 0.01 s/batch, ets 4615.51s\n",
      "\n",
      "Test set: Average loss: 1.4379, Accuracy: 210173/293785 (72%)\n",
      "\n",
      "Train Epoch: 42 [16000/906425] Loss: 0.177044 Acc: 0.9375\n",
      "Train Epoch: 42 [32000/906425] Loss: 0.342243 Acc: 0.9375\n",
      "Train Epoch: 42 [48000/906425] Loss: 0.251165 Acc: 0.9375\n",
      "Train Epoch: 42 [64000/906425] Loss: 0.730258 Acc: 0.8125\n",
      "Train Epoch: 42 [80000/906425] Loss: 0.564665 Acc: 0.9375\n",
      "Train Epoch: 42 [96000/906425] Loss: 0.473535 Acc: 0.8750\n",
      "Train Epoch: 42 [112000/906425] Loss: 0.502197 Acc: 0.8750\n",
      "Train Epoch: 42 [128000/906425] Loss: 1.017996 Acc: 0.7500\n",
      "Train Epoch: 42 [144000/906425] Loss: 0.471374 Acc: 0.8750\n",
      "Train Epoch: 42 [160000/906425] Loss: 0.805169 Acc: 0.8125\n",
      "Train Epoch: 42 [176000/906425] Loss: 0.567431 Acc: 0.8750\n",
      "Train Epoch: 42 [192000/906425] Loss: 0.605190 Acc: 0.8750\n",
      "Train Epoch: 42 [208000/906425] Loss: 1.046774 Acc: 0.6875\n",
      "Train Epoch: 42 [224000/906425] Loss: 0.706807 Acc: 0.8750\n",
      "Train Epoch: 42 [240000/906425] Loss: 1.037206 Acc: 0.7500\n",
      "Train Epoch: 42 [256000/906425] Loss: 0.792903 Acc: 0.7500\n",
      "Train Epoch: 42 [272000/906425] Loss: 0.566484 Acc: 0.8125\n",
      "Train Epoch: 42 [288000/906425] Loss: 0.527374 Acc: 0.8750\n",
      "Train Epoch: 42 [304000/906425] Loss: 0.318800 Acc: 0.8750\n",
      "Train Epoch: 42 [320000/906425] Loss: 1.694684 Acc: 0.6875\n",
      "Train Epoch: 42 [336000/906425] Loss: 1.034847 Acc: 0.9375\n",
      "Train Epoch: 42 [352000/906425] Loss: 0.324788 Acc: 0.9375\n",
      "Train Epoch: 42 [368000/906425] Loss: 0.412630 Acc: 0.8750\n",
      "Train Epoch: 42 [384000/906425] Loss: 1.454144 Acc: 0.8125\n",
      "Train Epoch: 42 [400000/906425] Loss: 0.346432 Acc: 0.9375\n",
      "Train Epoch: 42 [416000/906425] Loss: 0.406938 Acc: 0.9375\n",
      "Train Epoch: 42 [432000/906425] Loss: 1.050736 Acc: 0.8125\n",
      "Train Epoch: 42 [448000/906425] Loss: 0.269825 Acc: 0.8750\n",
      "Train Epoch: 42 [464000/906425] Loss: 0.576574 Acc: 0.8125\n",
      "Train Epoch: 42 [480000/906425] Loss: 0.814417 Acc: 0.7500\n",
      "Train Epoch: 42 [496000/906425] Loss: 0.637438 Acc: 0.6875\n",
      "Train Epoch: 42 [512000/906425] Loss: 0.499516 Acc: 0.8750\n",
      "Train Epoch: 42 [528000/906425] Loss: 0.661356 Acc: 0.8125\n",
      "Train Epoch: 42 [544000/906425] Loss: 0.380118 Acc: 0.8750\n",
      "Train Epoch: 42 [560000/906425] Loss: 0.633150 Acc: 0.8750\n",
      "Train Epoch: 42 [576000/906425] Loss: 0.563800 Acc: 0.7500\n",
      "Train Epoch: 42 [592000/906425] Loss: 0.401090 Acc: 0.8750\n",
      "Train Epoch: 42 [608000/906425] Loss: 0.466874 Acc: 0.8125\n",
      "Train Epoch: 42 [624000/906425] Loss: 0.568425 Acc: 0.8750\n",
      "Train Epoch: 42 [640000/906425] Loss: 1.247914 Acc: 0.8125\n",
      "Train Epoch: 42 [656000/906425] Loss: 0.776630 Acc: 0.8125\n",
      "Train Epoch: 42 [672000/906425] Loss: 0.801963 Acc: 0.8125\n",
      "Train Epoch: 42 [688000/906425] Loss: 0.311346 Acc: 0.8750\n",
      "Train Epoch: 42 [704000/906425] Loss: 0.696335 Acc: 0.7500\n",
      "Train Epoch: 42 [720000/906425] Loss: 0.474694 Acc: 0.8750\n",
      "Train Epoch: 42 [736000/906425] Loss: 0.549629 Acc: 0.8125\n",
      "Train Epoch: 42 [752000/906425] Loss: 0.955534 Acc: 0.7500\n",
      "Train Epoch: 42 [768000/906425] Loss: 0.687161 Acc: 0.8125\n",
      "Train Epoch: 42 [784000/906425] Loss: 0.456249 Acc: 0.8750\n",
      "Train Epoch: 42 [800000/906425] Loss: 0.268319 Acc: 0.9375\n",
      "Train Epoch: 42 [816000/906425] Loss: 0.225424 Acc: 0.9375\n",
      "Train Epoch: 42 [832000/906425] Loss: 0.630590 Acc: 0.6875\n",
      "Train Epoch: 42 [848000/906425] Loss: 0.358560 Acc: 0.9375\n",
      "Train Epoch: 42 [864000/906425] Loss: 0.643953 Acc: 0.8750\n",
      "Train Epoch: 42 [880000/906425] Loss: 0.484935 Acc: 0.8125\n",
      "Train Epoch: 42 [896000/906425] Loss: 1.138183 Acc: 0.7500\n",
      "Elapsed 24810.26s, 576.98 s/epoch, 0.01 s/batch, ets 4038.88s\n",
      "\n",
      "Test set: Average loss: 1.4674, Accuracy: 209612/293785 (71%)\n",
      "\n",
      "Train Epoch: 43 [16000/906425] Loss: 1.334550 Acc: 0.7500\n",
      "Train Epoch: 43 [32000/906425] Loss: 0.388595 Acc: 0.9375\n",
      "Train Epoch: 43 [48000/906425] Loss: 0.511734 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [64000/906425] Loss: 0.196654 Acc: 0.9375\n",
      "Train Epoch: 43 [80000/906425] Loss: 0.290529 Acc: 0.8750\n",
      "Train Epoch: 43 [96000/906425] Loss: 1.977703 Acc: 0.5625\n",
      "Train Epoch: 43 [112000/906425] Loss: 0.640953 Acc: 0.7500\n",
      "Train Epoch: 43 [128000/906425] Loss: 0.822272 Acc: 0.7500\n",
      "Train Epoch: 43 [144000/906425] Loss: 1.124019 Acc: 0.8125\n",
      "Train Epoch: 43 [160000/906425] Loss: 0.362695 Acc: 0.9375\n",
      "Train Epoch: 43 [176000/906425] Loss: 0.691645 Acc: 0.8750\n",
      "Train Epoch: 43 [192000/906425] Loss: 0.131827 Acc: 0.9375\n",
      "Train Epoch: 43 [208000/906425] Loss: 0.219023 Acc: 0.9375\n",
      "Train Epoch: 43 [224000/906425] Loss: 0.620961 Acc: 0.8750\n",
      "Train Epoch: 43 [240000/906425] Loss: 0.518811 Acc: 0.6875\n",
      "Train Epoch: 43 [256000/906425] Loss: 0.361534 Acc: 0.8750\n",
      "Train Epoch: 43 [272000/906425] Loss: 0.978478 Acc: 0.6875\n",
      "Train Epoch: 43 [288000/906425] Loss: 0.510983 Acc: 0.8750\n",
      "Train Epoch: 43 [304000/906425] Loss: 0.503728 Acc: 0.9375\n",
      "Train Epoch: 43 [320000/906425] Loss: 0.678836 Acc: 0.7500\n",
      "Train Epoch: 43 [336000/906425] Loss: 0.887849 Acc: 0.8125\n",
      "Train Epoch: 43 [352000/906425] Loss: 0.541685 Acc: 0.8750\n",
      "Train Epoch: 43 [368000/906425] Loss: 0.663707 Acc: 0.6250\n",
      "Train Epoch: 43 [384000/906425] Loss: 0.968163 Acc: 0.8750\n",
      "Train Epoch: 43 [400000/906425] Loss: 1.123689 Acc: 0.7500\n",
      "Train Epoch: 43 [416000/906425] Loss: 0.421259 Acc: 0.8750\n",
      "Train Epoch: 43 [432000/906425] Loss: 1.088227 Acc: 0.6875\n",
      "Train Epoch: 43 [448000/906425] Loss: 1.081689 Acc: 0.6875\n",
      "Train Epoch: 43 [464000/906425] Loss: 1.111740 Acc: 0.5625\n",
      "Train Epoch: 43 [480000/906425] Loss: 0.631144 Acc: 0.7500\n",
      "Train Epoch: 43 [496000/906425] Loss: 0.352195 Acc: 0.8750\n",
      "Train Epoch: 43 [512000/906425] Loss: 1.029525 Acc: 0.7500\n",
      "Train Epoch: 43 [528000/906425] Loss: 0.607076 Acc: 0.8750\n",
      "Train Epoch: 43 [544000/906425] Loss: 0.433282 Acc: 0.9375\n",
      "Train Epoch: 43 [560000/906425] Loss: 1.307118 Acc: 0.7500\n",
      "Train Epoch: 43 [576000/906425] Loss: 0.282687 Acc: 0.8750\n",
      "Train Epoch: 43 [592000/906425] Loss: 1.011310 Acc: 0.7500\n",
      "Train Epoch: 43 [608000/906425] Loss: 0.205408 Acc: 0.9375\n",
      "Train Epoch: 43 [624000/906425] Loss: 0.822166 Acc: 0.7500\n",
      "Train Epoch: 43 [640000/906425] Loss: 0.845004 Acc: 0.8750\n",
      "Train Epoch: 43 [656000/906425] Loss: 0.885134 Acc: 0.8750\n",
      "Train Epoch: 43 [672000/906425] Loss: 0.915622 Acc: 0.7500\n",
      "Train Epoch: 43 [688000/906425] Loss: 0.462800 Acc: 0.8125\n",
      "Train Epoch: 43 [704000/906425] Loss: 0.424038 Acc: 0.8750\n",
      "Train Epoch: 43 [720000/906425] Loss: 0.577237 Acc: 0.8750\n",
      "Train Epoch: 43 [736000/906425] Loss: 0.702491 Acc: 0.8125\n",
      "Train Epoch: 43 [752000/906425] Loss: 0.558926 Acc: 0.8125\n",
      "Train Epoch: 43 [768000/906425] Loss: 0.409029 Acc: 0.8750\n",
      "Train Epoch: 43 [784000/906425] Loss: 0.467471 Acc: 0.8125\n",
      "Train Epoch: 43 [800000/906425] Loss: 0.509950 Acc: 0.8125\n",
      "Train Epoch: 43 [816000/906425] Loss: 0.533595 Acc: 0.8750\n",
      "Train Epoch: 43 [832000/906425] Loss: 0.201424 Acc: 1.0000\n",
      "Train Epoch: 43 [848000/906425] Loss: 0.319708 Acc: 0.9375\n",
      "Train Epoch: 43 [864000/906425] Loss: 0.783038 Acc: 0.8125\n",
      "Train Epoch: 43 [880000/906425] Loss: 0.515601 Acc: 0.8750\n",
      "Train Epoch: 43 [896000/906425] Loss: 0.470384 Acc: 0.7500\n",
      "Elapsed 25389.56s, 577.04 s/epoch, 0.01 s/batch, ets 3462.21s\n",
      "\n",
      "Test set: Average loss: 1.4752, Accuracy: 210112/293785 (72%)\n",
      "\n",
      "Train Epoch: 44 [16000/906425] Loss: 0.573532 Acc: 0.8125\n",
      "Train Epoch: 44 [32000/906425] Loss: 0.562120 Acc: 0.7500\n",
      "Train Epoch: 44 [48000/906425] Loss: 0.544145 Acc: 0.8750\n",
      "Train Epoch: 44 [64000/906425] Loss: 0.689791 Acc: 0.8125\n",
      "Train Epoch: 44 [80000/906425] Loss: 0.491072 Acc: 0.8125\n",
      "Train Epoch: 44 [96000/906425] Loss: 0.467146 Acc: 0.9375\n",
      "Train Epoch: 44 [112000/906425] Loss: 0.360980 Acc: 0.8750\n",
      "Train Epoch: 44 [128000/906425] Loss: 0.788361 Acc: 0.8125\n",
      "Train Epoch: 44 [144000/906425] Loss: 1.390901 Acc: 0.7500\n",
      "Train Epoch: 44 [160000/906425] Loss: 1.335459 Acc: 0.6250\n",
      "Train Epoch: 44 [176000/906425] Loss: 0.767796 Acc: 0.6875\n",
      "Train Epoch: 44 [192000/906425] Loss: 0.803615 Acc: 0.8750\n",
      "Train Epoch: 44 [208000/906425] Loss: 0.308046 Acc: 0.9375\n",
      "Train Epoch: 44 [224000/906425] Loss: 0.115403 Acc: 1.0000\n",
      "Train Epoch: 44 [240000/906425] Loss: 0.268538 Acc: 0.8750\n",
      "Train Epoch: 44 [256000/906425] Loss: 0.377058 Acc: 0.8750\n",
      "Train Epoch: 44 [272000/906425] Loss: 0.281902 Acc: 0.8750\n",
      "Train Epoch: 44 [288000/906425] Loss: 0.220821 Acc: 0.9375\n",
      "Train Epoch: 44 [304000/906425] Loss: 1.043532 Acc: 0.6875\n",
      "Train Epoch: 44 [320000/906425] Loss: 1.138495 Acc: 0.6875\n",
      "Train Epoch: 44 [336000/906425] Loss: 0.636630 Acc: 0.7500\n",
      "Train Epoch: 44 [352000/906425] Loss: 0.205639 Acc: 1.0000\n",
      "Train Epoch: 44 [368000/906425] Loss: 1.492940 Acc: 0.6875\n",
      "Train Epoch: 44 [384000/906425] Loss: 0.794375 Acc: 0.7500\n",
      "Train Epoch: 44 [400000/906425] Loss: 0.819130 Acc: 0.8750\n",
      "Train Epoch: 44 [416000/906425] Loss: 0.424722 Acc: 0.8750\n",
      "Train Epoch: 44 [432000/906425] Loss: 0.862721 Acc: 0.8125\n",
      "Train Epoch: 44 [448000/906425] Loss: 0.364561 Acc: 0.8750\n",
      "Train Epoch: 44 [464000/906425] Loss: 0.566822 Acc: 0.7500\n",
      "Train Epoch: 44 [480000/906425] Loss: 0.572932 Acc: 0.8750\n",
      "Train Epoch: 44 [496000/906425] Loss: 0.973922 Acc: 0.7500\n",
      "Train Epoch: 44 [512000/906425] Loss: 0.545589 Acc: 0.8125\n",
      "Train Epoch: 44 [528000/906425] Loss: 0.476103 Acc: 0.8750\n",
      "Train Epoch: 44 [544000/906425] Loss: 0.548419 Acc: 0.8750\n",
      "Train Epoch: 44 [560000/906425] Loss: 0.257645 Acc: 0.9375\n",
      "Train Epoch: 44 [576000/906425] Loss: 0.246830 Acc: 0.9375\n",
      "Train Epoch: 44 [592000/906425] Loss: 0.714958 Acc: 0.6875\n",
      "Train Epoch: 44 [608000/906425] Loss: 0.494895 Acc: 0.7500\n",
      "Train Epoch: 44 [624000/906425] Loss: 1.240539 Acc: 0.7500\n",
      "Train Epoch: 44 [640000/906425] Loss: 1.033789 Acc: 0.6875\n",
      "Train Epoch: 44 [656000/906425] Loss: 0.543978 Acc: 0.8750\n",
      "Train Epoch: 44 [672000/906425] Loss: 0.803423 Acc: 0.8125\n",
      "Train Epoch: 44 [688000/906425] Loss: 0.256132 Acc: 0.9375\n",
      "Train Epoch: 44 [704000/906425] Loss: 0.241664 Acc: 0.8750\n",
      "Train Epoch: 44 [720000/906425] Loss: 0.528459 Acc: 0.7500\n",
      "Train Epoch: 44 [736000/906425] Loss: 0.474873 Acc: 0.8750\n",
      "Train Epoch: 44 [752000/906425] Loss: 0.901047 Acc: 0.8750\n",
      "Train Epoch: 44 [768000/906425] Loss: 1.026750 Acc: 0.8750\n",
      "Train Epoch: 44 [784000/906425] Loss: 0.758499 Acc: 0.8750\n",
      "Train Epoch: 44 [800000/906425] Loss: 0.762948 Acc: 0.8750\n",
      "Train Epoch: 44 [816000/906425] Loss: 0.719047 Acc: 0.8125\n",
      "Train Epoch: 44 [832000/906425] Loss: 0.687417 Acc: 0.8125\n",
      "Train Epoch: 44 [848000/906425] Loss: 0.677377 Acc: 0.8125\n",
      "Train Epoch: 44 [864000/906425] Loss: 0.672242 Acc: 0.8750\n",
      "Train Epoch: 44 [880000/906425] Loss: 0.772745 Acc: 0.8125\n",
      "Train Epoch: 44 [896000/906425] Loss: 0.630116 Acc: 0.6875\n",
      "Elapsed 25968.94s, 577.09 s/epoch, 0.01 s/batch, ets 2885.44s\n",
      "\n",
      "Test set: Average loss: 1.4757, Accuracy: 210573/293785 (72%)\n",
      "\n",
      "Train Epoch: 45 [16000/906425] Loss: 1.180739 Acc: 0.6875\n",
      "Train Epoch: 45 [32000/906425] Loss: 0.381895 Acc: 0.8750\n",
      "Train Epoch: 45 [48000/906425] Loss: 0.704892 Acc: 0.7500\n",
      "Train Epoch: 45 [64000/906425] Loss: 0.177657 Acc: 0.9375\n",
      "Train Epoch: 45 [80000/906425] Loss: 0.625359 Acc: 0.6875\n",
      "Train Epoch: 45 [96000/906425] Loss: 0.323208 Acc: 0.8750\n",
      "Train Epoch: 45 [112000/906425] Loss: 1.453995 Acc: 0.6875\n",
      "Train Epoch: 45 [128000/906425] Loss: 0.357462 Acc: 0.8750\n",
      "Train Epoch: 45 [144000/906425] Loss: 0.141783 Acc: 1.0000\n",
      "Train Epoch: 45 [160000/906425] Loss: 0.687994 Acc: 0.8125\n",
      "Train Epoch: 45 [176000/906425] Loss: 0.323034 Acc: 0.9375\n",
      "Train Epoch: 45 [192000/906425] Loss: 0.564949 Acc: 0.8125\n",
      "Train Epoch: 45 [208000/906425] Loss: 0.394618 Acc: 0.8125\n",
      "Train Epoch: 45 [224000/906425] Loss: 0.592504 Acc: 0.8125\n",
      "Train Epoch: 45 [240000/906425] Loss: 0.508781 Acc: 0.8125\n",
      "Train Epoch: 45 [256000/906425] Loss: 0.274977 Acc: 0.9375\n",
      "Train Epoch: 45 [272000/906425] Loss: 0.719052 Acc: 0.8125\n",
      "Train Epoch: 45 [288000/906425] Loss: 0.295004 Acc: 0.9375\n",
      "Train Epoch: 45 [304000/906425] Loss: 0.346808 Acc: 0.9375\n",
      "Train Epoch: 45 [320000/906425] Loss: 0.662056 Acc: 0.8125\n",
      "Train Epoch: 45 [336000/906425] Loss: 0.658196 Acc: 0.8750\n",
      "Train Epoch: 45 [352000/906425] Loss: 1.143698 Acc: 0.8125\n",
      "Train Epoch: 45 [368000/906425] Loss: 0.890222 Acc: 0.8125\n",
      "Train Epoch: 45 [384000/906425] Loss: 0.681535 Acc: 0.8125\n",
      "Train Epoch: 45 [400000/906425] Loss: 1.078449 Acc: 0.6875\n",
      "Train Epoch: 45 [416000/906425] Loss: 0.308924 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [432000/906425] Loss: 0.923391 Acc: 0.8125\n",
      "Train Epoch: 45 [448000/906425] Loss: 0.705223 Acc: 0.7500\n",
      "Train Epoch: 45 [464000/906425] Loss: 0.264512 Acc: 0.9375\n",
      "Train Epoch: 45 [480000/906425] Loss: 0.877243 Acc: 0.7500\n",
      "Train Epoch: 45 [496000/906425] Loss: 0.345764 Acc: 0.8750\n",
      "Train Epoch: 45 [512000/906425] Loss: 0.564999 Acc: 0.8125\n",
      "Train Epoch: 45 [528000/906425] Loss: 0.545268 Acc: 0.8750\n",
      "Train Epoch: 45 [544000/906425] Loss: 1.008998 Acc: 0.7500\n",
      "Train Epoch: 45 [560000/906425] Loss: 0.458131 Acc: 0.8125\n",
      "Train Epoch: 45 [576000/906425] Loss: 1.270708 Acc: 0.6250\n",
      "Train Epoch: 45 [592000/906425] Loss: 0.391581 Acc: 0.9375\n",
      "Train Epoch: 45 [608000/906425] Loss: 1.133473 Acc: 0.8125\n",
      "Train Epoch: 45 [624000/906425] Loss: 0.661850 Acc: 0.8125\n",
      "Train Epoch: 45 [640000/906425] Loss: 0.958725 Acc: 0.7500\n",
      "Train Epoch: 45 [656000/906425] Loss: 0.413770 Acc: 0.9375\n",
      "Train Epoch: 45 [672000/906425] Loss: 0.193602 Acc: 0.9375\n",
      "Train Epoch: 45 [688000/906425] Loss: 0.670878 Acc: 0.7500\n",
      "Train Epoch: 45 [704000/906425] Loss: 0.192844 Acc: 0.9375\n",
      "Train Epoch: 45 [720000/906425] Loss: 0.694630 Acc: 0.8125\n",
      "Train Epoch: 45 [736000/906425] Loss: 0.814740 Acc: 0.6875\n",
      "Train Epoch: 45 [752000/906425] Loss: 0.190791 Acc: 0.8750\n",
      "Train Epoch: 45 [768000/906425] Loss: 0.214487 Acc: 0.9375\n",
      "Train Epoch: 45 [784000/906425] Loss: 0.094273 Acc: 1.0000\n",
      "Train Epoch: 45 [800000/906425] Loss: 0.377607 Acc: 0.8750\n",
      "Train Epoch: 45 [816000/906425] Loss: 0.326300 Acc: 0.8750\n",
      "Train Epoch: 45 [832000/906425] Loss: 0.194546 Acc: 0.9375\n",
      "Train Epoch: 45 [848000/906425] Loss: 0.567894 Acc: 0.8125\n",
      "Train Epoch: 45 [864000/906425] Loss: 0.128747 Acc: 1.0000\n",
      "Train Epoch: 45 [880000/906425] Loss: 0.716207 Acc: 0.7500\n",
      "Train Epoch: 45 [896000/906425] Loss: 0.252247 Acc: 0.8750\n",
      "Elapsed 26548.07s, 577.13 s/epoch, 0.01 s/batch, ets 2308.53s\n",
      "\n",
      "Test set: Average loss: 1.4701, Accuracy: 211446/293785 (72%)\n",
      "\n",
      "Train Epoch: 46 [16000/906425] Loss: 0.445849 Acc: 0.9375\n",
      "Train Epoch: 46 [32000/906425] Loss: 0.207199 Acc: 0.9375\n",
      "Train Epoch: 46 [48000/906425] Loss: 0.485395 Acc: 0.9375\n",
      "Train Epoch: 46 [64000/906425] Loss: 0.426122 Acc: 0.8750\n",
      "Train Epoch: 46 [80000/906425] Loss: 0.271778 Acc: 0.9375\n",
      "Train Epoch: 46 [96000/906425] Loss: 1.210089 Acc: 0.6875\n",
      "Train Epoch: 46 [112000/906425] Loss: 0.553190 Acc: 0.8750\n",
      "Train Epoch: 46 [128000/906425] Loss: 1.152902 Acc: 0.7500\n",
      "Train Epoch: 46 [144000/906425] Loss: 0.149900 Acc: 1.0000\n",
      "Train Epoch: 46 [160000/906425] Loss: 0.861757 Acc: 0.7500\n",
      "Train Epoch: 46 [176000/906425] Loss: 1.110948 Acc: 0.6875\n",
      "Train Epoch: 46 [192000/906425] Loss: 0.245032 Acc: 0.9375\n",
      "Train Epoch: 46 [208000/906425] Loss: 0.301600 Acc: 0.9375\n",
      "Train Epoch: 46 [224000/906425] Loss: 0.541846 Acc: 0.7500\n",
      "Train Epoch: 46 [240000/906425] Loss: 0.967670 Acc: 0.8750\n",
      "Train Epoch: 46 [256000/906425] Loss: 0.350839 Acc: 0.8750\n",
      "Train Epoch: 46 [272000/906425] Loss: 0.199178 Acc: 0.8750\n",
      "Train Epoch: 46 [288000/906425] Loss: 0.799650 Acc: 0.8125\n",
      "Train Epoch: 46 [304000/906425] Loss: 0.456032 Acc: 0.8125\n",
      "Train Epoch: 46 [320000/906425] Loss: 0.979237 Acc: 0.6875\n",
      "Train Epoch: 46 [336000/906425] Loss: 0.319575 Acc: 0.9375\n",
      "Train Epoch: 46 [352000/906425] Loss: 0.695368 Acc: 0.8125\n",
      "Train Epoch: 46 [368000/906425] Loss: 0.283472 Acc: 0.8750\n",
      "Train Epoch: 46 [384000/906425] Loss: 0.457842 Acc: 0.9375\n",
      "Train Epoch: 46 [400000/906425] Loss: 0.276640 Acc: 0.9375\n",
      "Train Epoch: 46 [416000/906425] Loss: 0.975394 Acc: 0.9375\n",
      "Train Epoch: 46 [432000/906425] Loss: 0.678719 Acc: 0.8750\n",
      "Train Epoch: 46 [448000/906425] Loss: 0.895727 Acc: 0.8750\n",
      "Train Epoch: 46 [464000/906425] Loss: 0.430174 Acc: 0.8750\n",
      "Train Epoch: 46 [480000/906425] Loss: 0.509967 Acc: 0.9375\n",
      "Train Epoch: 46 [496000/906425] Loss: 0.156318 Acc: 0.9375\n",
      "Train Epoch: 46 [512000/906425] Loss: 0.551207 Acc: 0.7500\n",
      "Train Epoch: 46 [528000/906425] Loss: 0.904528 Acc: 0.8125\n",
      "Train Epoch: 46 [544000/906425] Loss: 0.639955 Acc: 0.8750\n",
      "Train Epoch: 46 [560000/906425] Loss: 0.808453 Acc: 0.6875\n",
      "Train Epoch: 46 [576000/906425] Loss: 0.175930 Acc: 0.9375\n",
      "Train Epoch: 46 [592000/906425] Loss: 0.717344 Acc: 0.6875\n",
      "Train Epoch: 46 [608000/906425] Loss: 0.249449 Acc: 0.8750\n",
      "Train Epoch: 46 [624000/906425] Loss: 0.533200 Acc: 0.8125\n",
      "Train Epoch: 46 [640000/906425] Loss: 1.162528 Acc: 0.6875\n",
      "Train Epoch: 46 [656000/906425] Loss: 0.418500 Acc: 0.8125\n",
      "Train Epoch: 46 [672000/906425] Loss: 0.750849 Acc: 0.6875\n",
      "Train Epoch: 46 [688000/906425] Loss: 0.382430 Acc: 0.9375\n",
      "Train Epoch: 46 [704000/906425] Loss: 0.217726 Acc: 0.9375\n",
      "Train Epoch: 46 [720000/906425] Loss: 0.598777 Acc: 0.8125\n",
      "Train Epoch: 46 [736000/906425] Loss: 0.852645 Acc: 0.6875\n",
      "Train Epoch: 46 [752000/906425] Loss: 0.283623 Acc: 0.8750\n",
      "Train Epoch: 46 [768000/906425] Loss: 0.622594 Acc: 0.7500\n",
      "Train Epoch: 46 [784000/906425] Loss: 0.672588 Acc: 0.7500\n",
      "Train Epoch: 46 [800000/906425] Loss: 0.759687 Acc: 0.6875\n",
      "Train Epoch: 46 [816000/906425] Loss: 0.668559 Acc: 0.8125\n",
      "Train Epoch: 46 [832000/906425] Loss: 0.439932 Acc: 0.7500\n",
      "Train Epoch: 46 [848000/906425] Loss: 0.247568 Acc: 0.8750\n",
      "Train Epoch: 46 [864000/906425] Loss: 1.576173 Acc: 0.7500\n",
      "Train Epoch: 46 [880000/906425] Loss: 0.684089 Acc: 0.7500\n",
      "Train Epoch: 46 [896000/906425] Loss: 0.512563 Acc: 0.7500\n",
      "Elapsed 27127.51s, 577.18 s/epoch, 0.01 s/batch, ets 1731.54s\n",
      "\n",
      "Test set: Average loss: 1.4856, Accuracy: 211168/293785 (72%)\n",
      "\n",
      "Train Epoch: 47 [16000/906425] Loss: 0.426897 Acc: 0.8750\n",
      "Train Epoch: 47 [32000/906425] Loss: 0.578049 Acc: 0.8750\n",
      "Train Epoch: 47 [48000/906425] Loss: 0.250605 Acc: 1.0000\n",
      "Train Epoch: 47 [64000/906425] Loss: 0.608769 Acc: 0.8750\n",
      "Train Epoch: 47 [80000/906425] Loss: 0.218866 Acc: 0.9375\n",
      "Train Epoch: 47 [96000/906425] Loss: 0.075841 Acc: 1.0000\n",
      "Train Epoch: 47 [112000/906425] Loss: 0.557110 Acc: 0.8125\n",
      "Train Epoch: 47 [128000/906425] Loss: 0.712744 Acc: 0.7500\n",
      "Train Epoch: 47 [144000/906425] Loss: 0.470547 Acc: 0.9375\n",
      "Train Epoch: 47 [160000/906425] Loss: 1.064866 Acc: 0.7500\n",
      "Train Epoch: 47 [176000/906425] Loss: 0.738641 Acc: 0.6875\n",
      "Train Epoch: 47 [192000/906425] Loss: 0.542305 Acc: 0.8750\n",
      "Train Epoch: 47 [208000/906425] Loss: 1.155998 Acc: 0.6875\n",
      "Train Epoch: 47 [224000/906425] Loss: 0.915667 Acc: 0.7500\n",
      "Train Epoch: 47 [240000/906425] Loss: 0.418964 Acc: 0.8125\n",
      "Train Epoch: 47 [256000/906425] Loss: 0.246892 Acc: 0.9375\n",
      "Train Epoch: 47 [272000/906425] Loss: 0.469798 Acc: 0.8750\n",
      "Train Epoch: 47 [288000/906425] Loss: 1.536140 Acc: 0.7500\n",
      "Train Epoch: 47 [304000/906425] Loss: 0.935382 Acc: 0.8125\n",
      "Train Epoch: 47 [320000/906425] Loss: 0.427741 Acc: 0.9375\n",
      "Train Epoch: 47 [336000/906425] Loss: 0.582504 Acc: 0.8750\n",
      "Train Epoch: 47 [352000/906425] Loss: 0.331200 Acc: 0.8750\n",
      "Train Epoch: 47 [368000/906425] Loss: 0.213132 Acc: 0.9375\n",
      "Train Epoch: 47 [384000/906425] Loss: 0.814768 Acc: 0.6250\n",
      "Train Epoch: 47 [400000/906425] Loss: 0.663823 Acc: 0.8125\n",
      "Train Epoch: 47 [416000/906425] Loss: 0.507290 Acc: 0.7500\n",
      "Train Epoch: 47 [432000/906425] Loss: 0.161784 Acc: 1.0000\n",
      "Train Epoch: 47 [448000/906425] Loss: 0.798365 Acc: 0.7500\n",
      "Train Epoch: 47 [464000/906425] Loss: 2.063847 Acc: 0.5625\n",
      "Train Epoch: 47 [480000/906425] Loss: 0.658973 Acc: 0.8125\n",
      "Train Epoch: 47 [496000/906425] Loss: 1.543363 Acc: 0.6250\n",
      "Train Epoch: 47 [512000/906425] Loss: 0.216659 Acc: 1.0000\n",
      "Train Epoch: 47 [528000/906425] Loss: 0.488345 Acc: 0.8750\n",
      "Train Epoch: 47 [544000/906425] Loss: 0.663849 Acc: 0.7500\n",
      "Train Epoch: 47 [560000/906425] Loss: 0.206457 Acc: 0.9375\n",
      "Train Epoch: 47 [576000/906425] Loss: 0.406525 Acc: 0.8750\n",
      "Train Epoch: 47 [592000/906425] Loss: 0.844178 Acc: 0.7500\n",
      "Train Epoch: 47 [608000/906425] Loss: 0.421262 Acc: 0.8125\n",
      "Train Epoch: 47 [624000/906425] Loss: 0.498194 Acc: 0.8750\n",
      "Train Epoch: 47 [640000/906425] Loss: 0.669412 Acc: 0.8125\n",
      "Train Epoch: 47 [656000/906425] Loss: 0.481117 Acc: 0.8125\n",
      "Train Epoch: 47 [672000/906425] Loss: 0.672870 Acc: 0.8125\n",
      "Train Epoch: 47 [688000/906425] Loss: 0.598748 Acc: 0.8750\n",
      "Train Epoch: 47 [704000/906425] Loss: 0.203652 Acc: 0.9375\n",
      "Train Epoch: 47 [720000/906425] Loss: 0.983874 Acc: 0.6250\n",
      "Train Epoch: 47 [736000/906425] Loss: 0.395088 Acc: 0.9375\n",
      "Train Epoch: 47 [752000/906425] Loss: 1.509257 Acc: 0.7500\n",
      "Train Epoch: 47 [768000/906425] Loss: 0.150013 Acc: 0.9375\n",
      "Train Epoch: 47 [784000/906425] Loss: 0.386965 Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [800000/906425] Loss: 0.657119 Acc: 0.8125\n",
      "Train Epoch: 47 [816000/906425] Loss: 0.678351 Acc: 0.8125\n",
      "Train Epoch: 47 [832000/906425] Loss: 0.464266 Acc: 0.8125\n",
      "Train Epoch: 47 [848000/906425] Loss: 0.369452 Acc: 0.8125\n",
      "Train Epoch: 47 [864000/906425] Loss: 0.531006 Acc: 0.8125\n",
      "Train Epoch: 47 [880000/906425] Loss: 0.616705 Acc: 0.7500\n",
      "Train Epoch: 47 [896000/906425] Loss: 0.464658 Acc: 0.7500\n",
      "Elapsed 27706.81s, 577.23 s/epoch, 0.01 s/batch, ets 1154.45s\n",
      "\n",
      "Test set: Average loss: 1.4954, Accuracy: 211150/293785 (72%)\n",
      "\n",
      "Train Epoch: 48 [16000/906425] Loss: 0.668010 Acc: 0.8125\n",
      "Train Epoch: 48 [32000/906425] Loss: 0.622660 Acc: 0.9375\n",
      "Train Epoch: 48 [48000/906425] Loss: 0.237745 Acc: 0.9375\n",
      "Train Epoch: 48 [64000/906425] Loss: 0.536085 Acc: 0.8125\n",
      "Train Epoch: 48 [80000/906425] Loss: 0.829103 Acc: 0.8125\n",
      "Train Epoch: 48 [96000/906425] Loss: 0.198384 Acc: 0.9375\n",
      "Train Epoch: 48 [112000/906425] Loss: 0.401025 Acc: 0.8750\n",
      "Train Epoch: 48 [128000/906425] Loss: 0.560486 Acc: 0.8750\n",
      "Train Epoch: 48 [144000/906425] Loss: 1.055921 Acc: 0.8125\n",
      "Train Epoch: 48 [160000/906425] Loss: 0.273902 Acc: 0.8750\n",
      "Train Epoch: 48 [176000/906425] Loss: 1.279147 Acc: 0.6875\n",
      "Train Epoch: 48 [192000/906425] Loss: 0.245318 Acc: 0.9375\n",
      "Train Epoch: 48 [208000/906425] Loss: 0.901991 Acc: 0.7500\n",
      "Train Epoch: 48 [224000/906425] Loss: 0.261189 Acc: 1.0000\n",
      "Train Epoch: 48 [240000/906425] Loss: 0.517634 Acc: 0.8750\n",
      "Train Epoch: 48 [256000/906425] Loss: 0.302628 Acc: 0.8750\n",
      "Train Epoch: 48 [272000/906425] Loss: 0.445850 Acc: 0.8750\n",
      "Train Epoch: 48 [288000/906425] Loss: 0.654085 Acc: 0.8125\n",
      "Train Epoch: 48 [304000/906425] Loss: 0.553458 Acc: 0.8750\n",
      "Train Epoch: 48 [320000/906425] Loss: 0.897479 Acc: 0.7500\n",
      "Train Epoch: 48 [336000/906425] Loss: 0.134348 Acc: 1.0000\n",
      "Train Epoch: 48 [352000/906425] Loss: 0.257295 Acc: 0.9375\n",
      "Train Epoch: 48 [368000/906425] Loss: 0.469970 Acc: 0.7500\n",
      "Train Epoch: 48 [384000/906425] Loss: 1.501296 Acc: 0.6250\n",
      "Train Epoch: 48 [400000/906425] Loss: 1.122526 Acc: 0.6875\n",
      "Train Epoch: 48 [416000/906425] Loss: 1.837396 Acc: 0.6875\n",
      "Train Epoch: 48 [432000/906425] Loss: 0.327254 Acc: 0.8750\n",
      "Train Epoch: 48 [448000/906425] Loss: 0.140676 Acc: 1.0000\n",
      "Train Epoch: 48 [464000/906425] Loss: 0.994060 Acc: 0.7500\n",
      "Train Epoch: 48 [480000/906425] Loss: 0.177347 Acc: 1.0000\n",
      "Train Epoch: 48 [496000/906425] Loss: 1.287625 Acc: 0.6250\n",
      "Train Epoch: 48 [512000/906425] Loss: 0.706489 Acc: 0.8125\n",
      "Train Epoch: 48 [528000/906425] Loss: 0.512977 Acc: 0.8750\n",
      "Train Epoch: 48 [544000/906425] Loss: 1.169837 Acc: 0.6250\n",
      "Train Epoch: 48 [560000/906425] Loss: 0.848945 Acc: 0.6875\n",
      "Train Epoch: 48 [576000/906425] Loss: 0.861070 Acc: 0.6875\n",
      "Train Epoch: 48 [592000/906425] Loss: 0.201331 Acc: 1.0000\n",
      "Train Epoch: 48 [608000/906425] Loss: 0.666804 Acc: 0.8750\n",
      "Train Epoch: 48 [624000/906425] Loss: 1.031568 Acc: 0.8125\n",
      "Train Epoch: 48 [640000/906425] Loss: 0.441631 Acc: 0.8750\n",
      "Train Epoch: 48 [656000/906425] Loss: 0.315512 Acc: 0.9375\n",
      "Train Epoch: 48 [672000/906425] Loss: 0.143276 Acc: 1.0000\n",
      "Train Epoch: 48 [688000/906425] Loss: 0.324868 Acc: 0.8750\n",
      "Train Epoch: 48 [704000/906425] Loss: 0.660514 Acc: 0.7500\n",
      "Train Epoch: 48 [720000/906425] Loss: 0.288246 Acc: 0.9375\n",
      "Train Epoch: 48 [736000/906425] Loss: 0.147363 Acc: 0.9375\n",
      "Train Epoch: 48 [752000/906425] Loss: 0.605849 Acc: 0.8750\n",
      "Train Epoch: 48 [768000/906425] Loss: 0.404796 Acc: 0.9375\n",
      "Train Epoch: 48 [784000/906425] Loss: 0.330687 Acc: 0.8750\n",
      "Train Epoch: 48 [800000/906425] Loss: 0.819179 Acc: 0.7500\n",
      "Train Epoch: 48 [816000/906425] Loss: 0.165477 Acc: 0.9375\n",
      "Train Epoch: 48 [832000/906425] Loss: 0.535601 Acc: 0.8125\n",
      "Train Epoch: 48 [848000/906425] Loss: 1.020063 Acc: 0.7500\n",
      "Train Epoch: 48 [864000/906425] Loss: 0.152446 Acc: 0.9375\n",
      "Train Epoch: 48 [880000/906425] Loss: 0.717288 Acc: 0.7500\n",
      "Train Epoch: 48 [896000/906425] Loss: 0.347617 Acc: 0.9375\n",
      "Elapsed 28286.24s, 577.27 s/epoch, 0.01 s/batch, ets 577.27s\n",
      "\n",
      "Test set: Average loss: 1.4813, Accuracy: 211372/293785 (72%)\n",
      "\n",
      "Train Epoch: 49 [16000/906425] Loss: 0.808223 Acc: 0.8125\n",
      "Train Epoch: 49 [32000/906425] Loss: 0.673286 Acc: 0.7500\n",
      "Train Epoch: 49 [48000/906425] Loss: 0.843194 Acc: 0.8125\n",
      "Train Epoch: 49 [64000/906425] Loss: 0.563425 Acc: 0.7500\n",
      "Train Epoch: 49 [80000/906425] Loss: 0.420263 Acc: 0.9375\n",
      "Train Epoch: 49 [96000/906425] Loss: 0.529347 Acc: 0.8750\n",
      "Train Epoch: 49 [112000/906425] Loss: 0.805102 Acc: 0.7500\n",
      "Train Epoch: 49 [128000/906425] Loss: 0.082963 Acc: 1.0000\n",
      "Train Epoch: 49 [144000/906425] Loss: 0.682093 Acc: 0.8750\n",
      "Train Epoch: 49 [160000/906425] Loss: 0.314080 Acc: 0.9375\n",
      "Train Epoch: 49 [176000/906425] Loss: 0.230787 Acc: 0.9375\n",
      "Train Epoch: 49 [192000/906425] Loss: 0.734391 Acc: 0.8125\n",
      "Train Epoch: 49 [208000/906425] Loss: 0.812983 Acc: 0.6875\n",
      "Train Epoch: 49 [224000/906425] Loss: 1.335589 Acc: 0.6250\n",
      "Train Epoch: 49 [240000/906425] Loss: 1.331557 Acc: 0.7500\n",
      "Train Epoch: 49 [256000/906425] Loss: 0.552327 Acc: 0.8750\n",
      "Train Epoch: 49 [272000/906425] Loss: 0.466185 Acc: 0.7500\n",
      "Train Epoch: 49 [288000/906425] Loss: 1.064364 Acc: 0.7500\n",
      "Train Epoch: 49 [304000/906425] Loss: 0.091039 Acc: 1.0000\n",
      "Train Epoch: 49 [320000/906425] Loss: 0.196271 Acc: 0.9375\n",
      "Train Epoch: 49 [336000/906425] Loss: 0.512551 Acc: 0.7500\n",
      "Train Epoch: 49 [352000/906425] Loss: 0.353569 Acc: 0.8750\n",
      "Train Epoch: 49 [368000/906425] Loss: 0.508028 Acc: 0.8750\n",
      "Train Epoch: 49 [384000/906425] Loss: 0.328764 Acc: 0.8750\n",
      "Train Epoch: 49 [400000/906425] Loss: 1.298717 Acc: 0.7500\n",
      "Train Epoch: 49 [416000/906425] Loss: 0.199311 Acc: 0.9375\n",
      "Train Epoch: 49 [432000/906425] Loss: 0.265581 Acc: 0.9375\n",
      "Train Epoch: 49 [448000/906425] Loss: 0.449461 Acc: 0.9375\n",
      "Train Epoch: 49 [464000/906425] Loss: 0.211527 Acc: 0.9375\n",
      "Train Epoch: 49 [480000/906425] Loss: 0.502859 Acc: 0.8125\n",
      "Train Epoch: 49 [496000/906425] Loss: 0.206872 Acc: 0.9375\n",
      "Train Epoch: 49 [512000/906425] Loss: 0.791191 Acc: 0.8750\n",
      "Train Epoch: 49 [528000/906425] Loss: 0.501348 Acc: 0.8125\n",
      "Train Epoch: 49 [544000/906425] Loss: 0.648383 Acc: 0.8125\n",
      "Train Epoch: 49 [560000/906425] Loss: 0.825249 Acc: 0.8125\n",
      "Train Epoch: 49 [576000/906425] Loss: 0.303010 Acc: 0.8750\n",
      "Train Epoch: 49 [592000/906425] Loss: 1.109863 Acc: 0.7500\n",
      "Train Epoch: 49 [608000/906425] Loss: 0.513664 Acc: 0.8750\n",
      "Train Epoch: 49 [624000/906425] Loss: 0.487568 Acc: 0.8125\n",
      "Train Epoch: 49 [640000/906425] Loss: 1.025558 Acc: 0.8125\n",
      "Train Epoch: 49 [656000/906425] Loss: 0.371323 Acc: 0.9375\n",
      "Train Epoch: 49 [672000/906425] Loss: 0.552195 Acc: 0.9375\n",
      "Train Epoch: 49 [688000/906425] Loss: 1.514698 Acc: 0.5625\n",
      "Train Epoch: 49 [704000/906425] Loss: 0.988932 Acc: 0.6875\n",
      "Train Epoch: 49 [720000/906425] Loss: 0.401865 Acc: 0.9375\n",
      "Train Epoch: 49 [736000/906425] Loss: 0.441823 Acc: 0.9375\n",
      "Train Epoch: 49 [752000/906425] Loss: 0.197961 Acc: 0.9375\n",
      "Train Epoch: 49 [768000/906425] Loss: 0.638184 Acc: 0.8125\n",
      "Train Epoch: 49 [784000/906425] Loss: 0.929785 Acc: 0.8125\n",
      "Train Epoch: 49 [800000/906425] Loss: 1.307707 Acc: 0.6250\n",
      "Train Epoch: 49 [816000/906425] Loss: 1.192330 Acc: 0.7500\n",
      "Train Epoch: 49 [832000/906425] Loss: 0.684696 Acc: 0.8750\n",
      "Train Epoch: 49 [848000/906425] Loss: 0.457075 Acc: 0.8125\n",
      "Train Epoch: 49 [864000/906425] Loss: 0.923366 Acc: 0.7500\n",
      "Train Epoch: 49 [880000/906425] Loss: 0.432867 Acc: 0.8125\n",
      "Train Epoch: 49 [896000/906425] Loss: 0.789150 Acc: 0.7500\n",
      "Elapsed 28865.76s, 577.32 s/epoch, 0.01 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 1.5162, Accuracy: 211636/293785 (72%)\n",
      "\n",
      "Total time: 28943.39, Best Loss: 1.436\n",
      "TEST 22, TEST ACC: 72.04%, TOTIME: 8.04 hours\n"
     ]
    }
   ],
   "source": [
    "TEST_NUM = 22\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 50\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=600, out_features=300), # 4th layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 23\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 50\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 24\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=600, out_features=300), # 4th layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=300, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 25\n",
    "required_training = False\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_COUNT = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self._head = nn.Sequential(\n",
    "        nn.Linear(in_features=92, out_features=300), # 1st layer\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(in_features=300, out_features=1000), # 2nd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.Linear(in_features=1000, out_features=600), # 3rd layer\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=600, out_features=35531) # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "    \n",
    "if required_training:\n",
    "    try:\n",
    "        model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc, elapsed = \\\n",
    "        main(batch_size=BATCH_SIZE, epochs_count=EPOCHS_COUNT, learning_rate=LEARNING_RATE, neuralModel=AudioNet())\n",
    "        twilioMessage(testnum=TEST_NUM, acc=epoch_test_acc[-1]*100, time=elapsed/60/60)\n",
    "    except Exception as e:\n",
    "        twilioMessage(message=f\"ERROR ON TEST {TEST_NUM}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, PLEASE GIVE ME MORE TESTS TO RUN\n"
     ]
    }
   ],
   "source": [
    "twilioMessage(message=\"DONE, PLEASE GIVE ME MORE TESTS TO RUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
